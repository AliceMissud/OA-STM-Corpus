{"name":"OA STM Corpus","tagline":"A corpus, and small treebank, of Open Access journal articles from multiple disciplines in Science, Technology, and Medicine","body":"Natural Language Processing (NLP) tools perform best if they are\r\nused on the same kind of content on which they were trained and\r\ntested. Unfortunately for those in the STM domains, our content has\r\nsome big differences from the newswire text that is commonly used\r\nin the development of most NLP tools. There are some corpora of STM\r\ncontent, but the ones we know of are specific to one domain, such\r\nas biomedicine, and will typically consist of abstracts instead of\r\nfull articles. This is less than optimum because math articles are\r\nvery different from biomed articles, and articles are very different\r\nfrom abstracts.\r\n\r\n###Corpus\r\n\r\nTo improve this situation, Elsevier is providing a selection of 110\r\njournal articles from 10 different STM domains as a freely-redistributable\r\ncorpus. The articles were selected from our Open Access content\r\nand have a Creative Commons CC-BY license. Therefore, they are free to\r\nredistribute and use.  The domains are agriculture, astronomy,\r\nbiology, chemistry, computer science, earth science, engineering,\r\nmaterials science, math, and medicine.  Currently we provide 11\r\narticles in each of the 10 domains. For each article in the corpus we provide:\r\n* the XML source,\r\n* a simple text version for easier text mining,\r\n* several versions with different annotations. These include part\r\nof speech tags, sentence breaks, NP and VP chunks, lemmas, syntactic\r\nconstituents parses, wikipedia concept identification, and discourse\r\nanalysis. (Some of this is still under construction.)\r\n\r\n### Annotations and Test Sets\r\n\r\nIn addition to having a wide-ranging STM corpus, we also hope that\r\nthe content becomes densely annotated with many different types of\r\nNLP analyses beyond those mentioned above. Not only would this allow\r\ncomparison of algorithms for the same type of annotations, it would also\r\nallow for the automatic selection of features to be used in creating\r\nhigher-order annotations. \r\n\r\nMost of the annotations are automatically created. However, we have\r\nidentified 10 documents as a default test set. As new annotation types\r\nare added, those articles should be the first choice for manually\r\nreviewed and corrected test data.\r\n\r\n### Treebank\r\nTo seed the process of manually creating test sets, Elsevier has\r\ncommissioned a treebank of the ten full-text articles in the default test\r\nset.  We hope this corpus and treebank become a valuable resource\r\nfor NLP, linguistics, and text mining researchers, developers, and\r\nusers, as we all work towards tools that do a better job handling\r\nSTM content.\r\n\r\n### Context\r\n\r\nQuantity | Content\r\n---------|--------------------------------\r\n~12M     | All Elsevier journal articles\r\n~100k    | All Open Access Elsevier journal articles. PDFs free to read.\r\n~15k     | Open Access articles with CC-BY license. PDFs free to read, redistribute, and use.\r\n110      | STM Corpus articles. PDFs and XML free to read, redistribute, and use.\r\n10       | Default test set of articles. Starting point for manual annotations, and the source for our treebank.\r\n\r\n### Future\r\n\r\nA public prerelease was made on January 11, 2015, for the FORCE2015 Hackathon. We will make revisions based on feedback from the prerelease. The full release of the corpus and treebank will occur after all 10 articles are treebanked. We may include additional articles in the corpus beyond the initial 110, depending on feedback from the community.\r\n\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}