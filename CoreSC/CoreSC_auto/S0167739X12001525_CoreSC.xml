<?xml version="1.0" ?><PAPER><mode2 hasDoc="yes" name="S0167739X12001525.tmf1" version="elsevier"/>
<TITLE>Adaptive resource configuration for Cloud infrastructure management
</TITLE>
<ABSTRACT>

Abstract
<s sid="1"><CoreSc1 advantage="None" conceptID="Mot1" novelty="None" type="Mot"/><text>To guarantee the vision of Cloud Computing QoS goals between the Cloud provider and the customer have to be dynamically met.</text></s>
<s sid="2"><CoreSc1 advantage="None" conceptID="Mot2" novelty="None" type="Mot"/><text>This so-called Service Level Agreement (SLA) enactment should involve little human-based interaction in order to guarantee the scalability and efficient resource utilization of the system.</text></s>
<s sid="3"><CoreSc1 advantage="None" conceptID="Obj1" novelty="None" type="Obj"/><text>To achieve this we start from Autonomic Computing, examine the autonomic control loop and adapt it to govern Cloud Computing infrastructures.</text></s>
<s sid="4"><CoreSc1 advantage="None" conceptID="Obj2" novelty="None" type="Obj"/><text>We first hierarchically structure all possible adaptation actions into so-called escalation levels.</text></s>
<s sid="5"><CoreSc1 advantage="None" conceptID="Obj3" novelty="None" type="Obj"/><text>We then focus on one of these levels by analyzing monitored data from virtual machines and making decisions on their resource configuration with the help of knowledge management (KM).</text></s>
<s sid="6"><CoreSc1 advantage="None" conceptID="Obj4" novelty="None" type="Obj"/><text>The monitored data stems both from synthetically generated workload categorized in different workload volatility classes and from a real-world scenario: scientific workflow applications in bioinformatics.</text></s>
<s sid="7"><CoreSc1 advantage="None" conceptID="Obj5" novelty="None" type="Obj"/><text>As KM techniques, we investigate two methods, Case-Based Reasoning and a rule-based approach.</text></s>
<s sid="8"><CoreSc1 advantage="None" conceptID="Obj6" novelty="None" type="Obj"/><text>We design and implement both of them and evaluate them with the help of a simulation engine.</text></s>
<s sid="9"><CoreSc1 advantage="None" conceptID="Obj7" novelty="None" type="Obj"/><text>Simulation reveals the feasibility of the CBR approach and major improvements by the rule-based approach considering SLA violations, resource utilization, the number of necessary reconfigurations and time performance for both, synthetically generated and real-world data.</text></s>
Highlights
<s sid="10"><CoreSc1 advantage="None" conceptID="Obj8" novelty="None" type="Obj"/><text>► We apply knowledge management to guarantee SLAs and low resource wastage in Clouds.</text></s>
<s sid="11"><CoreSc1 advantage="None" conceptID="Obj9" novelty="None" type="Obj"/><text>► Escalation levels provide a hierarchical model to structure possible reconfiguration actions.</text></s>
<s sid="12"><CoreSc1 advantage="None" conceptID="Met1" novelty="None" type="Met"/><text>► Case-Based Reasoning and rule-based approach prove feasibility as KM techniques.</text></s>
<s sid="13"><CoreSc1 advantage="None" conceptID="Obs1" novelty="None" type="Obs"/><text>► In-depth evaluation of rule-based approach shows major improvements towards CBR.</text></s>
<s sid="14"><CoreSc1 advantage="None" conceptID="Res1" novelty="None" type="Res"/><text>► KM is applied to real-world data gathered from scientific bioinformatic workflows.</text></s>
</ABSTRACT>
<BODY>

Introduction
<s sid="15"><CoreSc1 advantage="None" conceptID="Res2" novelty="None" type="Res"/><text>The vision of Cloud Computing is to provide computing power as a utility, like gas, electricity or water [1].</text></s>
<s sid="16"><CoreSc1 advantage="None" conceptID="Res3" novelty="None" type="Res"/><text>For the underlying infrastructure this means that it has to deal with dynamic load changes, ranging from peak performance to utilization gaps.</text></s>
<s sid="17"><CoreSc1 advantage="None" conceptID="Mot3" novelty="None" type="Mot"/><text>This brings up two issues: on the one hand, the management of a Cloud Computing infrastructure has to guarantee pre-established contracts despite all the dynamism of workload changes.</text></s>
<s sid="18"><CoreSc1 advantage="None" conceptID="Bac1" novelty="None" type="Bac"/><text>On the other hand it has to efficiently utilize resources and reduce resource wastage.</text></s>
<s sid="19"><CoreSc1 advantage="None" conceptID="Bac2" novelty="None" type="Bac"/><text>As to the former, the pre-established contracts, so called Service Level Agreements (SLAs), contain Service Level Objectives (SLOs) that represent Quality of Service (QoS) goals, e.g., &quot;storage should be at least 1000 GB&quot;, &quot;bandwidth should be at least 10 Mbit/s&quot; or &quot;response time should be less than 2 s&quot;, and penalties that have to be paid to the customer if these goals are violated.</text></s>
<s sid="20"><CoreSc1 advantage="None" conceptID="Bac3" novelty="None" type="Bac"/><text>This work can be integrated into the Foundations of Self-governing ICT Infrastructure (FoSII) project [2], but is on its own completely self-sufficient.</text></s>
<s sid="21"><CoreSc1 advantage="None" conceptID="Bac4" novelty="None" type="Bac"/><text>The FoSII project aims at developing an infrastructure for autonomic SLA management and enforcement.</text></s>
<s sid="22"><CoreSc1 advantage="None" conceptID="Bac5" novelty="None" type="Bac"/><text>Besides the already implemented LoM2HiS framework [3] that takes care of monitoring the state of the Cloud infrastructure and its applications, the knowledge management (KM) system presented in this article can be viewed as another building block of the FoSII infrastructure.</text></s>
<s sid="23"><CoreSc1 advantage="None" conceptID="Bac6" novelty="None" type="Bac"/><text>[4] proposes an approach to manage Cloud infrastructures by means of Autonomic Computing, which in a control loop monitors (M) Cloud parameters, analyzes (A) them, plans (P) actions and executes (E) them; the full cycle is known as MAPE [5].</text></s>
<s sid="24"><CoreSc1 advantage="None" conceptID="Bac7" novelty="None" type="Bac"/><text>According to [6] a MAPE-K loop stores knowledge (K) required for decision-making in a knowledge base (KB) that is accessed by the individual phases.</text></s>
<s sid="25"><CoreSc1 advantage="None" conceptID="Goa1" novelty="None" type="Goa"/><text>This paper addresses the research question of finding a suitable KM system (i.e., a technique of how stored information should be used) and determining how it interacts with the other phases for dynamically and efficiently allocating resources.</text></s>
<s sid="26"><CoreSc1 advantage="None" conceptID="Goa2" novelty="None" type="Goa"/><text>One of the imminent problems that come up when dealing with the MAPE-K loop is to define possible actions that can be executed at the end of the loop.</text></s>
<s sid="27"><CoreSc1 advantage="None" conceptID="Obj10" novelty="None" type="Obj"/><text>Due to the plethora of possible reconfiguration actions in Clouds, e.g., increasing/decreasing available memory or storage for virtual machines (VMs), choosing VMs to migrate to selected physical machines (PMs), determining PMs to power on/off, etc., it is not trivial to identify the most beneficial action in a certain situation.</text></s>
<s sid="28"><CoreSc1 advantage="None" conceptID="Mot4" novelty="None" type="Mot"/><text>On the one hand it is not trivial to retrieve and store all necessary information in a Cloud infrastructure.</text></s>
<s sid="29"><CoreSc1 advantage="None" conceptID="Obj11" novelty="None" type="Obj"/><text>On the other hand, and more important in our work, dealing with the complexity of recommending an action based on this information is, as we will see, in most cases NP-hard.</text></s>
<s sid="30"><CoreSc1 advantage="None" conceptID="Obj12" novelty="None" type="Obj"/><text>To tackle this, we structure all possible actions and organize them in a hierarchical model of so called escalation levels.</text></s>
<s sid="31"><CoreSc1 advantage="None" conceptID="Obj13" novelty="None" type="Obj"/><text>In [7,8] we have shown that approaches using Case Based Reasoning (CBR) and rules as knowledge management techniques succeed in autonomically enacting SLAs and governing important parts of Cloud computing infrastructures.</text></s>
<s sid="32"><CoreSc1 advantage="None" conceptID="Met2" novelty="None" type="Met"/><text>Case Based Reasoning was chosen, because it offers a natural translation of Cloud status information into formal knowledge representation and an easy integration with the MAPE phases.</text></s>
<s sid="33"><CoreSc1 advantage="None" conceptID="Bac8" novelty="None" type="Bac"/><text>Moreover, it promises to be scalable (as opposed to e.g., Situation Calculus) and easily configurable (as opposed to rule-based systems).</text></s>
<s sid="34"><CoreSc1 advantage="None" conceptID="Bac9" novelty="None" type="Bac"/><text>Related work has not observed the usage of CBR nor has it evaluated different KM techniques in Cloud environments.</text></s>
<s sid="35"><CoreSc1 advantage="None" conceptID="Obj14" novelty="None" type="Obj"/><text>However, we determined some drawbacks of CBR as far as its learning performance and its scalability were concerned.</text></s>
<s sid="36"><CoreSc1 advantage="None" conceptID="Goa3" novelty="None" type="Goa"/><text>Therefore, we also designed and implemented a rule-based knowledge management approach.</text></s>
<s sid="37"><CoreSc1 advantage="None" conceptID="Goa4" novelty="None" type="Goa"/><text>Using rules [8] we managed to improve not only SLA adherence and resource allocation efficiency as discussed in [7], but also attained an efficient use of reallocation actions and high scalability.</text></s>
<s sid="38"><CoreSc1 advantage="None" conceptID="Obj15" novelty="None" type="Obj"/><text>Yet, evaluating the KM system on a real environment is not a trivial task because of two reasons: First, Cloud infrastructures usually are huge data centers consisting of hundreds of PMs and even more VMs.</text></s>
<s sid="39"><CoreSc1 advantage="None" conceptID="Obj16" novelty="None" type="Obj"/><text>Thus, a first step is to simulate the impact of autonomic management decisions on the Cloud infrastructure to determine the performance of the KM decisions.</text></s>
<s sid="40"><CoreSc1 advantage="None" conceptID="Obj17" novelty="None" type="Obj"/><text>Consequently, we designed and implemented a simulation engine that mimics the MAPE-K cycle on large Clouds.</text></s>
<s sid="41"><CoreSc1 advantage="None" conceptID="Obj18" novelty="None" type="Obj"/><text>Second, workload data for a large number of VMs has to be provided as input for the simulation.</text></s>
<s sid="42"><CoreSc1 advantage="None" conceptID="Goa5" novelty="None" type="Goa"/><text>We decided to go two ways: On the one hand, we generated synthetic workload data categorized into different workload volatility classes.</text></s>
<s sid="43"><CoreSc1 advantage="None" conceptID="Bac10" novelty="None" type="Bac"/><text>These workload volatility classes are determined by the speed and intensity of workload change.</text></s>
<s sid="44"><CoreSc1 advantage="None" conceptID="Mot5" novelty="None" type="Mot"/><text>On the other hand, we gathered real world data from monitoring scientific workflow applications in the field of bioinformatics [9].</text></s>
<s sid="45"><CoreSc1 advantage="None" conceptID="Mot6" novelty="None" type="Mot"/><text>These workflows need a huge, yet unpredictable and varying amount of resources, and are thus-due to the needed flexibility and scalability-a perfect match for a Cloud computing application [10].</text></s>
<s sid="46"><CoreSc1 advantage="None" conceptID="Goa6" novelty="None" type="Goa"/><text>The main challenge in this work is to evaluate KM techniques for autonomic SLA enactment in Cloud computing infrastructures that fulfill the three following conflicting goals: (i) achieving low SLA violation rates; (ii) achieving high resource utilization such that the level of allocated but unused resources is as low as possible; and (iii) achieving (i) and (ii) by as few time- and energy-consuming reallocation actions as possible.</text></s>
<s sid="47"><CoreSc1 advantage="None" conceptID="Obj19" novelty="None" type="Obj"/><text>We will call this problem the resource allocation problem throughout the rest of the paper.</text></s>
<s sid="48"><CoreSc1 advantage="None" conceptID="Obj20" novelty="None" type="Obj"/><text>The main contributions of this paper are: 1.</text></s>
<s sid="49"><CoreSc1 advantage="None" conceptID="Obj21" novelty="None" type="Obj"/><text>Design and implementation of a generic (KM-technique agnostic) simulation engine to assess the quality of the KM and decision-making techniques.</text></s>
2.
<s sid="50"><CoreSc1 advantage="None" conceptID="Met3" novelty="None" type="Met"/><text>Partitioning the resource allocation problem for Cloud infrastructures into several subproblems by proposing escalation levels that structure all possible reaction possibilities into different subproblems using a hierarchical model.</text></s>
3.
<s sid="51"><CoreSc1 advantage="None" conceptID="Met4" novelty="None" type="Met"/><text>Design, Implementation and Evaluation of two KM techniques for one escalation level, i.e., VM resource configuration: CBR, and the rule-based approach.</text></s>
4.
<s sid="52"><CoreSc1 advantage="None" conceptID="Met5" novelty="None" type="Met"/><text>Application of the rule-based approach to real-world monitoring data from scientific workflow applications in the field of bioinformatics.</text></s>
<s sid="53"><CoreSc1 advantage="None" conceptID="Res4" novelty="None" type="Res"/><text>The remainder of this work is divided as follows: In Section 2 we present related work.</text></s>
<s sid="54"><CoreSc1 advantage="None" conceptID="Res5" novelty="None" type="Res"/><text>Section 3 gives some background information by explaining the MAPE-K loop and the FoSII project.</text></s>
<s sid="55"><CoreSc1 advantage="None" conceptID="Obj22" novelty="None" type="Obj"/><text>In Section 4 we structure the problem into the mentioned escalation levels, and in Section 5 we describe how to use the two KM techniques (CBR and rules) to tackle the resource allocation problem for a certain escalation level.</text></s>
<s sid="56"><CoreSc1 advantage="None" conceptID="Obj23" novelty="None" type="Obj"/><text>Section 6 shows the evaluation of both approaches, especially focusing on the rule-based approach.</text></s>
<s sid="57"><CoreSc1 advantage="None" conceptID="Bac11" novelty="None" type="Bac"/><text>Section 7 concludes this contribution and points out future work.</text></s>
Related work
<s sid="58"><CoreSc1 advantage="None" conceptID="Goa7" novelty="None" type="Goa"/><text>Concerning related work, we have determined four different ways to compare our work with other achievements in this area.</text></s>
<s sid="59"><CoreSc1 advantage="None" conceptID="Goa8" novelty="None" type="Goa"/><text>Whereas the first level compares other works dealing with SLA enactment and resource efficiency, the second one considers the area of knowledge management, and the third one compares commercial products to our approach.</text></s>
<s sid="60"><CoreSc1 advantage="None" conceptID="Goa9" novelty="None" type="Goa"/><text>Fourthly, the FoSII project is briefly related to other projects in this field.</text></s>
<s sid="61"><CoreSc1 advantage="None" conceptID="Goa10" novelty="None" type="Goa"/><text>Firstly, there has been some considerable work on optimizing resource usage while keeping QoS goals.</text></s>
<s sid="62"><CoreSc1 advantage="None" conceptID="Met6" novelty="None" type="Met"/><text>These papers, however, concentrate on specific subsystems of Large Scale Distributed Systems, such as [11] on the performance of memory systems, or only deal with one or two specific SLA parameters.</text></s>
<s sid="63"><CoreSc1 advantage="None" conceptID="Met7" novelty="None" type="Met"/><text>Petrucci et al. [12] or Bichler et al. [13] investigate one general resource constraint and Khanna et al. [14] only focuses on response time and throughput.</text></s>
<s sid="64"><CoreSc1 advantage="None" conceptID="Res6" novelty="None" type="Res"/><text>A quite similar approach to our concept is provided by the Sandpiper framework [15], which offers black-box and gray-box resource management for VMs.</text></s>
<s sid="65"><CoreSc1 advantage="None" conceptID="Res7" novelty="None" type="Res"/><text>Contrary to our approach, though, it plans reactions just after violations have occurred.</text></s>
<s sid="66"><CoreSc1 advantage="None" conceptID="Res8" novelty="None" type="Res"/><text>Also the VCONF model by Rao et al. [16] has similar goals as presented in Section 1, but depends on specific parameters, can only execute one action per iteration and it neglects the energy consumption of executed actions.</text></s>
<s sid="67"><CoreSc1 advantage="None" conceptID="Goa11" novelty="None" type="Goa"/><text>Other papers focus on different escalation levels (as described in Section 4).</text></s>
<s sid="68"><CoreSc1 advantage="None" conceptID="Goa12" novelty="None" type="Goa"/><text>[17,18] focus on VM migration and [19] on turning on and off physical machines, whereas our paper focuses on VM re-configuration.</text></s>
<s sid="69"><CoreSc1 advantage="None" conceptID="Obj24" novelty="None" type="Obj"/><text>Additionally, none of the presented papers uses a KB for recording past action and learning.</text></s>
<s sid="70"><CoreSc1 advantage="None" conceptID="Bac12" novelty="None" type="Bac"/><text>Hoyer et al. [20] also undertake a speculative approach as in our work by overbooking PM resources.</text></s>
<s sid="71"><CoreSc1 advantage="None" conceptID="Bac13" novelty="None" type="Bac"/><text>They assign VMs to PMs that would exceed their maximum resource capacities, because VMs hardly ever use all their assigned resources.</text></s>
<s sid="72"><CoreSc1 advantage="None" conceptID="Bac14" novelty="None" type="Bac"/><text>Computing this allocation they also take into consideration workload correlation of different VMs.</text></s>
<s sid="73"><CoreSc1 advantage="None" conceptID="Bac15" novelty="None" type="Bac"/><text>Borgetto et al. [21] tackle the trade-off between consolidating VMs on PMs and turning off PMs on the one hand, and attaining SLOs for CPU and memory on the other.</text></s>
<s sid="74"><CoreSc1 advantage="None" conceptID="Bac16" novelty="None" type="Bac"/><text>However, the authors assume a static setting and do not consider dynamically changing workloads.</text></s>
<s sid="75"><CoreSc1 advantage="None" conceptID="Bac17" novelty="None" type="Bac"/><text>So, e.g., they do not take the number of migrations into account.</text></s>
<s sid="76"><CoreSc1 advantage="None" conceptID="Met8" novelty="None" type="Met"/><text>Stillwell et al. [22] in a similar setting define the resource allocation problem for static workloads, present the optimal solution for small instances and evaluate heuristics by simulations.</text></s>
<s sid="77"><CoreSc1 advantage="None" conceptID="Met9" novelty="None" type="Met"/><text>Nathani et al. [23], e.g., also deal with VM placement on PMs using scheduling techniques.</text></s>
<s sid="78"><CoreSc1 advantage="None" conceptID="Met10" novelty="None" type="Met"/><text>[24] react to changing workload demands by starting new VM instances; taking into account VM startup time, they use prediction models to have VMs available already before the peak occurs.</text></s>
<s sid="79"><CoreSc1 advantage="None" conceptID="Obj25" novelty="None" type="Obj"/><text>Other works such as [25] have already considered the last escalation level (see Section 4), i.e., outsourcing of applications to other Clouds.</text></s>
<s sid="80"><CoreSc1 advantage="None" conceptID="Mot7" novelty="None" type="Mot"/><text>Summarizing we can say that there has been a great deal of work on the different escalation levels, whereas VM configuration has not been observed yet.</text></s>
<s sid="81"><CoreSc1 advantage="None" conceptID="Bac18" novelty="None" type="Bac"/><text>Secondly, there has been work on KM of SLAs, especially rule-based systems.</text></s>
<s sid="82"><CoreSc1 advantage="None" conceptID="Bac19" novelty="None" type="Bac"/><text>Paschke and Bichler [26] look into a rule based approach in combination with the logical formalism ContractLog.</text></s>
<s sid="83"><CoreSc1 advantage="None" conceptID="Bac20" novelty="None" type="Bac"/><text>It specifies rules to trigger after a violation has occurred, but it does not deal with avoidance of SLA violations.</text></s>
<s sid="84"><CoreSc1 advantage="None" conceptID="Bac21" novelty="None" type="Bac"/><text>Others inspected the use of ontologies as KBs only at a conceptual level.</text></s>
<s sid="85"><CoreSc1 advantage="None" conceptID="Obj26" novelty="None" type="Obj"/><text>[27] viewed the system in four layers (i.e., business, system, network and device) and broke down the SLA into relevant information for each layer, which had the responsibility of allocating required resources.</text></s>
<s sid="86"><CoreSc1 advantage="None" conceptID="Bac22" novelty="None" type="Bac"/><text>Again, no details on how to achieve this have been given.</text></s>
<s sid="87"><CoreSc1 advantage="None" conceptID="Bac23" novelty="None" type="Bac"/><text>Bahati and Bauer [28] also use policies, i.e., rules, to achieve autonomic management.</text></s>
<s sid="88"><CoreSc1 advantage="None" conceptID="Bac24" novelty="None" type="Bac"/><text>They provide a system architecture including a KB and a learning component, and divide all possible states of the system into so called regions, which they assign a certain benefit for being in this region.</text></s>
<s sid="89"><CoreSc1 advantage="None" conceptID="Bac25" novelty="None" type="Bac"/><text>A bad region would be, e.g., response time&gt;500 (too slow), fair region response time&lt;100 (too fast, consuming unnecessary resources) and a good region 100≤response time≤500.</text></s>
<s sid="90"><CoreSc1 advantage="None" conceptID="Bac26" novelty="None" type="Bac"/><text>The actions are not structured, but are mixed together into a single rule, which makes the rules very hard to manage and to determine a salience concept behind them.</text></s>
<s sid="91"><CoreSc1 advantage="None" conceptID="Met11" novelty="None" type="Met"/><text>However, we share the idea of defining &quot;over-utilized&quot;, &quot;neutral&quot; and &quot;under-utilized&quot; regions.</text></s>
<s sid="92"><CoreSc1 advantage="None" conceptID="Met12" novelty="None" type="Met"/><text>Our KM system allows us to choose any arbitrary number of resource parameters that can be adjusted on a VM.</text></s>
<s sid="93"><CoreSc1 advantage="None" conceptID="Met13" novelty="None" type="Met"/><text>Moreover, our paper provides a more wholesome approach than related work and integrates the different action levels that work has been carried out on.</text></s>
<s sid="94"><CoreSc1 advantage="None" conceptID="Met14" novelty="None" type="Met"/><text>Thirdly, commercial Cloud IaaS platforms such as Amazon EC2 [29], Rackspace [30] or RightScale [31] have a very limited choice of preconfigured and static VM resource provisioning types.</text></s>
<s sid="95"><CoreSc1 advantage="None" conceptID="Met15" novelty="None" type="Met"/><text>Amazon EC2 only offers VM instance types such as small, medium or large with predefined storage, computing units, and memory without the possibility of reconfiguring or fine-tuning them beforehand, not to mention during runtime.</text></s>
<s sid="96"><CoreSc1 advantage="None" conceptID="Met16" novelty="None" type="Met"/><text>Rackspace only offers storage on the IaaS level, and RightScale focuses more on integrating different IaaS platforms such as Amazon EC2 or Rackspace into a holistic view.</text></s>
<s sid="97"><CoreSc1 advantage="None" conceptID="Goa13" novelty="None" type="Goa"/><text>Fourthly, compared to other SLA management projects like SLA@SOI [32], the FoSII project in general is more specific on Cloud Computing aspects like deployment, monitoring of resources and their translation into high level SLAs instead of just working on high-level SLAs in general service-oriented architectures.</text></s>
Background
<s sid="98"><CoreSc1 advantage="None" conceptID="Goa14" novelty="None" type="Goa"/><text>In this section we describe how the KM approach can be integrated within a more holistic Cloud management project that, e.g., also consists of a monitoring component.</text></s>
<s sid="99"><CoreSc1 advantage="None" conceptID="Met17" novelty="None" type="Met"/><text>Yet, the KM approach does not depend on the specific used monitoring framework, as long as it correctly measures the current values of the parameters specified in the SLA.</text></s>
<s sid="100"><CoreSc1 advantage="None" conceptID="Obj27" novelty="None" type="Obj"/><text>In this case, the FoSII project will serve as a running example.</text></s>
<s sid="101"><CoreSc1 advantage="None" conceptID="Obj28" novelty="None" type="Obj"/><text>We will describe how the KM approach relates to other components of the FoSII project.</text></s>
<s sid="102"><CoreSc1 advantage="None" conceptID="Obj29" novelty="None" type="Obj"/><text>Generally, the project distinguishes between system set-up and run time.</text></s>
<s sid="103"><CoreSc1 advantage="None" conceptID="Obj30" novelty="None" type="Obj"/><text>During system set-up, applications, their corresponding SLAs and used infrastructure are tailored and adapted.</text></s>
<s sid="104"><CoreSc1 advantage="None" conceptID="Obj31" novelty="None" type="Obj"/><text>Once the application is deployed, we consider monitoring, knowledge management and execution phases during run time.</text></s>
<s sid="105"><CoreSc1 advantage="None" conceptID="Obj32" novelty="None" type="Obj"/><text>In this section, in particular, we focus on the adaptation, monitoring, and knowledge management phases, as shown in Fig. 1.</text></s>
<s sid="106"><CoreSc1 advantage="None" conceptID="Res9" novelty="None" type="Res"/><text>Thus, the MAPE-K loop is extended to the A-MAPE-K loop, where the additional A stands for the adaptation phase during system set-up.</text></s>
<s sid="107"><CoreSc1 advantage="None" conceptID="Res10" novelty="None" type="Res"/><text>This adaptation phase, however, should not be confused with later adaptation and re-configuration of resources during system run time.</text></s>
<s sid="108"><CoreSc1 advantage="None" conceptID="Obj33" novelty="None" type="Obj"/><text>Quite evidently, we especially focus on the knowledge management phase in this paper.</text></s>
<s sid="109"><CoreSc1 advantage="None" conceptID="Obj34" novelty="None" type="Obj"/><text>The three mentioned phases are described as follows:</text></s>
Adaptation
<s sid="110"><CoreSc1 advantage="None" conceptID="Obs2" novelty="None" type="Obs"/><text>As shown in Fig. 1, part 1, the adaptation phase comprises all steps necessary to be done before successful deployment and start of the application.</text></s>
<s sid="111"><CoreSc1 advantage="None" conceptID="Obs3" novelty="None" type="Obs"/><text>This includes SLA contract establishment and tailoring of the monitoring systems for the particular application.</text></s>
<s sid="112"><CoreSc1 advantage="None" conceptID="Mod1" novelty="None" type="Mod"/><text>We assume that Cloud providers register their resources to particular databases containing public SLA templates.</text></s>
<s sid="113"><CoreSc1 advantage="None" conceptID="Res11" novelty="None" type="Res"/><text>Thereafter, Cloud users can look up resources that they want to use for the deployment of their applications.</text></s>
<s sid="114"><CoreSc1 advantage="None" conceptID="Res12" novelty="None" type="Res"/><text>Similar to the providers, Cloud users also have an SLA template utilized for their private business processes.</text></s>
<s sid="115"><CoreSc1 advantage="None" conceptID="Hyp1" novelty="None" type="Hyp"/><text>We assume that the private SLA template cannot be changed, since it could also be part of some other local business processes and has usually to comply with different legal and security guidelines.</text></s>
<s sid="116"><CoreSc1 advantage="None" conceptID="Res13" novelty="None" type="Res"/><text>If matching SLA templates are found, an SLA contract can be negotiated and established and the application can be deployed.</text></s>
<s sid="117"><CoreSc1 advantage="None" conceptID="Res14" novelty="None" type="Res"/><text>Thus, during this phase it has to be ensured that private templates of the provider and consumers match publicly available templates.</text></s>
<s sid="118"><CoreSc1 advantage="None" conceptID="Res15" novelty="None" type="Res"/><text>However, public and private templates may differ.</text></s>
<s sid="119"><CoreSc1 advantage="None" conceptID="Res16" novelty="None" type="Res"/><text>A typical mismatch between templates would be between different measurement units of attributes, as for example for the SLO clock speed or missing attributes.</text></s>
<s sid="120"><CoreSc1 advantage="None" conceptID="Res17" novelty="None" type="Res"/><text>Therefore, a mechanism is required for the automatic adaptation between different templates without changing the templates themselves.</text></s>
<s sid="121"><CoreSc1 advantage="None" conceptID="Res18" novelty="None" type="Res"/><text>A possible solution for this is the so called SLA mapping approach presented in [33].</text></s>
<s sid="122"><CoreSc1 advantage="None" conceptID="Res19" novelty="None" type="Res"/><text>This approach can include handling of missing SLA parameters, inconsistencies between attributes and translation between different attributes.</text></s>
<s sid="123"><CoreSc1 advantage="None" conceptID="Res20" novelty="None" type="Res"/><text>More complex adaptations would include automatic service aggregation, including third party services, if, for example, the clock speed attribute is completely missing in the public template, but required in the private template.</text></s>
<s sid="124"><CoreSc1 advantage="None" conceptID="Res21" novelty="None" type="Res"/><text>A third party provider (e.g., a computer hardware reseller) could be integrated to deliver information about the clock speed attribute.</text></s>
<s sid="125"><CoreSc1 advantage="None" conceptID="Res22" novelty="None" type="Res"/><text>Detailed information on the adaptation phase including the SLA mapping approach are found in [33,34].</text></s>
Monitoring
<s sid="126"><CoreSc1 advantage="None" conceptID="Res23" novelty="None" type="Res"/><text>Current monitoring systems (e.g., ganglia [35]) facilitate monitoring only of low-level systems resources, such as free_disk or packets_sent, but SLA parameters typically are, e.g., storage and outgoing bandwidth.</text></s>
<s sid="127"><CoreSc1 advantage="None" conceptID="Res24" novelty="None" type="Res"/><text>Thus, SLA parameters required by an application usually differ from the parameters measured by the monitoring tools.</text></s>
<s sid="128"><CoreSc1 advantage="None" conceptID="Res25" novelty="None" type="Res"/><text>To achieve a mapping from the low-level metrics to the high-level SLA parameters, the monitoring phase should comprise two core components, namely the host monitor and the run-time monitor (see Fig. 1, part 2).</text></s>
<s sid="129"><CoreSc1 advantage="None" conceptID="Res26" novelty="None" type="Res"/><text>The former is responsible for monitoring low-level resource metrics, whereas the latter is responsible for metric mapping, and consequently for the monitoring of SLAs and informing the KM phase about SLA violations.</text></s>
<s sid="130"><CoreSc1 advantage="None" conceptID="Con1" novelty="None" type="Con"/><text>This monitoring framework has proven to be highly scalable and is presented in more detail in [3].</text></s>
Knowledge Management
<s sid="131"><CoreSc1 advantage="None" conceptID="Con2" novelty="None" type="Con"/><text>Since the analysis, plan and KB parts are highly interweaved with each other, we call the ensemble of these phases the Knowledge Management Phase (see Fig. 1, part 3).</text></s>
<s sid="132"><CoreSc1 advantage="None" conceptID="Met18" novelty="None" type="Met"/><text>The knowledge management component receives current information about SLA parameters of each running application from the run-time monitor of the monitoring component.</text></s>
<s sid="133"><CoreSc1 advantage="None" conceptID="Res27" novelty="None" type="Res"/><text>Depending on the KM technique in use, the KM phase analyzes this data to determine critical situations, where either SLA parameters are about to be violated or too many resources are wasted.</text></s>
<s sid="134"><CoreSc1 advantage="None" conceptID="Obs4" novelty="None" type="Obs"/><text>The analysis component receives the monitoring data, stores it in the KB and queries it to recommend an action to be executed.</text></s>
<s sid="135"><CoreSc1 advantage="None" conceptID="Obs5" novelty="None" type="Obs"/><text>The plan phase maps these actions onto PMs or plans outsourcing them to other Cloud providers.</text></s>
<s sid="136"><CoreSc1 advantage="None" conceptID="Obs6" novelty="None" type="Obs"/><text>Finally, the actions are executed (Execution phase) with the help of actuators.</text></s>
<s sid="137"><CoreSc1 advantage="None" conceptID="Res28" novelty="None" type="Res"/><text>Additionally, the KB does not only enable decision making out of current data, i.e., suggesting actions to be executed, but also improving the quality of decisions by keeping track of the success or failure of previous decisions, i.e., learning.</text></s>
<s sid="138"><CoreSc1 advantage="None" conceptID="Res29" novelty="None" type="Res"/><text>Structuring the problem: escalation levels</text></s>
<s sid="139"><CoreSc1 advantage="None" conceptID="Obj35" novelty="None" type="Obj"/><text>This section presents a methodology of dividing the resource allocation problem into smaller subproblems using a hierarchical approach.</text></s>
<s sid="140"><CoreSc1 advantage="None" conceptID="Obj36" novelty="None" type="Obj"/><text>It demonstrates which actions can be executed in what level to achieve SLA adherence and efficient resource allocation for Cloud infrastructures.</text></s>
<s sid="141"><CoreSc1 advantage="None" conceptID="Obj37" novelty="None" type="Obj"/><text>In general, we can think of the following reallocation actions: 1.</text></s>
for individual applications: (a)
<s sid="142"><CoreSc1 advantage="None" conceptID="Obs7" novelty="None" type="Obs"/><text>Increase incoming bandwidth share by x%.</text></s>
(b)
<s sid="143"><CoreSc1 advantage="None" conceptID="Obs8" novelty="None" type="Obs"/><text>Decrease incoming bandwidth share by x%.</text></s>
(c)
<s sid="144"><CoreSc1 advantage="None" conceptID="Obs9" novelty="None" type="Obs"/><text>Increase outgoing bandwidth share by x%.</text></s>
(d)
<s sid="145"><CoreSc1 advantage="None" conceptID="Obs10" novelty="None" type="Obs"/><text>Decrease outgoing bandwidth share by x%.</text></s>
(e)
Increase memory by x%.
(f)
Decrease memory by x%.
(g)
<s sid="146"><CoreSc1 advantage="None" conceptID="Obs11" novelty="None" type="Obs"/><text>Add allocated storage by x%.</text></s>
(h)
<s sid="147"><CoreSc1 advantage="None" conceptID="Obs12" novelty="None" type="Obs"/><text>Remove allocated storage by x%.</text></s>
(i)
<s sid="148"><CoreSc1 advantage="None" conceptID="Obs13" novelty="None" type="Obs"/><text>Increase CPU share by x%.</text></s>
(j)
<s sid="149"><CoreSc1 advantage="None" conceptID="Obs14" novelty="None" type="Obs"/><text>Decrease CPU share by x%.</text></s>
(k)
<s sid="150"><CoreSc1 advantage="None" conceptID="Obs15" novelty="None" type="Obs"/><text>Outsource (move application) to other Cloud.</text></s>
(l)
<s sid="151"><CoreSc1 advantage="None" conceptID="Obs16" novelty="None" type="Obs"/><text>Insource (accept application) from other Cloud.</text></s>
(m)
<s sid="152"><CoreSc1 advantage="None" conceptID="Obs17" novelty="None" type="Obs"/><text>Migrate application to different VM.</text></s>
2.
for VMs: (a)
<s sid="153"><CoreSc1 advantage="None" conceptID="Obs18" novelty="None" type="Obs"/><text>Increase incoming bandwidth share by x%.</text></s>
(b)
<s sid="154"><CoreSc1 advantage="None" conceptID="Obs19" novelty="None" type="Obs"/><text>Decrease incoming bandwidth share by x%.</text></s>
(c)
<s sid="155"><CoreSc1 advantage="None" conceptID="Obs20" novelty="None" type="Obs"/><text>Increase outgoing bandwidth share by x%.</text></s>
(d)
<s sid="156"><CoreSc1 advantage="None" conceptID="Obs21" novelty="None" type="Obs"/><text>Decrease outgoing bandwidth share by x%.</text></s>
(e)
Increase memory by x%.
(f)
Decrease memory by x%.
(g)
<s sid="157"><CoreSc1 advantage="None" conceptID="Obs22" novelty="None" type="Obs"/><text>Add allocated storage by x%.</text></s>
(h)
<s sid="158"><CoreSc1 advantage="None" conceptID="Obs23" novelty="None" type="Obs"/><text>Remove allocated storage by x%.</text></s>
(i)
<s sid="159"><CoreSc1 advantage="None" conceptID="Obs24" novelty="None" type="Obs"/><text>Increase CPU share by x%.</text></s>
(j)
<s sid="160"><CoreSc1 advantage="None" conceptID="Obs25" novelty="None" type="Obs"/><text>Decrease CPU share by x%.</text></s>
(k)
<s sid="161"><CoreSc1 advantage="None" conceptID="Obs26" novelty="None" type="Obs"/><text>Outsource (move VM) to other Cloud.</text></s>
(l)
<s sid="162"><CoreSc1 advantage="None" conceptID="Res30" novelty="None" type="Res"/><text>Insource (accept VM) from other Cloud.</text></s>
(m)
<s sid="163"><CoreSc1 advantage="None" conceptID="Res31" novelty="None" type="Res"/><text>Migrate VM to different PM.</text></s>
3.
<s sid="164"><CoreSc1 advantage="None" conceptID="Res32" novelty="None" type="Res"/><text>for physical machines (computing nodes): (a)</text></s>
Add x computing nodes.
(b)
Remove x computing nodes.
4.
Do nothing.
<s sid="165"><CoreSc1 advantage="None" conceptID="Res33" novelty="None" type="Res"/><text>For an application, under &quot;increase incoming bandwidth share&quot; we understand to increase the application's share of all the available incoming bandwidth of a VM, and for a VM the share relates to all the available incoming bandwidth of a PM.</text></s>
<s sid="166"><CoreSc1 advantage="None" conceptID="Res34" novelty="None" type="Res"/><text>The idea of bandwidth sharing is a common idea in network systems as described in [36].</text></s>
<s sid="167"><CoreSc1 advantage="None" conceptID="Res35" novelty="None" type="Res"/><text>Similar arguments account for outgoing bandwidth or CPU share.</text></s>
<s sid="168"><CoreSc1 advantage="None" conceptID="Con3" novelty="None" type="Con"/><text>We then group these actions into so called escalation levels that we define in Table 1.</text></s>
<s sid="169"><CoreSc1 advantage="None" conceptID="Con4" novelty="None" type="Con"/><text>The idea is that every problem that occurs should be solved on the lowest escalation level.</text></s>
<s sid="170"><CoreSc1 advantage="None" conceptID="Con5" novelty="None" type="Con"/><text>Only if this is not possible, the problem is tried to be solved on the next level, and again, if this fails, on the next one, and so on.</text></s>
<s sid="171"><CoreSc1 advantage="None" conceptID="Con6" novelty="None" type="Con"/><text>The levels are ordered in a way such that lower levels offer faster and more local solutions than higher ones.</text></s>
<s sid="172"><CoreSc1 advantage="None" conceptID="Hyp2" novelty="None" type="Hyp"/><text>At every level it has to be decided, whether the proposed action should be executed or not, because it is important to know when to do nothing, since every reallocation action is time and energy consuming.</text></s>
<s sid="173"><CoreSc1 advantage="None" conceptID="Hyp3" novelty="None" type="Hyp"/><text>In fact, for every level there is the possibility not to execute the proposed action.</text></s>
<s sid="174"><CoreSc1 advantage="None" conceptID="Hyp4" novelty="None" type="Hyp"/><text>If the proposed action is not executed, then the decision-making process will stop and not evaluate whether the next escalation level should be considered or not.</text></s>
<s sid="175"><CoreSc1 advantage="None" conceptID="Res36" novelty="None" type="Res"/><text>The first escalation level (&quot;change VM configuration&quot;) works locally on a PM and tries to change the amount of storage or memory, e.g., that is allocated to the VM from the PM resources.</text></s>
<s sid="176"><CoreSc1 advantage="None" conceptID="Res37" novelty="None" type="Res"/><text>Then, migrating applications (escalation level 2) is more lightweight than migrating VMs and turning PMs on/off (escalation levels 3 and 4).</text></s>
<s sid="177"><CoreSc1 advantage="None" conceptID="Res38" novelty="None" type="Res"/><text>For all three escalation levels already the whole system state has to be taken into account to find an optimal solution.</text></s>
<s sid="178"><CoreSc1 advantage="None" conceptID="Con7" novelty="None" type="Con"/><text>The problem stemming from escalation level 3 alone can be formulated into a binary integer problem (BIP), which is known to be NP-complete [37].</text></s>
<s sid="179"><CoreSc1 advantage="None" conceptID="Res39" novelty="None" type="Res"/><text>The proof is out of scope for this paper, but a similar approach can be seen in [12].</text></s>
<s sid="180"><CoreSc1 advantage="None" conceptID="Res40" novelty="None" type="Res"/><text>The last escalation level has least locality and greatest complexity, since the capacity of other Cloud infrastructures have to be taken into account, too, and negotiations have to be started with them as well.</text></s>
<s sid="181"><CoreSc1 advantage="None" conceptID="Con8" novelty="None" type="Con"/><text>Also the rule-based approach benefits from this hierarchical action level model, because it provides a salience concept for contradicting rules.</text></s>
<s sid="182"><CoreSc1 advantage="None" conceptID="Res41" novelty="None" type="Res"/><text>Without this concept it would be troublesome to determine which of the actions, e.g., &quot;Power on additional PM with extra storage and migrate VM to this PM&quot;, &quot;Increase storage for VM by 10%&quot; or &quot;Migrate application to another VM with more storage&quot; should be executed, if a certain threshold for allocated storage has been exceeded.</text></s>
<s sid="183"><CoreSc1 advantage="None" conceptID="Obs27" novelty="None" type="Obs"/><text>The proposed KM approaches will present a solution for escalation level 1.</text></s>
<s sid="184"><CoreSc1 advantage="None" conceptID="Obs28" novelty="None" type="Obs"/><text>Fig. 2 visualizes the escalation levels from Table 1 before and after actions are executed.</text></s>
<s sid="185"><CoreSc1 advantage="None" conceptID="Obs29" novelty="None" type="Obs"/><text>Fig. 2(a) shows applications App1 and App2 deployed on VM1 that is itself deployed on PM1, whereas App3 runs on VM2 running on PM2.</text></s>
<s sid="186"><CoreSc1 advantage="None" conceptID="Obs30" novelty="None" type="Obs"/><text>Fig. 2(b) shows example actions for all five escalation levels.</text></s>
<s sid="187"><CoreSc1 advantage="None" conceptID="Res42" novelty="None" type="Res"/><text>The legend numbers correspond to the respective numbering of the escalation levels. •</text></s>
<s sid="188"><CoreSc1 advantage="None" conceptID="Res43" novelty="None" type="Res"/><text>Escalation level 1: At first, the autonomic manager considers whether it should change VM configuration or not.</text></s>
<s sid="189"><CoreSc1 advantage="None" conceptID="Res44" novelty="None" type="Res"/><text>Actions (1) show that the autonomic manager decided to change the VM configuration; VM1 is being up-sized and VM2 being down-sized.</text></s>
•
<s sid="190"><CoreSc1 advantage="None" conceptID="Res45" novelty="None" type="Res"/><text>Escalation level 2: If VM reconfiguration has taken place, or if it has been recommended, but cannot be fulfilled yet, because some resource cannot be increased anymore due to the constraints of the PM hosting the VM, in level 2 the autonomic manager considers migrating the application to another larger VM that fulfills the required specifications from level 1.</text></s>
<s sid="191"><CoreSc1 advantage="None" conceptID="Res46" novelty="None" type="Res"/><text>So if, e.g., provided storage needs to be increased from 500 to 800 GB, but only 200 GB are available on the respective VM, then the application has to be migrated to a VM that has at least the same resources as the current one plus the remaining 100 GB of storage.</text></s>
<s sid="192"><CoreSc1 advantage="None" conceptID="Res47" novelty="None" type="Res"/><text>Action (2) shows the re-deployment of App2 to VM2.</text></s>
<s sid="193"><CoreSc1 advantage="None" conceptID="Con9" novelty="None" type="Con"/><text>Due to possible confinements of some applications to certain VMs, e.g., a user deployed several applications that need to work together on one VM, this escalation might be skipped in some scenarios.</text></s>
<s sid="194"><CoreSc1 advantage="None" conceptID="Con10" novelty="None" type="Con"/><text>Also for Infrastructure as a Service (IaaS) providers, who directly provide the VMs without caring about the applications running on them, this escalation level is omitted.</text></s>
•
<s sid="195"><CoreSc1 advantage="None" conceptID="Con11" novelty="None" type="Con"/><text>Escalation level 3: If there is no appropriate VM available in level 2, or if level 2 is skipped and VM configurations have been recommended in level 1, in level 3 the autonomic manager considers creating a new VM on an appropriate PM or migrating the VM to a PM that has enough available resources.</text></s>
<s sid="196"><CoreSc1 advantage="None" conceptID="Res48" novelty="None" type="Res"/><text>Action (3) shows the re-deployment of VM2 to PM1.</text></s>
•
<s sid="197"><CoreSc1 advantage="None" conceptID="Res49" novelty="None" type="Res"/><text>Escalation level 4: Again, if there is no appropriate PM available in level 3, the autonomic manager suggests turning on a new PM (or turning it off if the last VM was emigrated from this PM) in level 4.</text></s>
<s sid="198"><CoreSc1 advantage="None" conceptID="Res50" novelty="None" type="Res"/><text>Action (4) shows powering on a new PM (PM3).</text></s>
•
<s sid="199"><CoreSc1 advantage="None" conceptID="Res51" novelty="None" type="Res"/><text>Escalation level 5: Finally, the last escalation level 5 tries to outsource the application to another Cloud provider as explained, e.g., in the Reservoir project [38].</text></s>
<s sid="200"><CoreSc1 advantage="None" conceptID="Res52" novelty="None" type="Res"/><text>Action (5) outsources App3 to another Cloud provider.</text></s>
<s sid="201"><CoreSc1 advantage="None" conceptID="Res53" novelty="None" type="Res"/><text>For an IaaS provider omitting escalation level 2, the sequence of these escalation levels is quite obvious: If VM sizes are not changed in escalation level 1, there is no need to trigger escalation level 3 as VMs have not changed, and no better allocation of VMs to PMs can be found, if the previous one was already optimal.</text></s>
<s sid="202"><CoreSc1 advantage="None" conceptID="Res54" novelty="None" type="Res"/><text>However, if VM sizes were changed, escalation level 3 can still come to the conclusion that VM migrations are unnecessary.</text></s>
<s sid="203"><CoreSc1 advantage="None" conceptID="Res55" novelty="None" type="Res"/><text>On the other hand, if VM migrations were recommended, some PMs could be then turned off in escalation level 4.</text></s>
<s sid="204"><CoreSc1 advantage="None" conceptID="Res56" novelty="None" type="Res"/><text>Similarly, if no migrations were triggered, thinking about turning off PMs is unnecessary, as no PMs run idle now that have not been running idle before.</text></s>
<s sid="205"><CoreSc1 advantage="None" conceptID="Con12" novelty="None" type="Con"/><text>Finally, if all the previous actions were successfully executed without the help of another Cloud provider, there is no need to consider outsourcing applications.</text></s>
<s sid="206"><CoreSc1 advantage="None" conceptID="Con13" novelty="None" type="Con"/><text>Only if the last possibility failed, outsourcing applications should be considered.</text></s>
<s sid="207"><CoreSc1 advantage="None" conceptID="Con14" novelty="None" type="Con"/><text>(Other business incentives for outsourcing applications such as cheaper execution costs in other Clouds, etc., are not considered here.) For providers of other Cloud delivery models such as SaaS or PaaS, the sequence of placing application migration after VM reconfiguration is arguable; another model could also propose an inverse sequence for these two levels.</text></s>
<s sid="208"><CoreSc1 advantage="None" conceptID="Obj38" novelty="None" type="Obj"/><text>Implementing the knowledge management phase</text></s>
<s sid="209"><CoreSc1 advantage="None" conceptID="Obj39" novelty="None" type="Obj"/><text>In this section we present the implementation of the Knowledge Management phase using CBR and a rule-based approach.</text></s>
Prerequisites
<s sid="210"><CoreSc1 advantage="None" conceptID="Obs31" novelty="None" type="Obs"/><text>This subsection subsumes all the common assumptions for both approaches.</text></s>
<s sid="211"><CoreSc1 advantage="None" conceptID="Res57" novelty="None" type="Res"/><text>We assume that customers deploy applications on an IaaS Cloud infrastructure.</text></s>
<s sid="212"><CoreSc1 advantage="None" conceptID="Res58" novelty="None" type="Res"/><text>SLOs are defined within an SLA between the customer and the Cloud provider for every application.</text></s>
<s sid="213"><CoreSc1 advantage="None" conceptID="Res59" novelty="None" type="Res"/><text>Furthermore, there is a 1:1 relationship between applications and VMs.</text></s>
<s sid="214"><CoreSc1 advantage="None" conceptID="Res60" novelty="None" type="Res"/><text>One VM runs on exactly one PM, but one PM can host an arbitrary number of VMs with respect to supplied vs. demanded resource capacities.</text></s>
<s sid="215"><CoreSc1 advantage="None" conceptID="Met19" novelty="None" type="Met"/><text>After allocating VMs with an initial capacity (by estimating initial resource demand) for every application, we continuously monitor actually used resources and re-allocate resources according to these measurements.</text></s>
<s sid="216"><CoreSc1 advantage="None" conceptID="Res61" novelty="None" type="Res"/><text>For tackling the resource allocation for VMs, we need to define how measured, provided and agreed values interrelate, and what actually constitutes an SLA violation.</text></s>
<s sid="217"><CoreSc1 advantage="None" conceptID="Res62" novelty="None" type="Res"/><text>An example is provided in Table 2.</text></s>
<s sid="218"><CoreSc1 advantage="None" conceptID="Res63" novelty="None" type="Res"/><text>First, we deal with the measured value (1), which represents the amount of a specific resource that is currently used by the customer.</text></s>
<s sid="219"><CoreSc1 advantage="None" conceptID="Res64" novelty="None" type="Res"/><text>Second, there is the amount of allocated resource (2) that can be used by the customer, i.e., that is allocated to the VM which hosts the application.</text></s>
<s sid="220"><CoreSc1 advantage="None" conceptID="Res65" novelty="None" type="Res"/><text>Third, there is the SLO agreed in the SLA (3).</text></s>
<s sid="221"><CoreSc1 advantage="None" conceptID="Res66" novelty="None" type="Res"/><text>A violation therefore occurs, if less is provided (2) than the customer utilizes (or wants to utilize) (1) with respect to the limits set in the SLA (3).</text></s>
<s sid="222"><CoreSc1 advantage="None" conceptID="Res67" novelty="None" type="Res"/><text>Considering Table 2 we can see that rows 1 and 3 do not represent violations, whereas row 2 does represent an SLA violation.</text></s>
<s sid="223"><CoreSc1 advantage="None" conceptID="Con15" novelty="None" type="Con"/><text>In order to save resources we envision a speculative approach: Can we allocate less than agreed, but still more than used in order not to violate an SLA? The most demanding questions are how much can we lower the provisioning of resource without risking an SLA violation.</text></s>
<s sid="224"><CoreSc1 advantage="None" conceptID="Con16" novelty="None" type="Con"/><text>This heavily depends on the characteristics of the workload of an application, especially its volatility.</text></s>
Case Based Reasoning
<s sid="225"><CoreSc1 advantage="None" conceptID="Con17" novelty="None" type="Con"/><text>Case Based Reasoning is the process of solving problems based on past experience [39].</text></s>
<s sid="226"><CoreSc1 advantage="None" conceptID="Con18" novelty="None" type="Con"/><text>In more detail, it tries to solve a case (a formatted instance of a problem) by looking for similar cases from the past and reusing the solutions of these cases to solve the current one.</text></s>
<s sid="227"><CoreSc1 advantage="None" conceptID="Res68" novelty="None" type="Res"/><text>In general, a typical CBR cycle consists of the following phases assuming that a new case was just received: 1.</text></s>
<s sid="228"><CoreSc1 advantage="None" conceptID="Res69" novelty="None" type="Res"/><text>Retrieve the most similar case or cases to the new one.</text></s>
2.
<s sid="229"><CoreSc1 advantage="None" conceptID="Con19" novelty="None" type="Con"/><text>Reuse the information and knowledge in the similar case(s) to solve the problem.</text></s>
3.
Revise the proposed solution.
4.
<s sid="230"><CoreSc1 advantage="None" conceptID="Con20" novelty="None" type="Con"/><text>Retain the parts of this experience likely to be useful for future problem solving.</text></s>
<s sid="231"><CoreSc1 advantage="None" conceptID="Res70" novelty="None" type="Res"/><text>(Store new case and found solution in KB.)</text></s>
<s sid="232"><CoreSc1 advantage="None" conceptID="Res71" novelty="None" type="Res"/><text>To adapt CBR to our problem, three issues have to be solved.</text></s>
<s sid="233"><CoreSc1 advantage="None" conceptID="Res72" novelty="None" type="Res"/><text>First, it has to be decided how to format an instance of the problem.</text></s>
<s sid="234"><CoreSc1 advantage="None" conceptID="Res73" novelty="None" type="Res"/><text>Second, it has to be decided when two cases are similar.</text></s>
<s sid="235"><CoreSc1 advantage="None" conceptID="Res74" novelty="None" type="Res"/><text>Third, good reactions have to be distinguished from bad reactions.</text></s>
<s sid="236"><CoreSc1 advantage="None" conceptID="Mod2" novelty="None" type="Mod"/><text>As to the first problem we assume that each SLA has a unique identifier id and a collection of SLOs.</text></s>
<s sid="237"><CoreSc1 advantage="None" conceptID="Mod3" novelty="None" type="Mod"/><text>SLOs are predicates of the form (1)SLOid(xi,comp,πi)with comp∈{&lt;,≤,&gt;,≥,=}, where xi∈P represents the parameter name for i=1,…,nid,πi the parameter goal, and comp the appropriate comparison operator.</text></s>
<s sid="238"><CoreSc1 advantage="None" conceptID="Mod4" novelty="None" type="Mod"/><text>Then, a CBR case c is defined as (2)c=(id,m1,p1,m2,p2,…,mnid,pnid), where id represents the SLA id, and mi and pi the measured (m) and provided (p) value of the SLA parameter xi, respectively.</text></s>
<s sid="239"><CoreSc1 advantage="None" conceptID="Mod5" novelty="None" type="Mod"/><text>To use the SLA parameters storage and incoming bandwidth for example, a typical use case looks like this: SLA id=1 with SLO1 (&quot;Storage&quot;, ≥, 1000) and SLO1 (&quot;Bandwidth&quot;, ≥, 50.0).</text></s>
<s sid="240"><CoreSc1 advantage="None" conceptID="Mod6" novelty="None" type="Mod"/><text>A corresponding case received by the measurement component is therefore written as c=(1,500,700,20.0,30.0).</text></s>
<s sid="241"><CoreSc1 advantage="None" conceptID="Res75" novelty="None" type="Res"/><text>A result case rc=(c-,ac,c+,utility) includes the initial case c-, the executed action ac, the resulting case c+ measured some time interval later, which corresponds to one iteration in the simulation engine, and the calculated utility described later.</text></s>
<s sid="242"><CoreSc1 advantage="None" conceptID="Res76" novelty="None" type="Res"/><text>In order to give the KB some knowledge about what to do in specific situations, several initial cases are stored in the KB as described in [7] in more detail.</text></s>
<s sid="243"><CoreSc1 advantage="None" conceptID="Res77" novelty="None" type="Res"/><text>Secondly, to define similarity between two cases is not straightforward, because due to their symmetric nature Euclidean distances, e.g., do not recognize the difference between over- and under-provisioning.</text></s>
<s sid="244"><CoreSc1 advantage="None" conceptID="Mod7" novelty="None" type="Mod"/><text>Following the principle of semantic similarity from [40] for the summation part this leads to the following equation (3)d(c-,c+)=min(wid,|id--id+|)+∑x∈Pwx|(px--mx-)-(px+-mx+)maxx-minx|, where w=(wid,wx1,…,wxn) is the weight vector; wid is the weight for non-identical SLAs; wx is the weight, and maxx and minx the maximum and minimum values of differences px-mx for parameter x.</text></s>
<s sid="245"><CoreSc1 advantage="None" conceptID="Obj40" novelty="None" type="Obj"/><text>As far as the third issue is concerned, every action is evaluated by its impact on violations and utilization.</text></s>
<s sid="246"><CoreSc1 advantage="None" conceptID="Res78" novelty="None" type="Res"/><text>This way CBR is able to learn whether an action was appropriate for a specific measurement or not.</text></s>
<s sid="247"><CoreSc1 advantage="None" conceptID="Res79" novelty="None" type="Res"/><text>The utility of an action is calculated by comparing the initial case c- with the resulting final case c+.</text></s>
<s sid="248"><CoreSc1 advantage="None" conceptID="Res80" novelty="None" type="Res"/><text>The utility function is composed by a violation and a utilization term weighed by the factor 0≤α≤1: (4)utility=∑x∈Pviolation(x)+α⋅utilization(x).</text></s>
<s sid="249"><CoreSc1 advantage="None" conceptID="Res81" novelty="None" type="Res"/><text>Higher values for α strengthen the utilization of resources, whereas lower values the non-violation of SLA parameters.</text></s>
<s sid="250"><CoreSc1 advantage="None" conceptID="Res82" novelty="None" type="Res"/><text>We further note that c(x) describes a case only with respect to parameter x.</text></s>
<s sid="251"><CoreSc1 advantage="None" conceptID="Res83" novelty="None" type="Res"/><text>E.g., we say that a violation has occurred in c(x), when in case c the parameter x was violated.</text></s>
<s sid="252"><CoreSc1 advantage="None" conceptID="Mod8" novelty="None" type="Mod"/><text>We define the violation function for every parameter x as follows: (5)violation(x)={1,No violation occurred in c+(x),but in c-(x)1/2,No violation occurred in c+(x)and c-(x)-1/2Violation occurred in c+(x) and c-(x)-1Violation occurred in c+(x),but not in c-(x).</text></s>
<s sid="253"><CoreSc1 advantage="None" conceptID="Mod9" novelty="None" type="Mod"/><text>The utilization function is calculated by comparing the used resources to the provided ones.</text></s>
<s sid="254"><CoreSc1 advantage="None" conceptID="Mod10" novelty="None" type="Mod"/><text>We define the distance δ(x,y)=|x-y|, and utilization for every parameter as (6)utilization(x)={1,δ(px-,mx-)&gt;δ(px+,ux+)-1,δ(px-,mx-)&lt;δ(px+,ux+)0,otherwise . A utilization utility of 1 is retrieved if less over-provisioning of resources takes place in the final case than in the initial one, and a utilization utility of -1 if more over-provisioning of resources takes place in the final case than in the initial one.</text></s>
<s sid="255"><CoreSc1 advantage="None" conceptID="Res84" novelty="None" type="Res"/><text>The whole CBR process works as follows: Before the first iteration, we store the mentioned initial cases consisting of an initial measurement, an action and a resulting measurement.</text></s>
<s sid="256"><CoreSc1 advantage="None" conceptID="Obj41" novelty="None" type="Obj"/><text>Then, when CBR receives a new measurement, this measurement is compared to all cases in the KB.</text></s>
<s sid="257"><CoreSc1 advantage="None" conceptID="Met20" novelty="None" type="Met"/><text>From the set of closest cases grouped by a clustering algorithm we choose the one with the highest utility and execute exactly the same action as in the chosen case.</text></s>
<s sid="258"><CoreSc1 advantage="None" conceptID="Met21" novelty="None" type="Met"/><text>Afterwards, this action, the resulting measurement and the utility of the action is added to the initial measurement, and stored as a complete case.</text></s>
Rule-based approach
<s sid="259"><CoreSc1 advantage="None" conceptID="Res85" novelty="None" type="Res"/><text>For the rule-based approach we first introduce several resource policy modes to reflect the overall utilization of the system in the VM configuration rules.</text></s>
<s sid="260"><CoreSc1 advantage="None" conceptID="Con21" novelty="None" type="Con"/><text>Dealing with SLA-bound resource management, where resource usage is paid for on a &quot;pay-as-you-go&quot; basis with SLOs that guarantee a minimum capacity of these resources as described above, raises the question, whether the Cloud provider should allow the consumer to use more resources than agreed.</text></s>
<s sid="261"><CoreSc1 advantage="None" conceptID="Con22" novelty="None" type="Con"/><text>We will refer to this behavior as over-consumption.</text></s>
<s sid="262"><CoreSc1 advantage="None" conceptID="Con23" novelty="None" type="Con"/><text>Since the consumer will pay for every additional resource, it should be in the Cloud provider's interest to allow over-consumption as long as this behavior does not endanger the SLAs of other consumers.</text></s>
<s sid="263"><CoreSc1 advantage="None" conceptID="Res86" novelty="None" type="Res"/><text>Thus, Cloud providers should not allow over-consumption when the resulting penalties they have to pay are higher than the expected revenue from over-consumption.</text></s>
<s sid="264"><CoreSc1 advantage="None" conceptID="Obj42" novelty="None" type="Obj"/><text>To tackle this problem, we introduce five policy modes for every resource that describe the interaction of the five escalation levels.</text></s>
<s sid="265"><CoreSc1 advantage="None" conceptID="Obs32" novelty="None" type="Obs"/><text>As can be seen in Table 3 the policy modes are green, green-orange, orange, orange-red and red.</text></s>
<s sid="266"><CoreSc1 advantage="None" conceptID="Mod11" novelty="None" type="Mod"/><text>They range from low utilization of the system with lots of free resources left (policy mode green) over a scarce resource situation (policy mode orange) to an extremely tight resource situation (policy mode red), where it is impossible to fulfill all SLAs to their full extent and decisions have to be made which SLAs to deliberately break and which applications to outsource.</text></s>
<s sid="267"><CoreSc1 advantage="None" conceptID="Mod12" novelty="None" type="Mod"/><text>In order to know whether a resource r is in danger of under-provisioning or already is under-provisioned, or whether it is over-provisioned, we calculate the current utilization utr=userprr×100, where user and prr signify how much of a resource r was used and provided, respectively, and divide the percentage range into three regions using the two &quot;threat thresholds&quot; TTlowr and TThighr: •</text></s>
<s sid="268"><CoreSc1 advantage="None" conceptID="Res87" novelty="None" type="Res"/><text>Region -1: Danger of under-provisioning, or under-provisioning (&gt;TThighr).</text></s>
•
<s sid="269"><CoreSc1 advantage="None" conceptID="Res88" novelty="None" type="Res"/><text>Region 0: Well provisioned (≤TThighrand≥TTlowr).</text></s>
•
Region +1: Over-Provisioning (&lt;TTlowr).
<s sid="270"><CoreSc1 advantage="None" conceptID="Res89" novelty="None" type="Res"/><text>The idea of this rule-based design is that the ideal value that we call target value tv(r) for utilization of a resource r is exactly in the center of region 0.</text></s>
<s sid="271"><CoreSc1 advantage="None" conceptID="Res90" novelty="None" type="Res"/><text>So, if the utilization value after some measurement leaves this region by using more (Region -1) or less resources (Region +1), then we reset the utilization to the target value, i.e., we increase or decrease allocated resources so that the utilization is again at tv(r)=TTlowr+TThighr2%.</text></s>
<s sid="272"><CoreSc1 advantage="None" conceptID="Res91" novelty="None" type="Res"/><text>As long as the utilization value stays in region 0, no action will be executed.</text></s>
<s sid="273"><CoreSc1 advantage="None" conceptID="Res92" novelty="None" type="Res"/><text>E.g., for r=storage,TTlowr=60%, and TThighr=80%, the target value would be tv(r)=70%.</text></s>
<s sid="274"><CoreSc1 advantage="None" conceptID="Obs33" novelty="None" type="Obs"/><text>Fig. 3 shows the regions and measurements (expressed as utilization of a certain resource) at time steps t1,t2,…,t6.</text></s>
<s sid="275"><CoreSc1 advantage="None" conceptID="Res93" novelty="None" type="Res"/><text>At t1 the utilization of the resource is in Region -1, because it is in danger of a violation.</text></s>
<s sid="276"><CoreSc1 advantage="None" conceptID="Res94" novelty="None" type="Res"/><text>Thus, the KB recommends to increase the resource such that at the next iteration t2 the utilization is at the center of Region 0, which equals the target value.</text></s>
<s sid="277"><CoreSc1 advantage="None" conceptID="Res95" novelty="None" type="Res"/><text>At time steps t3 and t4 utilization stays in the center region and consequently, no action is required.</text></s>
<s sid="278"><CoreSc1 advantage="None" conceptID="Res96" novelty="None" type="Res"/><text>At t5, the resource is under-utilized and so the KB recommends the decrease of the resource to tv(r), which is attained at t6.</text></s>
<s sid="279"><CoreSc1 advantage="None" conceptID="Res97" novelty="None" type="Res"/><text>Additionally, if over-provisioning is allowed in the current policy mode, then the adjustment will always be executed as described regardless of what limit was agreed in the SLA.</text></s>
<s sid="280"><CoreSc1 advantage="None" conceptID="Res98" novelty="None" type="Res"/><text>On the other hand, if over-provisioning is not allowed in the current policy mode, then the rule will allocate at most as much as agreed in the SLA (SLOr).</text></s>
<s sid="281"><CoreSc1 advantage="None" conceptID="Obs34" novelty="None" type="Obs"/><text>The concept of a rule increasing resource r is depicted in Fig. 4.</text></s>
<s sid="282"><CoreSc1 advantage="None" conceptID="Res99" novelty="None" type="Res"/><text>The rule executes if the current utilization utr and the predicted utilization utpredictedr of the next iteration (cf.</text></s>
<s sid="283"><CoreSc1 advantage="None" conceptID="Res100" novelty="None" type="Res"/><text>next paragraph) both exceed TThighr (line 2).</text></s>
<s sid="284"><CoreSc1 advantage="None" conceptID="Res101" novelty="None" type="Res"/><text>Depending on what policy level is active the rule either sets the provided resource prr to the target value tv(r) for policy levels green and green-orange (line 3) or to at most what was agreed in the SLA (SLOr) plus a certain percentage ϵ to account for rounding errors when calculating the target value in policy levels orange, orange-red and red (line 5).</text></s>
<s sid="285"><CoreSc1 advantage="None" conceptID="Obs35" novelty="None" type="Obs"/><text>A similar rule scheme for decreasing a resource can be seen in Fig. 5.</text></s>
<s sid="286"><CoreSc1 advantage="None" conceptID="Res102" novelty="None" type="Res"/><text>The main difference is that it does not distinguish between policy modes and that it sets the provisioned resource to at least a minimum value minPrr, which may be 0, that is needed to keep the application alive (line 4).</text></s>
<s sid="287"><CoreSc1 advantage="None" conceptID="Res103" novelty="None" type="Res"/><text>The rule is executed if the current utilization utr and the predicted utilization utpredictedr of the next iteration both lie below TTlowr (line 2).</text></s>
<s sid="288"><CoreSc1 advantage="None" conceptID="Res104" novelty="None" type="Res"/><text>A large enough span between the thresholds TTlowr and TThighr helps to prevent oscillations of repeatedly increasing and decreasing the same resource.</text></s>
<s sid="289"><CoreSc1 advantage="None" conceptID="Res105" novelty="None" type="Res"/><text>However, to further reduce the risk of oscillations, we suggest to calculate a prediction for the next value based on the latest measurements.</text></s>
<s sid="290"><CoreSc1 advantage="None" conceptID="Res106" novelty="None" type="Res"/><text>Thus, an action is only invoked when the current AND the predicted measurement exceed the respective TT.</text></s>
<s sid="291"><CoreSc1 advantage="None" conceptID="Res107" novelty="None" type="Res"/><text>So, especially when only one value exceeds the TT, no action is executed.</text></s>
<s sid="292"><CoreSc1 advantage="None" conceptID="Res108" novelty="None" type="Res"/><text>The rules have been implemented using the Java rule engine Drools [41].</text></s>
<s sid="293"><CoreSc1 advantage="None" conceptID="Res109" novelty="None" type="Res"/><text>The Drools engine sets up a knowledge session consisting of different rules and a working memory.</text></s>
<s sid="294"><CoreSc1 advantage="None" conceptID="Res110" novelty="None" type="Res"/><text>Rules get activated when specific elements are inserted into the working memory such that the conditional &quot;when&quot; part evaluates to true.</text></s>
<s sid="295"><CoreSc1 advantage="None" conceptID="Res111" novelty="None" type="Res"/><text>Activated rules are then triggered by the simulation engine.</text></s>
<s sid="296"><CoreSc1 advantage="None" conceptID="Res112" novelty="None" type="Res"/><text>In our case, the simulation engine inserts measurements and SLAs of applications into the working memory.</text></s>
<s sid="297"><CoreSc1 advantage="None" conceptID="Con24" novelty="None" type="Con"/><text>Different policy modes will load slightly modified rules into the Drools engine and thus achieve a high adaptability of the KM system reacting to the general performance of the Cloud infrastructure.</text></s>
<s sid="298"><CoreSc1 advantage="None" conceptID="Con25" novelty="None" type="Con"/><text>As opposed to the CBR approach in [7], the rule-based approach is able to fire more than one action at the same iteration, which inherently increases the flexibility of the system.</text></s>
<s sid="299"><CoreSc1 advantage="None" conceptID="Mod13" novelty="None" type="Mod"/><text>Without loss of generality we can assume that one application runs on one VM (several applications' SLAs can be aggregated to form one VM SLA) and we assume the more interesting case of policy modes orange, orange-red or red, where over-provisioning is not allowed.</text></s>
<s sid="300"><CoreSc1 advantage="None" conceptID="Obs36" novelty="None" type="Obs"/><text>Listing 1 shows the rule to increase parameter storage formulated in the Drools language following the pattern presented in Fig. 4.</text></s>
<s sid="301"><CoreSc1 advantage="None" conceptID="Obs37" novelty="None" type="Obs"/><text>Line 1 defines the name of the rule that is split into a condition part (when, lines 2-12) and an execution part (then, lines 13-17).</text></s>
<s sid="302"><CoreSc1 advantage="None" conceptID="Res113" novelty="None" type="Res"/><text>Line 4 tries to find the SLA of an application, and stores its id in $slaID and the SLA into $slaApp.</text></s>
<s sid="303"><CoreSc1 advantage="None" conceptID="Exp1" novelty="None" type="Exp"/><text>Line 6 looks for a set of actions for this $slaID where no storage action has been added yet (storage == false) in order to avoid contradicting actions for storage for one measurement.</text></s>
<s sid="304"><CoreSc1 advantage="None" conceptID="Res114" novelty="None" type="Res"/><text>Line 8 searches for a measurement for the appropriate VM (vmID == $slaID) that has been inserted into working memory that is no prediction ($prediction == false) and where the percentage of utilized storage exceeds TThighr (storage_utilized&gt;storage_HighTT), and stores used and provided values into $s_used and $s_provided, respectively.</text></s>
<s sid="305"><CoreSc1 advantage="None" conceptID="Res115" novelty="None" type="Res"/><text>The predicted measurement for the next iteration is handled similarly in line 10.</text></s>
<s sid="306"><CoreSc1 advantage="None" conceptID="Res116" novelty="None" type="Res"/><text>Finally, line 12 checks whether provided storage is still below the agreed value in the SLA.</text></s>
<s sid="307"><CoreSc1 advantage="None" conceptID="Res117" novelty="None" type="Res"/><text>This is done, because in policy modes orange to red over-consumption is prohibited.</text></s>
<s sid="308"><CoreSc1 advantage="None" conceptID="Res118" novelty="None" type="Res"/><text>The rules for policy modes green and green-orange would omit this line.</text></s>
<s sid="309"><CoreSc1 advantage="None" conceptID="Res119" novelty="None" type="Res"/><text>Now, if all these conditions are met, the rule gets activated.</text></s>
<s sid="310"><CoreSc1 advantage="None" conceptID="Obs38" novelty="None" type="Obs"/><text>When fired, line 15 calculates the new value for prr as explained in Fig. 4.</text></s>
<s sid="311"><CoreSc1 advantage="None" conceptID="Obs39" novelty="None" type="Obs"/><text>This line (as line 12) would also be altered for policy modes green and green-orange.</text></s>
<s sid="312"><CoreSc1 advantage="None" conceptID="Res120" novelty="None" type="Res"/><text>Line 17 then modifies the action container $as and inserts the appropriate storage action with the value for provided storage to be set.</text></s>
<s sid="313"><CoreSc1 advantage="None" conceptID="Obs40" novelty="None" type="Obs"/><text>Other rules follow the same pattern as described here and in Fig. 4 for rules increasing resource allocations and in Fig. 5 for rules decreasing resource allocations.</text></s>
Evaluation and comparison
<s sid="314"><CoreSc1 advantage="None" conceptID="Obj43" novelty="None" type="Obj"/><text>In this section we evaluate the two presented approaches with several different synthetic and real-world workload data.</text></s>
<s sid="315"><CoreSc1 advantage="None" conceptID="Obj44" novelty="None" type="Obj"/><text>For this purpose, we present a KM-agnostic simulation engine that implements the autonomic control loop and simulates executed actions and evaluates their quality responding to the workload data at stake.</text></s>
<s sid="316"><CoreSc1 advantage="None" conceptID="Obj45" novelty="None" type="Obj"/><text>Simulation engine implementing the MAPE-K loop</text></s>
<s sid="317"><CoreSc1 advantage="None" conceptID="Goa15" novelty="None" type="Goa"/><text>The goal of the simulation engine is to evaluate the quality of a KM system with respect to the number of SLA violations, the utilization of the resources and the number of required reallocation actions.</text></s>
<s sid="318"><CoreSc1 advantage="None" conceptID="Con26" novelty="None" type="Con"/><text>Furthermore, the simulation engine serves as an evaluation tool for any KM technique in the field of Cloud Computing, as long as it can implement the two methods of the KB management interface: 1.</text></s>
<s sid="319"><CoreSc1 advantage="None" conceptID="Res121" novelty="None" type="Res"/><text>public void receiveMeasurement(int slaID, String[] provided,</text></s>
<s sid="320"><CoreSc1 advantage="None" conceptID="Res122" novelty="None" type="Res"/><text>String[] measurements, List&lt;String&gt; violations); and</text></s>
2.
public Actions recommendAction(int slaID);.
<s sid="321"><CoreSc1 advantage="None" conceptID="Res123" novelty="None" type="Res"/><text>The parameter slaID describes the ID of the SLA that is tied to the specific VM, whose provided and measured values are stored in the arrays provided and measurements, respectively (cf.</text></s>
Section 5.1).
<s sid="322"><CoreSc1 advantage="None" conceptID="Res124" novelty="None" type="Res"/><text>The list violations contains all SLA parameters being violated for the current measurements.</text></s>
<s sid="323"><CoreSc1 advantage="None" conceptID="Res125" novelty="None" type="Res"/><text>The method receiveMeasurement inputs new data into the KB, whereas the method recommendActions outputs an action specific to the current measurement of the specified SLA.</text></s>
<s sid="324"><CoreSc1 advantage="None" conceptID="Res126" novelty="None" type="Res"/><text>The simulation engine traverses all parts of the MAPE-K loop as can be seen in Fig. 6 and described in Section 3.</text></s>
<s sid="325"><CoreSc1 advantage="None" conceptID="Res127" novelty="None" type="Res"/><text>The simulation engine is iteration based, meaning that in one iteration the MAPE-K loop is traversed exactly once.</text></s>
<s sid="326"><CoreSc1 advantage="None" conceptID="Res128" novelty="None" type="Res"/><text>(In reality, one iteration could last from some minutes to about an hour depending on the speed of the measurements, the length of time the decision making takes, and the duration of the execution of the actions, for example migrating a resource intensive VM to another PM.) The Monitoring component receives monitoring information from either synthetic or real-world workload from the current iteration.</text></s>
<s sid="327"><CoreSc1 advantage="None" conceptID="Res129" novelty="None" type="Res"/><text>It forwards the data into the Knowledge base (1).</text></s>
<s sid="328"><CoreSc1 advantage="None" conceptID="Res130" novelty="None" type="Res"/><text>The Knowledge base contains representations of all important objects in the Cloud and their characteristic information.</text></s>
<s sid="329"><CoreSc1 advantage="None" conceptID="Res131" novelty="None" type="Res"/><text>These objects are the running applications, the virtual machines, and the physical machines with the current state of their CPU power, memory, storage, etc., the corresponding SLAs with their SLOs, and information about other Clouds in the same federation.</text></s>
<s sid="330"><CoreSc1 advantage="None" conceptID="Con27" novelty="None" type="Con"/><text>Furthermore, the KB also has representations of the inserted measurements, and the available actions to execute (these have to be pre-defined).</text></s>
<s sid="331"><CoreSc1 advantage="None" conceptID="Con28" novelty="None" type="Con"/><text>Finally, the KB also contains a decision mechanism that interprets the state of available objects in order to recommend a reconfiguration action.</text></s>
<s sid="332"><CoreSc1 advantage="None" conceptID="Con29" novelty="None" type="Con"/><text>This mechanism can be substituted by any KM technique; as already mentioned, we used CBR and a rule-based mechanism.</text></s>
<s sid="333"><CoreSc1 advantage="None" conceptID="Obj46" novelty="None" type="Obj"/><text>The next step in the MAPE loop is the Analysis component, which queries the KB for actions to recommend (for a specific SLA id) (2); these actions are then returned to the analysis component (3).</text></s>
<s sid="334"><CoreSc1 advantage="None" conceptID="Res132" novelty="None" type="Res"/><text>The Planning component schedules the suggested actions, and the Execution component executes them.</text></s>
<s sid="335"><CoreSc1 advantage="None" conceptID="Res133" novelty="None" type="Res"/><text>The changed state configuration of the Cloud objects are automatically reflected in the KB (4).</text></s>
<s sid="336"><CoreSc1 advantage="None" conceptID="Res134" novelty="None" type="Res"/><text>The Monitoring and the Execution components are simulated.</text></s>
<s sid="337"><CoreSc1 advantage="None" conceptID="Res135" novelty="None" type="Res"/><text>This means that the monitoring data is not measured on a real system during the simulation, even though it handles input measured at a real system or synthetic workloads generated beforehand (see Sections 6.3 and 6.4).</text></s>
<s sid="338"><CoreSc1 advantage="None" conceptID="Obs41" novelty="None" type="Obs"/><text>The Execution component updates the object representation of the manipulated objects in the KB, but obviously does not actually manipulate real-world objects.</text></s>
<s sid="339"><CoreSc1 advantage="None" conceptID="Res136" novelty="None" type="Res"/><text>The quality of the decision making can ultimately be judged by the number of occurred SLA violations, resource wastage and the number of needed reallocation actions.</text></s>
Performance indicators
<s sid="340"><CoreSc1 advantage="None" conceptID="Obj47" novelty="None" type="Obj"/><text>The subsequent evaluations will be based on the following performance indicators: violations, utilization, actions, resource allocation efficiency (RAE), costs, and time efficiency.</text></s>
<s sid="341"><CoreSc1 advantage="None" conceptID="Obs42" novelty="None" type="Obs"/><text>Whereas the first three and the last one are rather self-explanatory, costs and RAE need a little more explanation.</text></s>
<s sid="342"><CoreSc1 advantage="None" conceptID="Res137" novelty="None" type="Res"/><text>So violations and actions measure (as a percentage) the amount of occurring violations/actions in relation to all possible violations/actions, and utilization the average utilization over all iterations (and over all SLA parameters, if they are not shown explicitly).</text></s>
<s sid="343"><CoreSc1 advantage="None" conceptID="Res138" novelty="None" type="Res"/><text>Time efficiency measures the average time that is needed to handle one VM in one iteration.</text></s>
<s sid="344"><CoreSc1 advantage="None" conceptID="Res139" novelty="None" type="Res"/><text>For resource allocation efficiency we want to relate violations and utilization.</text></s>
<s sid="345"><CoreSc1 advantage="None" conceptID="Mod14" novelty="None" type="Mod"/><text>The basic is idea is that RAE should equal utilization (100%-w, where w stands for wastage, see below) if no violations occur (p=0%, where p stands for penalty, see below), equal 0 if the violation rate is at 100%, and follow a linear decrease in between.</text></s>
Thus, we define (7)RAE=(100-w)(100-p)100.
<s sid="346"><CoreSc1 advantage="None" conceptID="Mod15" novelty="None" type="Mod"/><text>A more general approach also taking into account the cost of actions represents the definition of a generic cost function that maps SLA violations, resource wastage and the costs of executed actions into a monetary unit, which we want to call Cloud EUR.</text></s>
<s sid="347"><CoreSc1 advantage="None" conceptID="Mod16" novelty="None" type="Mod"/><text>First, we define a penalty function pr(p):[0,100]→R+ that defines the relationship between the percentage of violations p (as opposed to all possible violations) and the penalty for a violation of resource r.</text></s>
<s sid="348"><CoreSc1 advantage="None" conceptID="Mod17" novelty="None" type="Mod"/><text>Second, we define a function wastage wr(w):[0,100]→R+ that relates the percentage of unused resources w to the energy in terms of money that these resources unnecessarily consume.</text></s>
<s sid="349"><CoreSc1 advantage="None" conceptID="Mod18" novelty="None" type="Mod"/><text>Third, we define a cost function ar(a):[0,100]→R+ from the percentage of executed actions a (as opposed to all possible actions that could have been executed) to the energy and time costs in terms of money.</text></s>
<s sid="350"><CoreSc1 advantage="None" conceptID="Mod19" novelty="None" type="Mod"/><text>The total cost c is then defined as (8)c(p,w,c)=∑rpr(p)+wr(w)+ar(a).</text></s>
<s sid="351"><CoreSc1 advantage="None" conceptID="Mod20" novelty="None" type="Mod"/><text>We assume functions pr,wr and ar for this evaluation with pr(p)=100p, wr(w)=5w, and ar(a)=a for all r.</text></s>
<s sid="352"><CoreSc1 advantage="None" conceptID="Con30" novelty="None" type="Con"/><text>The intention behind choosing these functions is (i) to impose very strict fines in order to proclaim SLA adherence as top priority, (ii) to weigh resource wastage a little more than the cost of actions.</text></s>
<s sid="353"><CoreSc1 advantage="None" conceptID="Con31" novelty="None" type="Con"/><text>The cost function is currently not evaluated within the simulation engine, it is a value calculated after the simulation for comparison reasons.</text></s>
<s sid="354"><CoreSc1 advantage="None" conceptID="Con32" novelty="None" type="Con"/><text>Thus, the recommended actions do not depend on the specific functions we assumed.</text></s>
<s sid="355"><CoreSc1 advantage="None" conceptID="Con33" novelty="None" type="Con"/><text>However, it could be incorporated into the KB in order to adjust and learn the TTs for every resource r.</text></s>
<s sid="356"><CoreSc1 advantage="None" conceptID="Con34" novelty="None" type="Con"/><text>Evaluation and comparison of CBR and rules using synthetic data</text></s>
<s sid="357"><CoreSc1 advantage="None" conceptID="Con35" novelty="None" type="Con"/><text>To evaluate a great variety of workload data, one approach is to create them synthetically.</text></s>
<s sid="358"><CoreSc1 advantage="None" conceptID="Con36" novelty="None" type="Con"/><text>For this, we extended the workload generator as described in [7] to allow a categorization of data volatility.</text></s>
<s sid="359"><CoreSc1 advantage="None" conceptID="Res140" novelty="None" type="Res"/><text>The workload generator is intended to generate very general workloads for IaaS platforms dealing with slower developments as well as rapid changes.</text></s>
<s sid="360"><CoreSc1 advantage="None" conceptID="Res141" novelty="None" type="Res"/><text>For one parameter, the workload is generated as follows: The initial value of the workloads is randomly drawn from a Gaussian distribution with μ=SLO2 and σ=SLO8, where SLO represents the Service Level Objective value agreed in the SLA.</text></s>
<s sid="361"><CoreSc1 advantage="None" conceptID="Res142" novelty="None" type="Res"/><text>Then, an up- or down-trend is randomly drawn, as well as a duration of this trend between a pre-defined number of iterations (for our evaluation this interval of iterations equals [2,6]), both with equal probability.</text></s>
<s sid="362"><CoreSc1 advantage="None" conceptID="Res143" novelty="None" type="Res"/><text>For every iteration, as long as the trend lasts, the current measured value is increased or decreased (depending on the trend) by a percentage evenly drawn from the interval [iBegin,iEnd].</text></s>
<s sid="363"><CoreSc1 advantage="None" conceptID="Res144" novelty="None" type="Res"/><text>After the trend is over, a new trend is drawn and the iterations continue as described before.</text></s>
<s sid="364"><CoreSc1 advantage="None" conceptID="Res145" novelty="None" type="Res"/><text>Clearly, the values for iBegin and iEnd determine the difficulty for handling the workload.</text></s>
<s sid="365"><CoreSc1 advantage="None" conceptID="Res146" novelty="None" type="Res"/><text>A workload that operates with low iBegin and iEnd values exhibits only very slight changes and does not, consequently, need a lot of dynamic adaptations.</text></s>
<s sid="366"><CoreSc1 advantage="None" conceptID="Res147" novelty="None" type="Res"/><text>Large iEnd values, on the contrary, need the enforcement mechanisms to be very elastically tuned.</text></s>
<s sid="367"><CoreSc1 advantage="None" conceptID="Res148" novelty="None" type="Res"/><text>For the evaluation and comparison of CBR and the rule-based approach we defined a LOW_MEDIUM workload volatility class with iEnd=18%.</text></s>
<s sid="368"><CoreSc1 advantage="None" conceptID="Res149" novelty="None" type="Res"/><text>For the further evaluation of the rule-based approach we defined and tested LOW, MEDIUM, MEDIUM_HIGH and HIGH workload volatility classes (not shown here) with iEnd=10%, 50%, 75%, and 100%, respectively.</text></s>
<s sid="369"><CoreSc1 advantage="None" conceptID="Res150" novelty="None" type="Res"/><text>As a minimum change we set iBegin=2% for all classes.</text></s>
<s sid="370"><CoreSc1 advantage="None" conceptID="Res151" novelty="None" type="Res"/><text>As the crucial parameters for CBR and the rule-based approach differ, we define scenarios for both approaches separately, but still compare them to the aforementioned six performance indicators.</text></s>
<s sid="371"><CoreSc1 advantage="None" conceptID="Res152" novelty="None" type="Res"/><text>As resources for IaaS one can use all parameters that can be adapted on a VM.</text></s>
<s sid="372"><CoreSc1 advantage="None" conceptID="Mod21" novelty="None" type="Mod"/><text>For the evaluation we chose to take the following parameters and SLOs for CBR: storage≥1000GB,incomingbandwidth≥20Mbit/s, and the following parameters and SLOs for the rule-based approach: storage≥1000GB,incomingbandwidth≥20Mbit/s,outgoing bandwidth≥50Mbit/s,memory≥512MB, and CPU power≥100MIPS (Million Instructions Per Second).</text></s>
<s sid="373"><CoreSc1 advantage="None" conceptID="Res153" novelty="None" type="Res"/><text>As far as CBR is concerned, its behavior differs by the α value in Eq.</text></s>
<s sid="374"><CoreSc1 advantage="None" conceptID="Res154" novelty="None" type="Res"/><text>(4) (setting importance to avoiding violations or achieving high utilization), by the number of executed iterations, because of its inherent learning feature, and the initial cases.</text></s>
<s sid="375"><CoreSc1 advantage="None" conceptID="Res155" novelty="None" type="Res"/><text>At the beginning, we configure all 50 VMs exactly equally with 80% of the storage SLO value and two-thirds of the bandwidth SLO value provided.</text></s>
<s sid="376"><CoreSc1 advantage="None" conceptID="Obs43" novelty="None" type="Obs"/><text>Then, we execute 2, 5, 10 and 20 iterations with values for α being 0.1, 0.2, 0.3, 0.4, 0.5, 0.6 and 0.8.</text></s>
<s sid="377"><CoreSc1 advantage="None" conceptID="Res156" novelty="None" type="Res"/><text>We omit values 0.2 and 0.4 in the evaluation because their outcomes do not differ enough from the values shown, and all values &gt; 0.5, because they reveal unacceptable high SLA violation rates.</text></s>
<s sid="378"><CoreSc1 advantage="None" conceptID="Res157" novelty="None" type="Res"/><text>Setting up the initial cases was done by choosing one representative case for each action that could be triggered.</text></s>
<s sid="379"><CoreSc1 advantage="None" conceptID="Res158" novelty="None" type="Res"/><text>For our evaluation the SLA parameters bandwidth and storage (even though not being tied to them in any way-we could have also named them, e.g., memory and CPU time) were taken into consideration resulting in nine possible actions &quot;Increase/Decrease bandwidth by 10%/20%&quot;, &quot;Increase/Decrease storage by 10%/20%&quot;, and &quot;Do nothing&quot;.</text></s>
<s sid="380"><CoreSc1 advantage="None" conceptID="Obs44" novelty="None" type="Obs"/><text>Taking storage for example, we divide the range of distances for storage St between measured and provided resources into five parts as depicted in Fig. 7.</text></s>
<s sid="381"><CoreSc1 advantage="None" conceptID="Hyp5" novelty="None" type="Hyp"/><text>We choose some reasonable threshold for every action as follows: If pSt-mSt=-10 then action &quot;Increase Storage by 20%&quot; as this already is a violation; if pSt--mSt=+50 then action &quot;Increase Storage by 10%&quot; as resources are already scarce but not so problematic as in the previous case; if pSt-mSt=+100 then action &quot;Do nothing&quot; as resources are neither very over- nor under-provisioned; if pSt-mSt=+200 then action &quot;Decrease Storage by 10%&quot; as now resources are over-provisioned; and we set action &quot;Decrease Storage by 20%&quot; when we are over the latest threshold as then resources are extremely over-provisioned.</text></s>
<s sid="382"><CoreSc1 advantage="None" conceptID="Res159" novelty="None" type="Res"/><text>We choose the values for our initial cases from the center of the respective intervals.</text></s>
<s sid="383"><CoreSc1 advantage="None" conceptID="Res160" novelty="None" type="Res"/><text>Ultimately, for the initial case for the action, e.g., &quot;Increase Storage by 20%&quot; we take the just mentioned value for storage and the &quot;Do nothing&quot; value for bandwidth.</text></s>
<s sid="384"><CoreSc1 advantage="None" conceptID="Res161" novelty="None" type="Res"/><text>This leads to c=(id,0,-10,0,7.5), and because only the differences between the values matter, it is equivalent to, e.g., c=(id,200,190,7.5,15.0).</text></s>
<s sid="385"><CoreSc1 advantage="None" conceptID="Res162" novelty="None" type="Res"/><text>As far as the rule-based approach is concerned, its behavior differs by the set threat thresholds.</text></s>
<s sid="386"><CoreSc1 advantage="None" conceptID="Res163" novelty="None" type="Res"/><text>Thus, we investigate low, middle and high values for TTlowr and TThighr (as defined in Section 5.3), where TTlowr∈{30%,50%,70%} and TThighr∈{60%,75%,90%} for all resources stated above.</text></s>
<s sid="387"><CoreSc1 advantage="None" conceptID="Res164" novelty="None" type="Res"/><text>We combine the TTs to form eight different scenarios as depicted in Table 4.</text></s>
<s sid="388"><CoreSc1 advantage="None" conceptID="Res165" novelty="None" type="Res"/><text>We execute 100 iterations with 500 applications, and set the &quot;safety slack&quot; ϵ=5% (cf.</text></s>
Listing 1).
<s sid="389"><CoreSc1 advantage="None" conceptID="Res166" novelty="None" type="Res"/><text>Fig. 8 presents the aforementioned performance indicators of CBR.</text></s>
<s sid="390"><CoreSc1 advantage="None" conceptID="Res167" novelty="None" type="Res"/><text>The &quot;No CBR&quot; line means that the autonomic manager is turned off, which implies that the configuration of the VMs is left as set at the beginning, i.e., no adaptation actions due to changing demands are executed.</text></s>
<s sid="391"><CoreSc1 advantage="None" conceptID="Obs45" novelty="None" type="Obs"/><text>In Fig. 8(a) we see that up to more than half of the violations can be avoided when using α∈{0.1,0.3} instead of no autonomic management.</text></s>
<s sid="392"><CoreSc1 advantage="None" conceptID="Obs46" novelty="None" type="Obs"/><text>However, fewer SLA violations result in lower resource utilization (cf.</text></s>
<s sid="393"><CoreSc1 advantage="None" conceptID="Obs47" novelty="None" type="Obs"/><text>Fig. 8(b)), as more resources have to be provided than can actually be utilized.</text></s>
<s sid="394"><CoreSc1 advantage="None" conceptID="Obs48" novelty="None" type="Obs"/><text>Reconfiguration actions as depicted in Fig. 8(c) lie slightly below or at 50%, except for &quot;No CBR&quot;, of course.</text></s>
<s sid="395"><CoreSc1 advantage="None" conceptID="Res168" novelty="None" type="Res"/><text>Another point that can be observed is that after a certain amount of iterations the quality of the recommended actions decreases.</text></s>
<s sid="396"><CoreSc1 advantage="None" conceptID="Con37" novelty="None" type="Con"/><text>This is probably due to the fact that the initial cases get more and more blurred when more cases are stored into CBR, as all new cases are being learned and there is no distinction made between &quot;interesting&quot; and &quot;uninteresting&quot; cases.</text></s>
<s sid="397"><CoreSc1 advantage="None" conceptID="Con38" novelty="None" type="Con"/><text>Nevertheless, when we relate SLA violations and resource utilization in terms of RAE, all CBR methods are generally better than the default method, especially for α∈{0.3,0.5} after five iterations.</text></s>
<s sid="398"><CoreSc1 advantage="None" conceptID="Res169" novelty="None" type="Res"/><text>Yet, RAE decreases strictly monotonically for all α.</text></s>
<s sid="399"><CoreSc1 advantage="None" conceptID="Res170" novelty="None" type="Res"/><text>Furthermore, costs-relating violations, utilization and reconfiguration actions-can also be reduced to half for α∈{0.1,0.3}.</text></s>
<s sid="400"><CoreSc1 advantage="None" conceptID="Res171" novelty="None" type="Res"/><text>However, there is a seemingly exponential increase in the average execution time per VM (cf.</text></s>
<s sid="401"><CoreSc1 advantage="None" conceptID="Res172" novelty="None" type="Res"/><text>Fig. 8(f)) due to higher number of cases stored in the KB.</text></s>
<s sid="402"><CoreSc1 advantage="None" conceptID="Met22" novelty="None" type="Met"/><text>Summing up, the simulation shows that learning did take place (and cost some time) and that CBR is able to recommend right actions for many cases, i.e., to correctly handle and interpret the measurement information that is based on a random distribution not known to CBR.</text></s>
<s sid="403"><CoreSc1 advantage="None" conceptID="Obs49" novelty="None" type="Obs"/><text>Fig. 9 shows the same evaluation for the rule-based approach evaluating the aforementioned eight scenarios.</text></s>
<s sid="404"><CoreSc1 advantage="None" conceptID="Res173" novelty="None" type="Res"/><text>From Fig. 9(a) we learn that in terms of SLA violations Scenario 1 achieves the best result, where only 0.0908% of all possible violations occur, and Scenario 8 yields the worst result, with a still very low violation rate of 1.2040%.</text></s>
<s sid="405"><CoreSc1 advantage="None" conceptID="Res174" novelty="None" type="Res"/><text>In general, the higher the values are for TThigh, the worse is the outcome.</text></s>
<s sid="406"><CoreSc1 advantage="None" conceptID="Res175" novelty="None" type="Res"/><text>The best result achieved with CBR was at 7.5%.</text></s>
<s sid="407"><CoreSc1 advantage="None" conceptID="Con39" novelty="None" type="Con"/><text>Thus, the rule-based approach achieves an up to 82 times better performance with the right TTs set, and still a six times better performance in the worst case.</text></s>
<s sid="408"><CoreSc1 advantage="None" conceptID="Obs50" novelty="None" type="Obs"/><text>Fig. 9(b) shows resource utilization.</text></s>
<s sid="409"><CoreSc1 advantage="None" conceptID="Res176" novelty="None" type="Res"/><text>We see that the combination of high TTlow and high TThigh (Scenario 8) gives the best utilization (84.0%), whereas low values for TTlow and TThigh lead to the worst utilization (62.0% in Scenario 1).</text></s>
<s sid="410"><CoreSc1 advantage="None" conceptID="Res177" novelty="None" type="Res"/><text>Still, compared to CBR which scored a maximum of 80.4% and a minimum of 51.8%, the rule-based approach generally achieves better results.</text></s>
<s sid="411"><CoreSc1 advantage="None" conceptID="Res178" novelty="None" type="Res"/><text>The percentage of all executed actions as compared to all possible actions that could have been executed is shown in Fig. 9(c).</text></s>
<s sid="412"><CoreSc1 advantage="None" conceptID="Res179" novelty="None" type="Res"/><text>One observes that the greater the span between TTlow and TThigh is, the fewer actions have to be executed.</text></s>
<s sid="413"><CoreSc1 advantage="None" conceptID="Res180" novelty="None" type="Res"/><text>Most actions (60.8%) are executed for Scenario 7 (span of only 5% between TT values), whereas least actions (5.5%) are executed for Scenario 3 (span of 60% between TT values).</text></s>
<s sid="414"><CoreSc1 advantage="None" conceptID="Res181" novelty="None" type="Res"/><text>CBR almost always recommended exactly one (out of two possible) actions and hardly ever (in about 1% of the cases) recommended no action.</text></s>
<s sid="415"><CoreSc1 advantage="None" conceptID="Res182" novelty="None" type="Res"/><text>As violations are very low in general, the resource allocation efficiency is very similar to the utilization.</text></s>
<s sid="416"><CoreSc1 advantage="None" conceptID="Res183" novelty="None" type="Res"/><text>The best value can be achieved with Scenario 8 (84.0%), the worst with Scenario 1 (62.0%).</text></s>
<s sid="417"><CoreSc1 advantage="None" conceptID="Res184" novelty="None" type="Res"/><text>CBR achieves a RAE of at most 69.7% (α=0.5 at iteration 2), and at least 45.5% (α=0.1 at iteration 20).</text></s>
<s sid="418"><CoreSc1 advantage="None" conceptID="Res185" novelty="None" type="Res"/><text>Fig. 8(e) shows the costs for each scenario using Eq.</text></s>
(8).
<s sid="419"><CoreSc1 advantage="None" conceptID="Res186" novelty="None" type="Res"/><text>The best trade-off between the three terms is achieved by Scenario 5 that has medium values for TTlowr and TThighr.</text></s>
<s sid="420"><CoreSc1 advantage="None" conceptID="Res187" novelty="None" type="Res"/><text>It has a very low violation rate of 0.0916%, a quite elaborate utilization of 72.9%, but achieves this with only 19.8% of actions.</text></s>
<s sid="421"><CoreSc1 advantage="None" conceptID="Res188" novelty="None" type="Res"/><text>Scenario 7 achieves a better violation and utilization rate but at the cost of an action rate of 60.8%, and consequently has higher costs.</text></s>
<s sid="422"><CoreSc1 advantage="None" conceptID="Res189" novelty="None" type="Res"/><text>The lowest cost value for CBR is 923.0 Cloud EUR, the highest 2985.3 Cloud EUR.</text></s>
<s sid="423"><CoreSc1 advantage="None" conceptID="Res190" novelty="None" type="Res"/><text>If the utility of the decision decreases for a certain time frame (as cost increases), the KB could determine the cost summand in Eq.</text></s>
<s sid="424"><CoreSc1 advantage="None" conceptID="Res191" novelty="None" type="Res"/><text>(8) that contributes most to this decrease.</text></s>
<s sid="425"><CoreSc1 advantage="None" conceptID="Res192" novelty="None" type="Res"/><text>For any resource r, if the term is p, then decrease TThighr.</text></s>
<s sid="426"><CoreSc1 advantage="None" conceptID="Res193" novelty="None" type="Res"/><text>If the term is w, then increase TTlowr.</text></s>
<s sid="427"><CoreSc1 advantage="None" conceptID="Obs51" novelty="None" type="Obs"/><text>Otherwise, if the term is c, then widen the span of TThighr and TTlowr, i.e., increase TThighr and decrease TTlowr.</text></s>
<s sid="428"><CoreSc1 advantage="None" conceptID="Res194" novelty="None" type="Res"/><text>We plan to investigate this in our future research.</text></s>
<s sid="429"><CoreSc1 advantage="None" conceptID="Res195" novelty="None" type="Res"/><text>As far as time performance and scalability are concerned, the performance tests are very encouraging.</text></s>
<s sid="430"><CoreSc1 advantage="None" conceptID="Res196" novelty="None" type="Res"/><text>We executed 100 iterations from 100 to 3000 VMs.</text></s>
<s sid="431"><CoreSc1 advantage="None" conceptID="Met23" novelty="None" type="Met"/><text>We performed every test twice and calculated the average execution time as well as the average time it took for the simulation engine to handle one VM.</text></s>
<s sid="432"><CoreSc1 advantage="None" conceptID="Res197" novelty="None" type="Res"/><text>As shown in Fig. 9(f) the execution time per VM stays quite constant for up to 1500 VMs, and thus average execution time is about linear.</text></s>
<s sid="433"><CoreSc1 advantage="None" conceptID="Res198" novelty="None" type="Res"/><text>For 3000 VMs, it took 647s/100=6.47s for one iteration to treat all VMs.</text></s>
<s sid="434"><CoreSc1 advantage="None" conceptID="Res199" novelty="None" type="Res"/><text>The high time consumption per VM for 100 VMs in Fig. 9(f) is due to the initialization of the rule knowledge base which takes over-proportionally long for just a small number of VMs and does not weigh so much for more VMs.</text></s>
<s sid="435"><CoreSc1 advantage="None" conceptID="Res200" novelty="None" type="Res"/><text>CBR took 240 s for 50 VMs and 20 iterations.</text></s>
<s sid="436"><CoreSc1 advantage="None" conceptID="Con40" novelty="None" type="Con"/><text>Thus, CBR took 240s/20=12s for one iteration to treat all VMs, which is twice as long as the rule-based approach takes, which even has 60 times more VMs.</text></s>
<s sid="437"><CoreSc1 advantage="None" conceptID="Con41" novelty="None" type="Con"/><text>However, CBR implements learning features, which the rule-based approach currently does not, and could be sped up by choosing only specific cases to be stored in the KB.</text></s>
<s sid="438"><CoreSc1 advantage="None" conceptID="Con42" novelty="None" type="Con"/><text>Summarizing, the rule-based approach highly outperforms CBR with respect to violations (up to 82 times better results), actions, cost, and time performance.</text></s>
<s sid="439"><CoreSc1 advantage="None" conceptID="Con43" novelty="None" type="Con"/><text>The rule-based approach also achieves better &quot;best case&quot; and better &quot;worst case&quot; results for the remaining performance indicators utilization and resource allocations efficiency.</text></s>
<s sid="440"><CoreSc1 advantage="None" conceptID="Con44" novelty="None" type="Con"/><text>In more detail, seven out of eight scenarios were better than the worst CBR value for utilization, whereas only one scenario was better than the best CBR utilization value.</text></s>
<s sid="441"><CoreSc1 advantage="None" conceptID="Con45" novelty="None" type="Con"/><text>Again, accumulating these results into cost, all rule-based scenarios outperform CBR by a factor of at least 4 (worst rule-based scenario (236) compared to the best CBR result (923)), which to a large extent is due to the huge number of violations that the rule-based approach is able to prevent and the high number of actions it can save.</text></s>
<s sid="442"><CoreSc1 advantage="None" conceptID="Goa16" novelty="None" type="Goa"/><text>Consequently, we consider the rule-based approach as the better technique to deal with VM reconfiguration in Cloud Computing infrastructures, and we will focus the remaining part of this article on a deeper investigation and understanding of the rule-based approach by evaluating it with real world workload.</text></s>
<s sid="443"><CoreSc1 advantage="None" conceptID="Res201" novelty="None" type="Res"/><text>A deeper investigation of synthetic workload also suggests the self-adaptation of the TTs from the rule-based approach.</text></s>
<s sid="444"><CoreSc1 advantage="None" conceptID="Con46" novelty="None" type="Con"/><text>A successful self-adaptation has been presented in [42].</text></s>
<s sid="445"><CoreSc1 advantage="None" conceptID="Con47" novelty="None" type="Con"/><text>Applying and evaluating a bioinformatics workflow to the rule-based approach</text></s>
<s sid="446"><CoreSc1 advantage="None" conceptID="Con48" novelty="None" type="Con"/><text>As detailed in [43,44], bioinformatics workflows have gained a great need for large-scale data analysis.</text></s>
<s sid="447"><CoreSc1 advantage="None" conceptID="Con49" novelty="None" type="Con"/><text>Due to the fact that these scientific workflows are very resource intensive and can take hours if not days to complete, provisioning them in an environment with fixed resources leads to poor performance.</text></s>
<s sid="448"><CoreSc1 advantage="None" conceptID="Con50" novelty="None" type="Con"/><text>On the one hand, the workflow might run out of resources and thus may have to be restarted on a larger system.</text></s>
<s sid="449"><CoreSc1 advantage="None" conceptID="Con51" novelty="None" type="Con"/><text>On the other hand, too many resources might be provisioned in order not to take risks of a premature abort, which may cause a lot of resources to be wasted.</text></s>
<s sid="450"><CoreSc1 advantage="None" conceptID="Con52" novelty="None" type="Con"/><text>Thus, Cloud computing infrastructures offer a promising way to host these sorts of applications [10].</text></s>
<s sid="451"><CoreSc1 advantage="None" conceptID="Con53" novelty="None" type="Con"/><text>The monitoring data presented in this Section was gathered with the help of the Cloud monitoring framework Lom2His [3].</text></s>
<s sid="452"><CoreSc1 advantage="None" conceptID="Obj48" novelty="None" type="Obj"/><text>Using Lom2His we measured utilized resources of TopHat [45], a typical bioinformatics workflow application analyzing RNA-Seq data [46], for a duration of about three hours [9].</text></s>
<s sid="453"><CoreSc1 advantage="None" conceptID="Obj49" novelty="None" type="Obj"/><text>In the following we briefly describe the bioinformatics workflow in more detail.</text></s>
<s sid="454"><CoreSc1 advantage="None" conceptID="Obj50" novelty="None" type="Obj"/><text>We here consider Next Generation Sequencing (NGS), a recently introduced high-throughput technology for the identification of nucleotide molecules like RNA or DNA in biomedical samples.</text></s>
<s sid="455"><CoreSc1 advantage="None" conceptID="Con54" novelty="None" type="Con"/><text>The output of the sequencing process is a list of billions of character sequences called 'reads', each typically holds up to 35-200 letters that represent the individual DNA bases determined.</text></s>
<s sid="456"><CoreSc1 advantage="None" conceptID="Con55" novelty="None" type="Con"/><text>Lately, this technology has also been used to identify and count the abundances of RNA molecules that reflect new gene activity.</text></s>
<s sid="457"><CoreSc1 advantage="None" conceptID="Con56" novelty="None" type="Con"/><text>We use the approach, called RNA-Seq, as a typical example of a scientific workflow application in the field of bioinformatics.</text></s>
<s sid="458"><CoreSc1 advantage="None" conceptID="Con57" novelty="None" type="Con"/><text>At first, in the analysis of RNA-Seq data, the obtained sequences are aligned to the reference genome.</text></s>
<s sid="459"><CoreSc1 advantage="None" conceptID="Con58" novelty="None" type="Con"/><text>The aligner presented here, TopHat [45], consists of many sub-tasks, some of them have to be executed sequentially, whereas others can run in parallel (Fig. 10).</text></s>
<s sid="460"><CoreSc1 advantage="None" conceptID="Con59" novelty="None" type="Con"/><text>These sub-tasks can have different resource-demand characteristics: needing extensive computational power, demanding high I/O access, or requiring extensive memory size.</text></s>
<s sid="461"><CoreSc1 advantage="None" conceptID="Obs52" novelty="None" type="Obs"/><text>In Fig. 10, the green boxes represent simplified sub-tasks of the workflow application, whereas the blue boxes represent the data transferred between the sub-tasks.</text></s>
<s sid="462"><CoreSc1 advantage="None" conceptID="Res202" novelty="None" type="Res"/><text>The first sub-task aligns input reads to the given genome using the Bowtie program [47].</text></s>
<s sid="463"><CoreSc1 advantage="None" conceptID="Res203" novelty="None" type="Res"/><text>Unaligned reads are then divided into shorter sub-sequences which are further aligned to the reference genome in the next sub-task.</text></s>
<s sid="464"><CoreSc1 advantage="None" conceptID="Res204" novelty="None" type="Res"/><text>If sub-sequences coming from the same read were aligned successfully to the genome, that may indicate that this read was straddling a 'gap' in the gene, falling on a so-called splice-junction.</text></s>
<s sid="465"><CoreSc1 advantage="None" conceptID="Res205" novelty="None" type="Res"/><text>After verification of candidate reads falling on splice junctions, these and the reads that were aligned in the first sub-task are combined to create an output with a comprehensive list of localized alignments.</text></s>
<s sid="466"><CoreSc1 advantage="None" conceptID="Con60" novelty="None" type="Con"/><text>We demonstrate by simulation that the rule-based approach can guarantee the resource requirements in terms of CPU, memory and storage for the execution of the workflow in a resource-efficient way.</text></s>
<s sid="467"><CoreSc1 advantage="None" conceptID="Con61" novelty="None" type="Con"/><text>Therefore, we define the SLA shown in Table 5 for TopHat with the maximum amount of available resources on the physical machine on which we are executing it.</text></s>
<s sid="468"><CoreSc1 advantage="None" conceptID="Res206" novelty="None" type="Res"/><text>The physical machine has a Linux/Ubuntu OS with a Intel Xeon(R) 3 GHz CPU, two cores, 9 GB of memory, and 19 GB of storage.</text></s>
<s sid="469"><CoreSc1 advantage="None" conceptID="Mod22" novelty="None" type="Mod"/><text>For CPU power, we convert CPU utilization into MIPS based on the assumption that an Intel Xeon(R) 3 GHz processor delivers 10000 MIPS for 100% resource utilization of one core, and linearly degrades with CPU utilization.</text></s>
<s sid="470"><CoreSc1 advantage="None" conceptID="Mod23" novelty="None" type="Mod"/><text>In order to validate our approach, we make three simulation categories, where we set up and manage our VMs differently: In the first category (Scenario 1) we assume a static configuration with a fixed initial resource configuration of the VMs.</text></s>
<s sid="471"><CoreSc1 advantage="None" conceptID="Res207" novelty="None" type="Res"/><text>Normally, when setting up such a testbed as described in [9], an initial guess of possible resource consumption is done based on early monitoring data.</text></s>
<s sid="472"><CoreSc1 advantage="None" conceptID="Res208" novelty="None" type="Res"/><text>From this data on, we assume quite generous resource limits.</text></s>
<s sid="473"><CoreSc1 advantage="None" conceptID="Res209" novelty="None" type="Res"/><text>The first ten measurements of CPU, memory, and storage lie in the range of [140, 12500] MIPS, [172, 1154] MB, [15.6, 15.7] GB, respectively.</text></s>
<s sid="474"><CoreSc1 advantage="None" conceptID="Res210" novelty="None" type="Res"/><text>So we initially configured our VM with 15000 MIPS, 4096 MB, and 17.1 GB, respectively.</text></s>
<s sid="475"><CoreSc1 advantage="None" conceptID="Con62" novelty="None" type="Con"/><text>The second category subsumes several scenarios, where we apply our autonomic management approach to the initial configuration in the first category.</text></s>
<s sid="476"><CoreSc1 advantage="None" conceptID="Con63" novelty="None" type="Con"/><text>The eight scenarios in this category depend on the chosen TTs.</text></s>
<s sid="477"><CoreSc1 advantage="None" conceptID="Con64" novelty="None" type="Con"/><text>According to Table 4 we define these scenarios as Scenario 2.1, 2.2,…,2.8, respectively.</text></s>
<s sid="478"><CoreSc1 advantage="None" conceptID="Con65" novelty="None" type="Con"/><text>As the third category (Scenario 3), we consider a best case scenario, where we assume we have an oracle that predicts the maximal resource consumption that we statically set our VM configuration to.</text></s>
<s sid="479"><CoreSc1 advantage="None" conceptID="Con66" novelty="None" type="Con"/><text>Moreover, according to the first measurements we decide to enforce a minimum of 1 MIPS CPU, 768 MB memory, and 1 GB storage.</text></s>
<s sid="480"><CoreSc1 advantage="None" conceptID="Con67" novelty="None" type="Con"/><text>As depicted in Fig. 11(a)-(c) one sees violations, utilization, as well as the number of reconfiguration actions, respectively, for every parameter (together with an average value) in the different scenarios.</text></s>
<s sid="481"><CoreSc1 advantage="None" conceptID="Con68" novelty="None" type="Con"/><text>Generally, the bars are naturally ordered beginning from Scenario 1, over Scenarios 2.1,…,2.8, ending with Scenario 3.</text></s>
<s sid="482"><CoreSc1 advantage="None" conceptID="Res211" novelty="None" type="Res"/><text>The number of violations in Scenario 1 reach 41.7% for CPU and memory, and 49.4% for storage, which leads to an average of 44.3%.</text></s>
<s sid="483"><CoreSc1 advantage="None" conceptID="Con69" novelty="None" type="Con"/><text>(For better visibility, these results have been excluded from Fig. 11(a).) Thus, we experience violations in almost half of the cases.</text></s>
<s sid="484"><CoreSc1 advantage="None" conceptID="Con70" novelty="None" type="Con"/><text>This is especially crucial for parameters memory and storage, where program execution could fail, if it runs out of memory or storage, whereas for a violation of the parameter CPU, we would &quot;only&quot; delay the successful termination of the workflow.</text></s>
<s sid="485"><CoreSc1 advantage="None" conceptID="Con71" novelty="None" type="Con"/><text>With Scenarios 2.* we can reduce the SLA violations to a minimum.</text></s>
<s sid="486"><CoreSc1 advantage="None" conceptID="Res212" novelty="None" type="Res"/><text>We completely avoid violations for storage in all sub-scenarios, as well as for memory in all but one sub-scenarios.</text></s>
<s sid="487"><CoreSc1 advantage="None" conceptID="Res213" novelty="None" type="Res"/><text>Also CPU violations can be reduced to 0.6% for sub-scenarios 2.1 and 2.4, and still achieve a maximum SLA violation rate of 2.8% with Scenario 2.8.</text></s>
<s sid="488"><CoreSc1 advantage="None" conceptID="Res214" novelty="None" type="Res"/><text>The average SLA violation rate can be lowered to 0.2% in the best case.</text></s>
<s sid="489"><CoreSc1 advantage="None" conceptID="Res215" novelty="None" type="Res"/><text>Scenario 3, of course, shows no violations.</text></s>
<s sid="490"><CoreSc1 advantage="None" conceptID="Con72" novelty="None" type="Con"/><text>However, it is unlikely to know the maximum resource consumption before workflow execution.</text></s>
<s sid="491"><CoreSc1 advantage="None" conceptID="Con73" novelty="None" type="Con"/><text>As to the utilization of the resources, it is clearly higher when a lot of violations occur, so Scenario 1 naturally achieves high utilization.</text></s>
<s sid="492"><CoreSc1 advantage="None" conceptID="Con74" novelty="None" type="Con"/><text>This is the case, because when a parameter is violated, then the resource is already fully used up, but even more of the resource would be needed to fulfill the needs.</text></s>
<s sid="493"><CoreSc1 advantage="None" conceptID="Con75" novelty="None" type="Con"/><text>On the opposite, Scenario 3 naturally achieves low utilization, as a lot of resources are over-provisioned.</text></s>
<s sid="494"><CoreSc1 advantage="None" conceptID="Res216" novelty="None" type="Res"/><text>Scenarios 2.* achieve a good utilization that is on average in between the two extremes and ranges from 70.6% (Scenario 2.1) to 86.2% (Scenario 2.8).</text></s>
<s sid="495"><CoreSc1 advantage="None" conceptID="Res217" novelty="None" type="Res"/><text>Furthermore, we observe some exceptions to this &quot;rule&quot; when considering individual parameters.</text></s>
<s sid="496"><CoreSc1 advantage="None" conceptID="Res218" novelty="None" type="Res"/><text>So, e.g., for memory we achieve a utilization of 85.0% with Scenario 2.8 or 80.0% with Scenario 2.6, which is higher than the utilization in Scenario 1 (77.4%).</text></s>
<s sid="497"><CoreSc1 advantage="None" conceptID="Res219" novelty="None" type="Res"/><text>The same is true for CPU utilization rates of 85.5% as compared to 84.3% for the Scenario 1 and 2.8, respectively.</text></s>
<s sid="498"><CoreSc1 advantage="None" conceptID="Res220" novelty="None" type="Res"/><text>Only for storage the utilization of all but one of the Scenarios 2.*, which is at 85.9%, is smaller than for Scenario 3 (90.1%).</text></s>
<s sid="499"><CoreSc1 advantage="None" conceptID="Res221" novelty="None" type="Res"/><text>A huge advantage of Scenarios 2.* is that they do not run into any crucial SLA violation (except for Scenario 2.3), but achieve a higher utilization as compared to Scenario 3.</text></s>
<s sid="500"><CoreSc1 advantage="None" conceptID="Res222" novelty="None" type="Res"/><text>As to the reallocation actions, of course, Scenario 1 and 3 do not execute any, but also for the autonomic management in Scenarios 2.*, the amount of executed reallocation actions for most scenarios stays below 10%.</text></s>
<s sid="501"><CoreSc1 advantage="None" conceptID="Res223" novelty="None" type="Res"/><text>Only Scenario 2.7 executes actions in 19.8% of the cases on average of the time.</text></s>
<s sid="502"><CoreSc1 advantage="None" conceptID="Res224" novelty="None" type="Res"/><text>Five out of eight scenarios stay below 5% on average.</text></s>
<s sid="503"><CoreSc1 advantage="None" conceptID="Res225" novelty="None" type="Res"/><text>When it comes to the overall costs of the scenarios (cf.</text></s>
<s sid="504"><CoreSc1 advantage="None" conceptID="Res226" novelty="None" type="Res"/><text>Fig. 12(a)), all 2.* scenarios approach the result achieved by the best case scenario 3.</text></s>
<s sid="505"><CoreSc1 advantage="None" conceptID="Res227" novelty="None" type="Res"/><text>Scenario 1 sums up costs of 4493.6, and has therefore been omitted in the figure.</text></s>
<s sid="506"><CoreSc1 advantage="None" conceptID="Res228" novelty="None" type="Res"/><text>Furthermore, the lowest cost is achieved using Scenario 2.6, which is even lower than the cost for Scenario 3.</text></s>
<s sid="507"><CoreSc1 advantage="None" conceptID="Res229" novelty="None" type="Res"/><text>This is possible, because Scenario 2.6 achieves a very good utilization and SLA violation rate with a very low number of reallocation actions.</text></s>
<s sid="508"><CoreSc1 advantage="None" conceptID="Res230" novelty="None" type="Res"/><text>Also resource allocation efficiency for Scenarios 2.* as shown in Fig. 12(b) achieves unambiguously better results than for Scenario 1 (RAE of 48.2%).</text></s>
<s sid="509"><CoreSc1 advantage="None" conceptID="Res231" novelty="None" type="Res"/><text>Furthermore, all scenarios of the second category achieve a better RAE than the RAE of Scenario 3 (69.3%).</text></s>
<s sid="510"><CoreSc1 advantage="None" conceptID="Con76" novelty="None" type="Con"/><text>Thus, we conclude that by using the suggested autonomic management technique, we can avoid most costly SLA violations, and thus ensure workflow execution, together with a focus on resource-efficient usage.</text></s>
<s sid="511"><CoreSc1 advantage="None" conceptID="Con77" novelty="None" type="Con"/><text>All this can be achieved by a very low number of time- and energy-consuming VM reallocation actions for many of the autonomic management scenarios.</text></s>
Conclusion
<s sid="512"><CoreSc1 advantage="None" conceptID="Con78" novelty="None" type="Con"/><text>The goal of this research field is to enact SLAs in a resource-efficient way with little human-based interaction in order to guarantee the scalability and strengthen the dynamic behavior and adaptation of the system.</text></s>
<s sid="513"><CoreSc1 advantage="None" conceptID="Con79" novelty="None" type="Con"/><text>Autonomically governing Cloud Computing infrastructures is the investigated method leading to this goal.</text></s>
<s sid="514"><CoreSc1 advantage="None" conceptID="Con80" novelty="None" type="Con"/><text>In this paper we have hierarchically structured all possible reallocation actions, and designed, implemented, and evaluated two knowledge management techniques, Case Based Reasoning and a rule-based approach to achieve the aforementioned goal for one reallocation level, i.e., VM reconfiguration.</text></s>
<s sid="515"><CoreSc1 advantage="None" conceptID="Con81" novelty="None" type="Con"/><text>After a comparison, we determined the rule-based approach to outperform CBR with respect to violations and utilization, but also to time performance.</text></s>
<s sid="516"><CoreSc1 advantage="None" conceptID="Con82" novelty="None" type="Con"/><text>Furthermore, we applied the rule-based approach to a real-world use case evaluating a scientific workflow from the area of bioinformatics.</text></s>
<s sid="517"><CoreSc1 advantage="None" conceptID="Con83" novelty="None" type="Con"/><text>We showed by simulation that the rule-based approach can effectively guarantee the execution of a workload with unpredictably large resource consumptions.</text></s>
<s sid="518"><CoreSc1 advantage="None" conceptID="Con84" novelty="None" type="Con"/><text>The next step will be to move from simulation to a real Cloud testbed.</text></s>
<s sid="519"><CoreSc1 advantage="None" conceptID="Con85" novelty="None" type="Con"/><text>Furthermore, the presented methods still involve some user-interaction for parameter tuning.</text></s>
<s sid="520"><CoreSc1 advantage="None" conceptID="Con86" novelty="None" type="Con"/><text>Thus, it will be of great interest to autonomically determine crucial parameters of the presented methods and to adapt them based on current performance.</text></s>
<s sid="521"><CoreSc1 advantage="None" conceptID="Con87" novelty="None" type="Con"/><text>Another related field is the autonomic generation of IaaS SLA out of SaaS or PaaS SLAs.</text></s>
<s sid="522"><CoreSc1 advantage="None" conceptID="Con88" novelty="None" type="Con"/><text>Theoretically, SaaS or PaaS applications can be perfectly set up on top of IaaS platforms.</text></s>
<s sid="523"><CoreSc1 advantage="None" conceptID="Res232" novelty="None" type="Res"/><text>The crucial point is to extract an SLA for the IaaS parameters like bandwidth, storage, CPU power and memory that fit to SaaS/PaaS parameters like response time.</text></s>
<s sid="524"><CoreSc1 advantage="None" conceptID="Con89" novelty="None" type="Con"/><text>It is obvious that response time directly relates to the mentioned IaaS parameters and user interaction.</text></s>
<s sid="525"><CoreSc1 advantage="None" conceptID="Con90" novelty="None" type="Con"/><text>It is not that obvious, however, how this translation should take place.</text></s>
<s sid="526"><CoreSc1 advantage="None" conceptID="Con91" novelty="None" type="Con"/><text>E.g., does the SLO &quot; response time&lt;2 s&quot; translate into &quot; memory&gt;512 MB&quot; and &quot; CPU power&gt;8000 MIPS&quot; or rather &quot; memory&gt;4096 MB&quot; and &quot; CPU power&gt;1000 MIPS&quot;? Once the autonomic governance of IaaS infrastructures is up and running, the autonomic translation of these SLAs will probably leverage the usage and usability of IaaS even more.</text></s>
</BODY>
<OTHER>
Acknowledgments
The work described in this paper is supported by the Vienna Science and Technology Fund (WWTF) under grant agreement ICT08-018 Foundations of Self-Governing ICT Infrastructures (FoSII) and by COST-Action IC0804 on Energy Efficiency in Large Scale Distributed Systems.
We also want to thank Paweł P. Łabaj and David P. Kreil (Boku University Vienna) for providing us with the bioinformatics workflow application and Vincent C.
Emeakaroha (TU Vienna) for providing monitoring data on it.

</OTHER>
</PAPER>