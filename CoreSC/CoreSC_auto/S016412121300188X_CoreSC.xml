<?xml version="1.0" ?><PAPER><mode2 hasDoc="yes" name="S016412121300188X.tmf1" version="elsevier"/>
<TITLE>Coherent clusters in source code
</TITLE>
<ABSTRACT>

Highlights
•
<s sid="1"><CoreSc1 advantage="None" conceptID="Res1" novelty="None" type="Res"/><text>Introduction of efficient clustering algorithm.</text></s>
•
<s sid="2"><CoreSc1 advantage="None" conceptID="Res2" novelty="None" type="Res"/><text>Empirical analysis to assess the frequency and size of coherent clusters.</text></s>
•
<s sid="3"><CoreSc1 advantage="None" conceptID="Res3" novelty="None" type="Res"/><text>A series of case studies showing how clusters identify logical program structures.</text></s>
•
<s sid="4"><CoreSc1 advantage="None" conceptID="Res4" novelty="None" type="Res"/><text>A study on the relationship between coherent clusters and program faults.</text></s>
•
<s sid="5"><CoreSc1 advantage="None" conceptID="Res5" novelty="None" type="Res"/><text>A study on the relationship between coherent clusters and system evolution.</text></s>
Abstract
<s sid="6"><CoreSc1 advantage="None" conceptID="Obj1" novelty="None" type="Obj"/><text>This paper presents the results of a large scale empirical study of coherent dependence clusters.</text></s>
<s sid="7"><CoreSc1 advantage="None" conceptID="Obs1" novelty="None" type="Obs"/><text>All statements in a coherent dependence cluster depend upon the same set of statements and affect the same set of statements; a coherent cluster's statements have 'coherent' shared backward and forward dependence.</text></s>
<s sid="8"><CoreSc1 advantage="None" conceptID="Res6" novelty="None" type="Res"/><text>We introduce an approximation to efficiently locate coherent clusters and show that it has a minimum precision of 97.76%.</text></s>
<s sid="9"><CoreSc1 advantage="None" conceptID="Res7" novelty="None" type="Res"/><text>Our empirical study also finds that, despite their tight coherence constraints, coherent dependence clusters are in abundance: 23 of the 30 programs studied have coherent clusters that contain at least 10% of the whole program.</text></s>
<s sid="10"><CoreSc1 advantage="None" conceptID="Res8" novelty="None" type="Res"/><text>Studying patterns of clustering in these programs reveals that most programs contain multiple substantial coherent clusters.</text></s>
<s sid="11"><CoreSc1 advantage="None" conceptID="Res9" novelty="None" type="Res"/><text>A series of subsequent case studies uncover that all clusters of significant size map to a logical functionality and correspond to a program structure.</text></s>
<s sid="12"><CoreSc1 advantage="None" conceptID="Res10" novelty="None" type="Res"/><text>For example, we show that for the program acct, the top five coherent clusters all map to specific, yet otherwise non-obvious, functionality.</text></s>
<s sid="13"><CoreSc1 advantage="None" conceptID="Bac1" novelty="None" type="Bac"/><text>Cluster visualization also brings out subtle deficiencies in program structure and identifies potential refactoring candidates.</text></s>
<s sid="14"><CoreSc1 advantage="None" conceptID="Bac2" novelty="None" type="Bac"/><text>A study of inter-cluster dependence is used to highlight how coherent clusters are connected to each other, revealing higher-level structures, which can be used in reverse engineering.</text></s>
<s sid="15"><CoreSc1 advantage="None" conceptID="Mot1" novelty="None" type="Mot"/><text>Finally, studies are presented to illustrate how clusters are not correlated with program faults as they remain stable during most system evolution.</text></s>
</ABSTRACT>
<BODY>

Introduction
<s sid="16"><CoreSc1 advantage="None" conceptID="Mot2" novelty="None" type="Mot"/><text>Program dependence analysis is a foundation for many activities in software engineering such as testing, comprehension, and impact analysis (Binkley, 2007).</text></s>
<s sid="17"><CoreSc1 advantage="None" conceptID="Mot3" novelty="None" type="Mot"/><text>For example, it is essential to understand the relationships between different parts of a system when making changes and the impacts of these changes (Gallagher and Lyle, 1991).</text></s>
<s sid="18"><CoreSc1 advantage="None" conceptID="Bac3" novelty="None" type="Bac"/><text>This has led to both static (Yau and Collofello, 1985; Black, 2001) and blended (static and dynamic) (Ren et al., 2006, 2005) dependence analyses of the relationships between dependence and impact.</text></s>
<s sid="19"><CoreSc1 advantage="None" conceptID="Bac4" novelty="None" type="Bac"/><text>One important property of dependence is the way in which it may cluster.</text></s>
<s sid="20"><CoreSc1 advantage="None" conceptID="Bac5" novelty="None" type="Bac"/><text>This occurs when a set of statements all depend upon one another, forming a dependence cluster.</text></s>
<s sid="21"><CoreSc1 advantage="None" conceptID="Bac6" novelty="None" type="Bac"/><text>Within such a cluster, any change to an element potentially affects every other element of the cluster.</text></s>
<s sid="22"><CoreSc1 advantage="None" conceptID="Bac7" novelty="None" type="Bac"/><text>If such a dependence cluster is very large, then this mutual dependence clearly has implications related to the cost of maintaining the code.</text></s>
<s sid="23"><CoreSc1 advantage="None" conceptID="Goa1" novelty="None" type="Goa"/><text>In previous work (Binkley and Harman, 2005), we introduced the study of dependence clusters in terms of program slicing and demonstrated that large dependence clusters were (perhaps surprisingly) common, both in production (closed source) code and in open source code (Harman et al., 2009).</text></s>
<s sid="24"><CoreSc1 advantage="None" conceptID="Goa2" novelty="None" type="Goa"/><text>Our findings over a large corpus of C code was that 89% of the programs studied contained at least one dependence cluster composed of 10% or more of the program's statements.</text></s>
<s sid="25"><CoreSc1 advantage="None" conceptID="Goa3" novelty="None" type="Goa"/><text>The average size of the programs studied was 20KLoC, so these clusters of more than 10% denoted significant portions of code.</text></s>
<s sid="26"><CoreSc1 advantage="None" conceptID="Goa4" novelty="None" type="Goa"/><text>We also found evidence of super-large clusters: 40% of the programs had a dependence cluster that consumed over half of the program.</text></s>
<s sid="27"><CoreSc1 advantage="None" conceptID="Bac8" novelty="None" type="Bac"/><text>More recently, our finding that large clusters are widespread in C systems has been replicated for other languages and systems by other authors, both in open source and in proprietary code (Acharya and Robinson, 2011; Beszédes et al., 2007; Szegedi et al., 2007).</text></s>
<s sid="28"><CoreSc1 advantage="None" conceptID="Bac9" novelty="None" type="Bac"/><text>Large dependence clusters were also found in Java systems (Beszédes et al., 2007; Savernik, 2007; Szegedi et al., 2007) and in legacy Cobol systems (Hajnal and Forgács, 2011).</text></s>
<s sid="29"><CoreSc1 advantage="None" conceptID="Bac10" novelty="None" type="Bac"/><text>There has been interesting work on the relationship between faults, program size, and dependence clusters (Black et al., 2006), and between impact analysis and dependence clusters (Acharya and Robinson, 2011; Harman et al., 2009).</text></s>
<s sid="30"><CoreSc1 advantage="None" conceptID="Bac11" novelty="None" type="Bac"/><text>Large dependence clusters can be thought of as dependence 'anti-patterns' because of the high impact that a change anywhere in the cluster has.</text></s>
<s sid="31"><CoreSc1 advantage="None" conceptID="Bac12" novelty="None" type="Bac"/><text>For example, it may lead to problems for on-going software maintenance and evolution (Acharya and Robinson, 2011; Binkley et al., 2008; Savernik, 2007).</text></s>
<s sid="32"><CoreSc1 advantage="None" conceptID="Bac13" novelty="None" type="Bac"/><text>As a result, refactoring has been proposed as a technique for breaking larger clusters of dependence into smaller clusters (Binkley and Harman, 2005; Black et al., 2009).</text></s>
<s sid="33"><CoreSc1 advantage="None" conceptID="Bac14" novelty="None" type="Bac"/><text>Dependence cluster analysis is complicated by the fact that inter-procedural program dependence is non-transitive, which means that the statements in a traditional dependence cluster, though they all depend on each other, may not each depend on the same set of statements, nor need they necessarily affect the same set of statements external to the cluster.</text></s>
<s sid="34"><CoreSc1 advantage="None" conceptID="Bac15" novelty="None" type="Bac"/><text>This paper introduces and empirically studies11</text></s>
<s sid="35"><CoreSc1 advantage="None" conceptID="Bac16" novelty="None" type="Bac"/><text>Preliminary results were presented at PASTE (Islam et al., 2010b).</text></s>
 coherent dependence clusters.
<s sid="36"><CoreSc1 advantage="None" conceptID="Bac17" novelty="None" type="Bac"/><text>In a coherent dependence cluster all statements share identical intra-cluster and extra-cluster dependence.</text></s>
<s sid="37"><CoreSc1 advantage="None" conceptID="Bac18" novelty="None" type="Bac"/><text>A coherent dependence cluster is thus more constrained than a general dependence cluster.</text></s>
<s sid="38"><CoreSc1 advantage="None" conceptID="Obs2" novelty="None" type="Obs"/><text>A coherent dependence cluster retains the essential property that all statements within the cluster are mutually dependent, but adds the constraint that all incoming dependence must be identical and all outgoing dependence must also be identical.</text></s>
<s sid="39"><CoreSc1 advantage="None" conceptID="Obs3" novelty="None" type="Obs"/><text>That is, all statements within a coherent cluster depend upon the same set of statements outside the cluster and all statements within a coherent cluster affect the same set of statements outside the cluster.</text></s>
<s sid="40"><CoreSc1 advantage="None" conceptID="Mot4" novelty="None" type="Mot"/><text>This means that, when studying a coherent cluster, we need to understand only a single external dependence context in order to understand the behavior of the entire cluster.</text></s>
<s sid="41"><CoreSc1 advantage="None" conceptID="Mot5" novelty="None" type="Mot"/><text>For a dependence cluster that fails to meet the external constraint, statements of the cluster may have a different external dependence context.</text></s>
<s sid="42"><CoreSc1 advantage="None" conceptID="Mot6" novelty="None" type="Mot"/><text>This is possible because inter-procedural dependence is non-transitive.</text></s>
<s sid="43"><CoreSc1 advantage="None" conceptID="Hyp1" novelty="None" type="Hyp"/><text>It might be thought that very few sets of statements would meet these additional coherence constraints, or that, where such sets of statements do meet the constraints, there would be relatively few statements in the coherent cluster so-formed.</text></s>
<s sid="44"><CoreSc1 advantage="None" conceptID="Res11" novelty="None" type="Res"/><text>Our empirical findings provide evidence that this is not the case: coherent dependence clusters are common and they can be very large.</text></s>
<s sid="45"><CoreSc1 advantage="None" conceptID="Goa5" novelty="None" type="Goa"/><text>This paper is part of a series of work that we have conducted in the area of dependence clusters.</text></s>
<s sid="46"><CoreSc1 advantage="None" conceptID="Goa6" novelty="None" type="Goa"/><text>The overarching motivation for this work is to gain a better understanding of the dependence clusters found in programs.</text></s>
<s sid="47"><CoreSc1 advantage="None" conceptID="Goa7" novelty="None" type="Goa"/><text>Although this paper is a continuation of our previous work on dependence clusters, we present the work in a completely new light.</text></s>
<s sid="48"><CoreSc1 advantage="None" conceptID="Goa8" novelty="None" type="Goa"/><text>In this paper we show that the specialized version of dependence clusters, coherent clusters are found in abundance in programs and need not be regarded as problems.</text></s>
<s sid="49"><CoreSc1 advantage="None" conceptID="Goa9" novelty="None" type="Goa"/><text>We rather show that these clusters map to logical program structures which will aid developers in program comprehension and understanding.</text></s>
<s sid="50"><CoreSc1 advantage="None" conceptID="Goa10" novelty="None" type="Goa"/><text>Furthermore, this paper extends the current knowledge in the area and motivates future work by presenting initial results of inter-cluster dependence which can be used as a foundation for reverse engineering.</text></s>
<s sid="51"><CoreSc1 advantage="None" conceptID="Goa11" novelty="None" type="Goa"/><text>We answer several representative open questions such as whether clusters are related to program faults and how clusters change over time during system evolution.</text></s>
<s sid="52"><CoreSc1 advantage="None" conceptID="Bac19" novelty="None" type="Bac"/><text>The primary contributions of the paper are as follows:1</text></s>
<s sid="53"><CoreSc1 advantage="None" conceptID="Bac20" novelty="None" type="Bac"/><text>An Empirical analysis of thirty programs assesses the frequency and size of coherent dependence clusters.</text></s>
<s sid="54"><CoreSc1 advantage="None" conceptID="Bac21" novelty="None" type="Bac"/><text>The results demonstrate that large coherent clusters are common, validating their further study.</text></s>
2
<s sid="55"><CoreSc1 advantage="None" conceptID="Obj2" novelty="None" type="Obj"/><text>Two further empirical validation studies consider the impact of data-flow analysis precision and the precision of the approximation used to efficiently identify coherent clusters.</text></s>
3
<s sid="56"><CoreSc1 advantage="None" conceptID="Res12" novelty="None" type="Res"/><text>A series of four case studies shows how coherent clusters map to logical program structures.</text></s>
4
<s sid="57"><CoreSc1 advantage="None" conceptID="Res13" novelty="None" type="Res"/><text>A study of inter-cluster dependence highlights how coherent clusters form the building blocks of larger dependence structures where identification can support, as an example, reverse engineering.</text></s>
5
<s sid="58"><CoreSc1 advantage="None" conceptID="Res14" novelty="None" type="Res"/><text>A study of bug fixes finds no relationship between program faults and coherent clusters implying that dependence clusters are not responsible for program faults.</text></s>
6
<s sid="59"><CoreSc1 advantage="None" conceptID="Res15" novelty="None" type="Res"/><text>A longitudinal study of system evolution shows that coherent clusters remain stable during evolution thus depicting the core architecture of systems.</text></s>
<s sid="60"><CoreSc1 advantage="None" conceptID="Res16" novelty="None" type="Res"/><text>The remainder of this paper is organized as follows: Section 2 provides background on coherent clusters and their visualization.</text></s>
<s sid="61"><CoreSc1 advantage="None" conceptID="Res17" novelty="None" type="Res"/><text>Section 3 provides details on the subject programs, the validation of the slice approximation used, and the experimental setup.</text></s>
<s sid="62"><CoreSc1 advantage="None" conceptID="Res18" novelty="None" type="Res"/><text>This is followed by quantitative and qualitative studies into the existence and impact of coherent dependence clusters and the inter-cluster dependence study.</text></s>
<s sid="63"><CoreSc1 advantage="None" conceptID="Obj3" novelty="None" type="Obj"/><text>It also includes studies on program faults and system evolution and their relationship to coherent clusters.</text></s>
<s sid="64"><CoreSc1 advantage="None" conceptID="Obj4" novelty="None" type="Obj"/><text>Section 4 considers related work and finally, Section 5 summarizes the work presented.</text></s>
Background
<s sid="65"><CoreSc1 advantage="None" conceptID="Obj5" novelty="None" type="Obj"/><text>This section provides background on dependence clusters.</text></s>
<s sid="66"><CoreSc1 advantage="None" conceptID="Obj6" novelty="None" type="Obj"/><text>It first presents a sequence of definitions that culminate in the definition for a coherent dependence cluster.</text></s>
<s sid="67"><CoreSc1 advantage="None" conceptID="Bac22" novelty="None" type="Bac"/><text>Previous work (Binkley and Harman, 2005; Harman et al., 2009) has used the term dependence cluster for a particular kind of cluster, termed a mutually-dependent cluster herein to emphasize that such clusters consider only mutual dependence internal to the cluster.</text></s>
<s sid="68"><CoreSc1 advantage="None" conceptID="Bac23" novelty="None" type="Bac"/><text>This distinction allows the definition to be extended to incorporate external dependence.</text></s>
<s sid="69"><CoreSc1 advantage="None" conceptID="Bac24" novelty="None" type="Bac"/><text>The section also reviews the current graph-based visualizations for dependence clusters.</text></s>
Dependence clusters
<s sid="70"><CoreSc1 advantage="None" conceptID="Bac25" novelty="None" type="Bac"/><text>Informally, mutually-dependent clusters are maximal sets of program statements that mutually depend upon one another (Harman et al., 2009).</text></s>
<s sid="71"><CoreSc1 advantage="None" conceptID="Bac26" novelty="None" type="Bac"/><text>They are formalized in terms of mutually dependent sets in the following definition.</text></s>
Definition 2.1
<s sid="72"><CoreSc1 advantage="None" conceptID="Bac27" novelty="None" type="Bac"/><text>Mutually-dependent set and cluster (Harman et al., 2009)</text></s>
<s sid="73"><CoreSc1 advantage="None" conceptID="Bac28" novelty="None" type="Bac"/><text>A mutually-dependent set (MDS) is a set of statements, S, such that</text></s>
<s sid="74"><CoreSc1 advantage="None" conceptID="Bac29" novelty="None" type="Bac"/><text>∀x, y∈S:x depends on y.</text></s>
<s sid="75"><CoreSc1 advantage="None" conceptID="Bac30" novelty="None" type="Bac"/><text>A mutually-dependent cluster is a maximal MDS; thus, it is an MDS not properly contained within another MDS.</text></s>
<s sid="76"><CoreSc1 advantage="None" conceptID="Bac31" novelty="None" type="Bac"/><text>The definition of an MDS is parameterized by an underlying depends-on relation.</text></s>
<s sid="77"><CoreSc1 advantage="None" conceptID="Bac32" novelty="None" type="Bac"/><text>Ideally, such a relation would precisely capture the impact, influence, and dependence between statements.</text></s>
<s sid="78"><CoreSc1 advantage="None" conceptID="Bac33" novelty="None" type="Bac"/><text>Unfortunately, such a relation is not computable (Weiser, 1984).</text></s>
<s sid="79"><CoreSc1 advantage="None" conceptID="Bac34" novelty="None" type="Bac"/><text>A well known approximation is based on Weiser's program slice (Weiser, 1984): a slice is the set of program statements that affect the values computed at a particular statement of interest (referred to as a slicing criterion).</text></s>
<s sid="80"><CoreSc1 advantage="None" conceptID="Bac35" novelty="None" type="Bac"/><text>While its computation is undecidable, a minimal (or precise) slice includes exactly those program elements that affect the criterion and thus can be used to define an MDS in which t depends on s iff s is in the minimal slice taken with respect to slicing criterion t.</text></s>
<s sid="81"><CoreSc1 advantage="None" conceptID="Met1" novelty="None" type="Met"/><text>The slice-based definition is useful because algorithms to compute approximations to minimal slices can be used to define and compute approximations to mutually-dependent clusters.</text></s>
<s sid="82"><CoreSc1 advantage="None" conceptID="Met2" novelty="None" type="Met"/><text>One such algorithm computes a slice as the solution to a reachability problem over a program's System Dependence Graph (SDG) (Horwitz et al., 1990).</text></s>
<s sid="83"><CoreSc1 advantage="None" conceptID="Bac36" novelty="None" type="Bac"/><text>An SDG is comprised of vertices, which essentially represent the statements of the program and two kinds of edges: data dependence edges and control dependence edges.</text></s>
<s sid="84"><CoreSc1 advantage="None" conceptID="Bac37" novelty="None" type="Bac"/><text>A data dependence connects a definition of a variable with each use of the variable reached by the definition (Ferrante et al., 1987).</text></s>
<s sid="85"><CoreSc1 advantage="None" conceptID="Bac38" novelty="None" type="Bac"/><text>Control dependence connects a predicate p to a vertex v when p has at least two control-flow-graph successors, one of which can lead to the exit vertex without encountering v and the other always leads eventually to v (Ferrante et al., 1987).</text></s>
<s sid="86"><CoreSc1 advantage="None" conceptID="Bac39" novelty="None" type="Bac"/><text>Thus p controls the possible future execution of v.</text></s>
<s sid="87"><CoreSc1 advantage="None" conceptID="Bac40" novelty="None" type="Bac"/><text>For structured code, control dependence reflects the nesting structure of the program.</text></s>
<s sid="88"><CoreSc1 advantage="None" conceptID="Bac41" novelty="None" type="Bac"/><text>When slicing an SDG, a slicing criterion is a vertex from the SDG.</text></s>
<s sid="89"><CoreSc1 advantage="None" conceptID="Bac42" novelty="None" type="Bac"/><text>A naïve definition of a dependence cluster would be based on the transitive closure of the dependence relation and thus would define a cluster to be a strongly connected component.</text></s>
<s sid="90"><CoreSc1 advantage="None" conceptID="Bac43" novelty="None" type="Bac"/><text>Unfortunately, for certain language features, dependence is non-transitive.</text></s>
<s sid="91"><CoreSc1 advantage="None" conceptID="Bac44" novelty="None" type="Bac"/><text>Examples of such features include procedures (Horwitz et al., 1990) and threads (Krinke, 1998).</text></s>
<s sid="92"><CoreSc1 advantage="None" conceptID="Bac45" novelty="None" type="Bac"/><text>Thus, in the presence of these features, strongly connected components overstate the size and number of dependence clusters.</text></s>
<s sid="93"><CoreSc1 advantage="None" conceptID="Bac46" novelty="None" type="Bac"/><text>Fortunately, context-sensitive slicing captures the necessary context information (Binkley and Harman, 2005, 2003; Horwitz et al., 1990; Krinke, 2002, 2003).</text></s>
<s sid="94"><CoreSc1 advantage="None" conceptID="Bac47" novelty="None" type="Bac"/><text>Two kinds of SDG slices are used in this paper: backward slices and forward slices (Horwitz et al., 1990; Ottenstein and Ottenstein, 1984).</text></s>
<s sid="95"><CoreSc1 advantage="None" conceptID="Mod1" novelty="None" type="Mod"/><text>The backward slice taken with respect to vertex v, denoted BSlice(v), is the set of vertices reaching v via a path of control and data dependence edges where this path respects context.</text></s>
<s sid="96"><CoreSc1 advantage="None" conceptID="Mod2" novelty="None" type="Mod"/><text>The forward slice, taken with respect to vertex v, denoted FSlice(v), is the set of vertices reachable from v via a path of control and data dependence edges where this path respects context.</text></s>
<s sid="97"><CoreSc1 advantage="None" conceptID="Obs4" novelty="None" type="Obs"/><text>The program P shown in Fig. 1 illustrates the non-transitivity of slice inclusion.</text></s>
<s sid="98"><CoreSc1 advantage="None" conceptID="Obs5" novelty="None" type="Obs"/><text>The program has six assignment statements (assigning the variables a, b, c, d, e and f) whose dependencies are shown in columns 1-6 as backward slice inclusion.</text></s>
<s sid="99"><CoreSc1 advantage="None" conceptID="Obs6" novelty="None" type="Obs"/><text>Backward slice inclusion contains statements that affect the slicing criterion through data and control dependence.</text></s>
<s sid="100"><CoreSc1 advantage="None" conceptID="Obs7" novelty="None" type="Obs"/><text>The dependence relationship between these statements is also extracted and shown in Fig. 2 using a directed graph where the nodes of the graph represent the assignment statements and the edges represent the backward slice inclusion relationship from Fig. 1.</text></s>
<s sid="101"><CoreSc1 advantage="None" conceptID="Obs8" novelty="None" type="Obs"/><text>The table on the right in Fig. 2 also gives the forward slice inclusions for the statements.</text></s>
<s sid="102"><CoreSc1 advantage="None" conceptID="Obs9" novelty="None" type="Obs"/><text>All other statements in P, which do not define a variable, are ignored.</text></s>
<s sid="103"><CoreSc1 advantage="None" conceptID="Res19" novelty="None" type="Res"/><text>In the diagram, x depends on y (y ∈ BSlice(x)) is represented by y → x.</text></s>
<s sid="104"><CoreSc1 advantage="None" conceptID="Res20" novelty="None" type="Res"/><text>The diagram shows two instances of dependence intransitivity in P. Although b depends on nodes a, c, and d, node f, which depends on b, does not depend on a, c, or d.</text></s>
<s sid="105"><CoreSc1 advantage="None" conceptID="Res21" novelty="None" type="Res"/><text>Similarly, d depends on e but a, b, and c, which depend on d do not depend on e.</text></s>
Slice-based clusters
<s sid="106"><CoreSc1 advantage="None" conceptID="Bac48" novelty="None" type="Bac"/><text>A slice-based cluster is a maximal set of vertices included in each other's slice.</text></s>
<s sid="107"><CoreSc1 advantage="None" conceptID="Bac49" novelty="None" type="Bac"/><text>The following definition essentially instantiates Definition 2.1 using BSlice.</text></s>
<s sid="108"><CoreSc1 advantage="None" conceptID="Bac50" novelty="None" type="Bac"/><text>Because x∈BSlice(y)⇔y∈FSlice(x) the dual of this definition using FSlice is equivalent.</text></s>
<s sid="109"><CoreSc1 advantage="None" conceptID="Bac51" novelty="None" type="Bac"/><text>Where such a duality does not hold, both definitions are given.</text></s>
<s sid="110"><CoreSc1 advantage="None" conceptID="Bac52" novelty="None" type="Bac"/><text>When it is important to differentiate between the two, the terms backward and forward will be added to the definition's name as is done in this section.</text></s>
Definition 2.2
<s sid="111"><CoreSc1 advantage="None" conceptID="Bac53" novelty="None" type="Bac"/><text>Backward-slice MDS and cluster (Harman et al., 2009)</text></s>
<s sid="112"><CoreSc1 advantage="None" conceptID="Mod3" novelty="None" type="Mod"/><text>A backward-slice MDS is a set of SDG vertices, V, such that</text></s>
∀x, y∈V:x∈BSlice(y).
<s sid="113"><CoreSc1 advantage="None" conceptID="Mod4" novelty="None" type="Mod"/><text>A backward-slice cluster is a backward-slice MDS contained within no other backward-slice MDS.</text></s>
<s sid="114"><CoreSc1 advantage="None" conceptID="Mod5" novelty="None" type="Mod"/><text>Note that as x and y are interchangeable, this is equivalent to ∀x, y∈V:x∈BSlice(y)∧y∈BSlice(x).</text></s>
<s sid="115"><CoreSc1 advantage="None" conceptID="Mod6" novelty="None" type="Mod"/><text>Thus, any unordered pair (x, y) with x∈BSlice(y)∧y∈BSlice(x) creates an edge (x, y) in an undirected graph in which a complete subgraph is equivalent to a backward-slice MDS and a backward-slice cluster is equivalent to a maximal clique.</text></s>
<s sid="116"><CoreSc1 advantage="None" conceptID="Mod7" novelty="None" type="Mod"/><text>Therefore, the clustering problem is the NP-Hard maximal cliques problem (Bomze et al., 1999) making Definition 2.2 prohibitively expensive to implement.</text></s>
<s sid="117"><CoreSc1 advantage="None" conceptID="Obs10" novelty="None" type="Obs"/><text>In the example shown in Fig. 2, the vertices representing the assignments to a, b, c and d are all in each others backward slices and hence satisfy the definition of a backward-slice cluster.</text></s>
<s sid="118"><CoreSc1 advantage="None" conceptID="Obs11" novelty="None" type="Obs"/><text>These vertices also satisfy the definition of a forward-slice cluster as they are also in each others forward slices.</text></s>
<s sid="119"><CoreSc1 advantage="None" conceptID="Obs12" novelty="None" type="Obs"/><text>As dependence is not transitive, a statement can be in multiple slice-based clusters.</text></s>
<s sid="120"><CoreSc1 advantage="None" conceptID="Obs13" novelty="None" type="Obs"/><text>For example, in Fig. 2 the statements d and e are mutually dependent upon each other and thus satisfy the definition of a slice-based cluster.</text></s>
<s sid="121"><CoreSc1 advantage="None" conceptID="Obs14" novelty="None" type="Obs"/><text>Statement d is also mutually dependent on statements a, b, c, thus the set {a, b, c, d} also satisfies the definition of a slice-based cluster.</text></s>
Same-slice clusters
<s sid="122"><CoreSc1 advantage="None" conceptID="Obj7" novelty="None" type="Obj"/><text>An alternative definition uses the same-slice relation in place of slice inclusion (Binkley and Harman, 2005).</text></s>
<s sid="123"><CoreSc1 advantage="None" conceptID="Obj8" novelty="None" type="Obj"/><text>This relation replaces the need to check if two vertices are in each others slice with checking if two vertices have the same slice.</text></s>
<s sid="124"><CoreSc1 advantage="None" conceptID="Obj9" novelty="None" type="Obj"/><text>The result is captured in the following definitions for same-slice cluster.</text></s>
<s sid="125"><CoreSc1 advantage="None" conceptID="Obs15" novelty="None" type="Obs"/><text>The first uses backward slices and the second forward slices.</text></s>
Definition 2.3
<s sid="126"><CoreSc1 advantage="None" conceptID="Obs16" novelty="None" type="Obs"/><text>Same-slice MDS and cluster (Harman et al., 2009)</text></s>
<s sid="127"><CoreSc1 advantage="None" conceptID="Obs17" novelty="None" type="Obs"/><text>A same-backward-slice MDS is a set of SDG vertices, V, such that</text></s>
∀x, y∈V:BSlice(x)=BSlice(y).
<s sid="128"><CoreSc1 advantage="None" conceptID="Obs18" novelty="None" type="Obs"/><text>A same-backward-slice cluster is a same-backward-slice MDS contained within no other same-backward-slice MDS.</text></s>
<s sid="129"><CoreSc1 advantage="None" conceptID="Obs19" novelty="None" type="Obs"/><text>A same-forward-slice MDS is a set of SDG vertices, V, such that</text></s>
∀x, y∈V:FSlice(x)=FSlice(y).
<s sid="130"><CoreSc1 advantage="None" conceptID="Obs20" novelty="None" type="Obs"/><text>A same-forward-slice cluster is a same-forward-slice MDS contained within no other same-forward-slice MDS.</text></s>
<s sid="131"><CoreSc1 advantage="None" conceptID="Obs21" novelty="None" type="Obs"/><text>Because x∈BSlice(x) and x∈FSlice(x), two vertices that have the same slice will always be in each other's slice.</text></s>
<s sid="132"><CoreSc1 advantage="None" conceptID="Obs22" novelty="None" type="Obs"/><text>If slice inclusion were transitive, a backward-slice MDS (Definition 2.2) would be identical to a same-backward-slice MDS (Definition 2.3).</text></s>
<s sid="133"><CoreSc1 advantage="None" conceptID="Obs23" novelty="None" type="Obs"/><text>However, as illustrated by the examples in Fig. 1, slice inclusion is not transitive; thus, the relation is one of containment where every same-backward-slice MDS is also a backward-slice MDS but not necessarily a maximal one.</text></s>
<s sid="134"><CoreSc1 advantage="None" conceptID="Obs24" novelty="None" type="Obs"/><text>For example, in Fig. 2 the set of vertices {a, b, c} form a same-backward-slice cluster because each vertex of the set yields the same backward slice.</text></s>
<s sid="135"><CoreSc1 advantage="None" conceptID="Obs25" novelty="None" type="Obs"/><text>Whereas the set of vertices {a, c} form a same-forward-slice cluster as they have the same forward slice.</text></s>
<s sid="136"><CoreSc1 advantage="None" conceptID="Obs26" novelty="None" type="Obs"/><text>Although vertex d is mutually dependent with all vertices of either set, it does not form the same-slice cluster with either set because it has an additional dependence relationship with vertex e.</text></s>
<s sid="137"><CoreSc1 advantage="None" conceptID="Obs27" novelty="None" type="Obs"/><text>Although the introduction of same-slice clusters was motivated by the need for efficiency, the definition inadvertently introduced an external requirement on the cluster.</text></s>
<s sid="138"><CoreSc1 advantage="None" conceptID="Obs28" novelty="None" type="Obs"/><text>Comparing the definitions for slice-based clusters (Definition 2.2) and same-slice clusters (Definition 2.3), a slice-based cluster includes only the internal requirement that the vertices of a cluster depend upon one another.</text></s>
<s sid="139"><CoreSc1 advantage="None" conceptID="Obs29" novelty="None" type="Obs"/><text>However, a same-backward-slice cluster (inadvertently) adds to this internal requirement the external requirement that all vertices in the cluster are affected by the same vertices external to the cluster.</text></s>
<s sid="140"><CoreSc1 advantage="None" conceptID="Obs30" novelty="None" type="Obs"/><text>Symmetrically, a same-forward-slice cluster adds the external requirement that all vertices in the cluster affect the same vertices external to the cluster.</text></s>
Coherent dependence clusters
<s sid="141"><CoreSc1 advantage="None" conceptID="Obj10" novelty="None" type="Obj"/><text>This subsection first formalizes the notion of coherent dependence clusters and then presents a slice-based instantiation of the definition.</text></s>
<s sid="142"><CoreSc1 advantage="None" conceptID="Mod8" novelty="None" type="Mod"/><text>Coherent clusters are dependence clusters that include not only an internal dependence requirement (each statement of a cluster depends on all the other statements of the cluster) but also an external dependence requirement.</text></s>
<s sid="143"><CoreSc1 advantage="None" conceptID="Mod9" novelty="None" type="Mod"/><text>The external dependence requirement includes both that each statement of a cluster depends on the same statements external to the cluster and also that it influences the same set of statements external to the cluster.</text></s>
<s sid="144"><CoreSc1 advantage="None" conceptID="Mod10" novelty="None" type="Mod"/><text>In other words, a coherent cluster is a set of statements that are mutually dependent and share identical extra-cluster dependence.</text></s>
<s sid="145"><CoreSc1 advantage="None" conceptID="Mod11" novelty="None" type="Mod"/><text>Coherent clusters are defined in terms of the coherent MDS:</text></s>
Definition 2.4
<s sid="146"><CoreSc1 advantage="None" conceptID="Mod12" novelty="None" type="Mod"/><text>Coherent MDS and cluster (Islam et al., 2010b)</text></s>
<s sid="147"><CoreSc1 advantage="None" conceptID="Mod13" novelty="None" type="Mod"/><text>A coherent MDS is a MDS V, such that</text></s>
<s sid="148"><CoreSc1 advantage="None" conceptID="Mod14" novelty="None" type="Mod"/><text>∀x, y∈V: x depends on a implies y depends on a and a depends on x implies a depends on y.</text></s>
<s sid="149"><CoreSc1 advantage="None" conceptID="Mod15" novelty="None" type="Mod"/><text>A coherent cluster is a coherent MDS contained within no other coherent MDS.</text></s>
<s sid="150"><CoreSc1 advantage="None" conceptID="Mod16" novelty="None" type="Mod"/><text>The slice-based instantiation of coherent cluster employs both backward and forward slices.</text></s>
<s sid="151"><CoreSc1 advantage="None" conceptID="Mod17" novelty="None" type="Mod"/><text>The combination has the advantage that the entire cluster is both affected by the same set of vertices (as in the case of same-backward-slice clusters) and also affects the same set of vertices (as in the case of same-forward-slice clusters).</text></s>
<s sid="152"><CoreSc1 advantage="None" conceptID="Mod18" novelty="None" type="Mod"/><text>In the slice-based instantiation, a set of vertices V forms a coherent MDS if</text></s>
<s sid="153"><CoreSc1 advantage="None" conceptID="Mod19" novelty="None" type="Mod"/><text>∀x, y∈V:x∈BSlice(y)the internal requirement of an MDS∧a∈BSlice(x)⇒a∈BSlice(y)x and y depend on same external a∧a∈FSlice(x)⇒a∈FSlice(y)x and y impact on same external a</text></s>
<s sid="154"><CoreSc1 advantage="None" conceptID="Mod20" novelty="None" type="Mod"/><text>Because x and y are interchangeable</text></s>
<s sid="155"><CoreSc1 advantage="None" conceptID="Mod21" novelty="None" type="Mod"/><text>∀x,y∈V:x∈BSlice(y)∧ a∈BSlice(x) ⇒ a∈BSlice(y)∧ a∈FSlice(x) ⇒ a∈FSlice(y)∧ y∈BSlice(x)∧ a∈BSlice(y) ⇒ a∈BSlice(x)∧ a∈FSlice(y) ⇒ a∈FSlice(x)This is equivalent to</text></s>
<s sid="156"><CoreSc1 advantage="None" conceptID="Mod22" novelty="None" type="Mod"/><text>∀x,y∈V:x∈BSlice(y)∧y∈BSlice(x)∧ (a∈BSlice(x)⇔a∈BSlice(y))∧ (a∈FSlice(x)⇔a∈FSlice(y))which simplifies to</text></s>
<s sid="157"><CoreSc1 advantage="None" conceptID="Mod23" novelty="None" type="Mod"/><text>∀x,y∈V:BSlice(x)=BSlice(y)∧FSlice(x)=FSlice(y)and can be used to define coherent-slice MDS and clusters:</text></s>
Definition 2.5
<s sid="158"><CoreSc1 advantage="None" conceptID="Mod24" novelty="None" type="Mod"/><text>Coherent-slice MDS and cluster (Islam et al., 2010b)</text></s>
<s sid="159"><CoreSc1 advantage="None" conceptID="Mod25" novelty="None" type="Mod"/><text>A coherent-slice MDS is a set of SDG vertices, V, such that</text></s>
∀x, y∈V:BSlice(x)=BSlice(y)∧FSlice(x)=FSlice(y)
<s sid="160"><CoreSc1 advantage="None" conceptID="Obs31" novelty="None" type="Obs"/><text>A coherent-slice cluster is a coherent-slice MDS contained within no other coherent-slice MDS.</text></s>
<s sid="161"><CoreSc1 advantage="None" conceptID="Res22" novelty="None" type="Res"/><text>At first glance the use of both backward and forward slices might seem redundant because x∈BSlice(y)⇔y∈FSlice(x).</text></s>
<s sid="162"><CoreSc1 advantage="None" conceptID="Res23" novelty="None" type="Res"/><text>This is true up to a point: for the internal requirement of a coherent-slice cluster, the use of either BSlice or FSlice would suffice.</text></s>
<s sid="163"><CoreSc1 advantage="None" conceptID="Res24" novelty="None" type="Res"/><text>However, the two are not redundant when it comes to the external requirements of a coherent-slice cluster.</text></s>
<s sid="164"><CoreSc1 advantage="None" conceptID="Res25" novelty="None" type="Res"/><text>With a mutually-dependent cluster (Definition 2.1), it is possible for two vertices within the cluster to influence or be affected by different vertices external to the cluster.</text></s>
<s sid="165"><CoreSc1 advantage="None" conceptID="Res26" novelty="None" type="Res"/><text>Neither is allowed with a coherent-slice cluster.</text></s>
<s sid="166"><CoreSc1 advantage="None" conceptID="Res27" novelty="None" type="Res"/><text>To ensure that both external effects are captured, both backward and forward slices are required for coherent-slice clusters.</text></s>
<s sid="167"><CoreSc1 advantage="None" conceptID="Obs32" novelty="None" type="Obs"/><text>In Fig. 2 the set of vertices {a, c} form a coherent cluster as both these vertices have exactly the same backward and forward slices.</text></s>
<s sid="168"><CoreSc1 advantage="None" conceptID="Obs33" novelty="None" type="Obs"/><text>That is, they share identical intra- and extra-cluster dependencies.</text></s>
<s sid="169"><CoreSc1 advantage="None" conceptID="Obs34" novelty="None" type="Obs"/><text>Coherent clusters are therefore a stricter from of same-slice clusters, all coherent clusters are also same-slice MDS but not necessarily maximal.</text></s>
<s sid="170"><CoreSc1 advantage="None" conceptID="Obs35" novelty="None" type="Obs"/><text>It is worth noting that same-slice clusters partially share extra-cluster dependency.</text></s>
<s sid="171"><CoreSc1 advantage="None" conceptID="Obs36" novelty="None" type="Obs"/><text>For example, each of the vertices in the same-backward-slice cluster {a, b, c} is dependent on the same set of external statements, but do not influence the same set of external statements.</text></s>
<s sid="172"><CoreSc1 advantage="None" conceptID="Obs37" novelty="None" type="Obs"/><text>Coherent slice-clusters have an important property: If a slice contains a vertex of a coherent slice-cluster V, it will contain all vertices of the cluster:</text></s>
<s sid="173"><CoreSc1 advantage="None" conceptID="Obs38" novelty="None" type="Obs"/><text>(1)BSlice(x)∩V≠∅ ⇒ BSlice(x)∩V=VThis holds because:</text></s>
<s sid="174"><CoreSc1 advantage="None" conceptID="Obs39" novelty="None" type="Obs"/><text>∀y,y′∈V:y∈BSlice(x) ⇒ x∈FSlice(y) ⇒x∈FSlice(y′) ⇒ y′∈BSlice(x)The same argument clearly holds for forward slices.</text></s>
<s sid="175"><CoreSc1 advantage="None" conceptID="Obs40" novelty="None" type="Obs"/><text>However, the same is not true for non-coherent clusters.</text></s>
<s sid="176"><CoreSc1 advantage="None" conceptID="Obs41" novelty="None" type="Obs"/><text>For example, in the case of a same-backward-slice cluster, a vertex contained within the forward slice of any vertex of the cluster is not guaranteed to be in the forward slice of other vertices of the same cluster.</text></s>
<s sid="177"><CoreSc1 advantage="None" conceptID="Res28" novelty="None" type="Res"/><text>Hash based coherent slice clusters</text></s>
<s sid="178"><CoreSc1 advantage="None" conceptID="Res29" novelty="None" type="Res"/><text>The computation of coherent-slice clusters (Definition 2.5) grows prohibitively expensive even for mid-sized programs where tens of gigabytes of memory are required to store the set of all possible backward and forward slices.</text></s>
<s sid="179"><CoreSc1 advantage="None" conceptID="Res30" novelty="None" type="Res"/><text>The computation is cubic in time and quadratic in space.</text></s>
<s sid="180"><CoreSc1 advantage="None" conceptID="Res31" novelty="None" type="Res"/><text>An approximation is employed to reduce the computation time and memory requirement.</text></s>
<s sid="181"><CoreSc1 advantage="None" conceptID="Res32" novelty="None" type="Res"/><text>This approximation replaces comparison of slices with comparison of hash values, where hash values are used to summarize slice content.</text></s>
<s sid="182"><CoreSc1 advantage="None" conceptID="Res33" novelty="None" type="Res"/><text>The result is the following approximation to coherent-slice clusters in which H denotes a hash function.</text></s>
Definition 2.6
<s sid="183"><CoreSc1 advantage="None" conceptID="Obs42" novelty="None" type="Obs"/><text>Hash-based coherent-slice MDS and cluster (Islam et al., 2010b)</text></s>
<s sid="184"><CoreSc1 advantage="None" conceptID="Obs43" novelty="None" type="Obs"/><text>A hash-based coherent-slice MDS is a set of SDG vertices, V, such that</text></s>
∀x, y∈V:H(BSlice(x))=H(BSlice(y))∧H(FSlice(x))=H(FSlice(y))
<s sid="185"><CoreSc1 advantage="None" conceptID="Obs44" novelty="None" type="Obs"/><text>A hash-based coherent-slice cluster is a hash-based coherent-slice MDS contained within no other hash-based coherent-slice MDS.</text></s>
<s sid="186"><CoreSc1 advantage="None" conceptID="Obs45" novelty="None" type="Obs"/><text>A description of the hash function H along with the evaluation of its precision is presented in Section 3.3.</text></s>
<s sid="187"><CoreSc1 advantage="None" conceptID="Res34" novelty="None" type="Res"/><text>From here on, the paper considers only hash-based coherent-slice clusters unless explicitly stated otherwise.</text></s>
<s sid="188"><CoreSc1 advantage="None" conceptID="Res35" novelty="None" type="Res"/><text>Thus, for ease of reading, a hash-based coherent-slice cluster is referred to simply as a coherent cluster.</text></s>
Graph based cluster visualization
<s sid="189"><CoreSc1 advantage="None" conceptID="Res36" novelty="None" type="Res"/><text>This section describes two graph-based visualizations for dependence clusters.</text></s>
<s sid="190"><CoreSc1 advantage="None" conceptID="Res37" novelty="None" type="Res"/><text>The first visualization, the Monotone Slice-size Graph (MSG) (Binkley and Harman, 2005), plots a landscape of monotonically increasing slice sizes where the y-axis shows the size of each slice, as a percentage of the entire program, and the x-axis shows each slice, in monotonically increasing order of slice size.</text></s>
<s sid="191"><CoreSc1 advantage="None" conceptID="Obs46" novelty="None" type="Obs"/><text>In an MSG, a dependence cluster appears as a sheer-drop cliff face followed by a plateau.</text></s>
<s sid="192"><CoreSc1 advantage="None" conceptID="Goa12" novelty="None" type="Goa"/><text>The visualization assists with the inherently subjective task of deciding whether a cluster is large (how long is the plateau at the top of the cliff face relative to the surrounding landscape?) and whether it denotes a discontinuity in the dependence profile (how steep is the cliff face relative to the surrounding landscape?).</text></s>
<s sid="193"><CoreSc1 advantage="None" conceptID="Exp1" novelty="None" type="Exp"/><text>An MSG drawn using backward slice sizes is referred to as a backward-slice MSG (B-MSG), and an MSG drawn using forward slice sizes is referred to as a forward-slice MSG (F-MSG).</text></s>
<s sid="194"><CoreSc1 advantage="None" conceptID="Obs47" novelty="None" type="Obs"/><text>As an example, the open source calculator bc contains 9438 lines of code represented by 7538 SDG vertices.</text></s>
<s sid="195"><CoreSc1 advantage="None" conceptID="Obs48" novelty="None" type="Obs"/><text>The B-MSG for bc, shown in Fig. 3a, contains a large plateau that spans almost 70% of the MSG.</text></s>
<s sid="196"><CoreSc1 advantage="None" conceptID="Res38" novelty="None" type="Res"/><text>Under the assumption that same slice size implies the same slice, this indicates a large same-slice cluster.</text></s>
<s sid="197"><CoreSc1 advantage="None" conceptID="Res39" novelty="None" type="Res"/><text>However, &quot;zooming&quot; in reveals that the cluster is actually composed of several smaller clusters made from slices of very similar size.</text></s>
<s sid="198"><CoreSc1 advantage="None" conceptID="Res40" novelty="None" type="Res"/><text>The tolerance implicit in the visual resolution used to plot the MSG obscures this detail.</text></s>
<s sid="199"><CoreSc1 advantage="None" conceptID="Res41" novelty="None" type="Res"/><text>The second visualization, the Slice/Cluster Size Graph (SCG) (Islam et al., 2010b), alleviates this issue by combining both slice and cluster sizes.</text></s>
<s sid="200"><CoreSc1 advantage="None" conceptID="Res42" novelty="None" type="Res"/><text>It plots three landscapes, one of increasing slice sizes, one of the corresponding same-slice cluster sizes, and the third of the corresponding coherent cluster sizes.</text></s>
<s sid="201"><CoreSc1 advantage="None" conceptID="Mod26" novelty="None" type="Mod"/><text>In the SCG, vertices are ordered along the x-axis using three values, primarily according to their slice size, secondarily according to their same-slice cluster size, and finally according to the coherent cluster size.</text></s>
<s sid="202"><CoreSc1 advantage="None" conceptID="Obs49" novelty="None" type="Obs"/><text>Three values are plotted on the y-axis: slice sizes form the first landscape, and cluster sizes form the second and third.</text></s>
<s sid="203"><CoreSc1 advantage="None" conceptID="Res43" novelty="None" type="Res"/><text>Thus, SCGs not only show the sizes of the slices and the clusters, they also show the relation between them and thus bring to light interesting links.</text></s>
<s sid="204"><CoreSc1 advantage="None" conceptID="Res44" novelty="None" type="Res"/><text>Two variants of the SCG are considered: the backward-slice SCG (B-SCG) is built from the sizes of backward slices, same-backward-slice clusters, and coherent clusters, while the forward-slice SCG (F-SCG) is built from the sizes of forward slices, same-forward-slice clusters, and coherent clusters.</text></s>
<s sid="205"><CoreSc1 advantage="None" conceptID="Obs50" novelty="None" type="Obs"/><text>Note that both backward and forward SCGs use the same coherent cluster sizes.</text></s>
<s sid="206"><CoreSc1 advantage="None" conceptID="Obs51" novelty="None" type="Obs"/><text>The B-SCG and F-SCG for the program bc are shown in Fig. 4.</text></s>
<s sid="207"><CoreSc1 advantage="None" conceptID="Exp2" novelty="None" type="Exp"/><text>In both graphs the slice size landscape is plotted using a solid blackline, the same-slice cluster size landscape using a gray line, and the coherent cluster size landscape using a (red) broken line.</text></s>
<s sid="208"><CoreSc1 advantage="None" conceptID="Res45" novelty="None" type="Res"/><text>The B-SCG (Fig. 4a) shows that bc contains two large same-backward-slice clusters consisting of around 55% and 15% of the program.</text></s>
<s sid="209"><CoreSc1 advantage="None" conceptID="Res46" novelty="None" type="Res"/><text>Surprisingly, the larger same-backward-slice cluster is composed of smaller slices than the smaller same-backward-slice cluster; thus, the smaller cluster has a bigger impact (slice size) than the larger cluster.</text></s>
<s sid="210"><CoreSc1 advantage="None" conceptID="Res47" novelty="None" type="Res"/><text>In addition, the presence of three coherent clusters spanning approximately 15%, 20% and 30% of the program's statements can also be seen.</text></s>
<s sid="211"><CoreSc1 advantage="None" conceptID="Obs52" novelty="None" type="Obs"/><text>Fig. 3c shows two box plots depicting the distribution of (backward and forward) slice sizes for bc.</text></s>
<s sid="212"><CoreSc1 advantage="None" conceptID="Obs53" novelty="None" type="Obs"/><text>The average size of the slices is also displayed in the box plot using a solid square box.</text></s>
<s sid="213"><CoreSc1 advantage="None" conceptID="Met3" novelty="None" type="Met"/><text>Comparing the box plot information to the information provided by the MSGs, we can see that all the information available from the box plots can be derived from the MSGs itself (except for the average).</text></s>
<s sid="214"><CoreSc1 advantage="None" conceptID="Res48" novelty="None" type="Res"/><text>However, MSGs show a landscape (slice profile) which cannot be obtained from the box plots.</text></s>
<s sid="215"><CoreSc1 advantage="None" conceptID="Res49" novelty="None" type="Res"/><text>Similarly, the box plots in Fig. 4c show the size distributions of the various clusters (i.e. a vertex is in a cluster of size x) in addition to the slice size distributions.</text></s>
<s sid="216"><CoreSc1 advantage="None" conceptID="Res50" novelty="None" type="Res"/><text>Although the information from these box plots can not be derived from the SCGs shown in Fig. 4a and b directly, the profiles (landscapes) give a better intuition about the clusters, the number of major clusters and their sizes.</text></s>
<s sid="217"><CoreSc1 advantage="None" conceptID="Res51" novelty="None" type="Res"/><text>For our empirical study we use the size of individual clusters and the cluster profile to find mappings between the clusters and program components.</text></s>
<s sid="218"><CoreSc1 advantage="None" conceptID="Con1" novelty="None" type="Con"/><text>Therefore, we drop box plots in favor of SCGs to show the cluster profile and provide additional statistics in tabular format where required.</text></s>
Empirical evaluation
<s sid="219"><CoreSc1 advantage="None" conceptID="Obj11" novelty="None" type="Obj"/><text>This section presents the empirical evaluation into the existence and impact of coherent dependence clusters.</text></s>
<s sid="220"><CoreSc1 advantage="None" conceptID="Obj12" novelty="None" type="Obj"/><text>The section first discusses the experimental setup and the subject programs included in the study.</text></s>
<s sid="221"><CoreSc1 advantage="None" conceptID="Obj13" novelty="None" type="Obj"/><text>It then presents two validation studies, the first considers the effect of pointer analysis precision and the second considers the validity of hashing in efficient cluster identification.</text></s>
<s sid="222"><CoreSc1 advantage="None" conceptID="Obj14" novelty="None" type="Obj"/><text>The section then quantitatively considers the existence of coherent dependence clusters and identifies patterns of clustering within the programs.</text></s>
<s sid="223"><CoreSc1 advantage="None" conceptID="Obj15" novelty="None" type="Obj"/><text>This is followed by a series of four case studies, where qualitative analysis, aided by the decluvi cluster visualization tool (Islam et al., 2010a), highlight how knowledge of clusters can aid a software engineer.</text></s>
<s sid="224"><CoreSc1 advantage="None" conceptID="Obj16" novelty="None" type="Obj"/><text>The section then presents studies on inter-cluster dependence, and the relationship of program faults and system evolution to coherent clusters.</text></s>
<s sid="225"><CoreSc1 advantage="None" conceptID="Obj17" novelty="None" type="Obj"/><text>Finally, threats to validity are considered.</text></s>
<s sid="226"><CoreSc1 advantage="None" conceptID="Obj18" novelty="None" type="Obj"/><text>To formalize the goals of this section, the empirical evaluation addresses the following research questions:RQ1</text></s>
<s sid="227"><CoreSc1 advantage="None" conceptID="Obj19" novelty="None" type="Obj"/><text>What is the effect of pointer analysis precision on coherent clusters?</text></s>
RQ2
<s sid="228"><CoreSc1 advantage="None" conceptID="Obj20" novelty="None" type="Obj"/><text>How precise is hashing as a proxy for comparing slices?</text></s>
RQ3
<s sid="229"><CoreSc1 advantage="None" conceptID="Mod27" novelty="None" type="Mod"/><text>How large are the coherent clusters that exist in production source code and which patterns of clustering can be identified?</text></s>
RQ4
<s sid="230"><CoreSc1 advantage="None" conceptID="Met4" novelty="None" type="Met"/><text>Which structures within a program can coherent cluster analysis reveal?</text></s>
RQ5
<s sid="231"><CoreSc1 advantage="None" conceptID="Obj21" novelty="None" type="Obj"/><text>What are the implications of inter-cluster dependence between coherent clusters?</text></s>
RQ6
<s sid="232"><CoreSc1 advantage="None" conceptID="Obj22" novelty="None" type="Obj"/><text>How do program faults relate to coherent clusters?</text></s>
RQ7
<s sid="233"><CoreSc1 advantage="None" conceptID="Obj23" novelty="None" type="Obj"/><text>How stable are coherent clusters during system evolution?</text></s>
<s sid="234"><CoreSc1 advantage="None" conceptID="Obj24" novelty="None" type="Obj"/><text>The first two research questions provide empirical verification for the results subsequently presented.</text></s>
<s sid="235"><CoreSc1 advantage="None" conceptID="Goa13" novelty="None" type="Goa"/><text>RQ1 establishes the impact of pointer analysis on the clustering, whereas RQ2 establishes that the hash function used to approximate a slice is sufficiently precise.</text></s>
<s sid="236"><CoreSc1 advantage="None" conceptID="Con2" novelty="None" type="Con"/><text>If the static slices produced by the slicer are overly conservative or if the slice approximation is not sufficiently precise, then the results presented will not be reliable.</text></s>
<s sid="237"><CoreSc1 advantage="None" conceptID="Con3" novelty="None" type="Con"/><text>Fortunately, the results provide confidence that the slice precision and hashing accuracy are sufficient.</text></s>
<s sid="238"><CoreSc1 advantage="None" conceptID="Con4" novelty="None" type="Con"/><text>Whereas RQ1 and RQ2 focus on the veracity of our approach, RQ3 investigates the validity of the study; if large coherent clusters are not prevalent, then they would not be worthy of further study.</text></s>
<s sid="239"><CoreSc1 advantage="None" conceptID="Goa14" novelty="None" type="Goa"/><text>We place very specific and demanding constraints on a set of vertices for it to be deemed a coherent cluster.</text></s>
<s sid="240"><CoreSc1 advantage="None" conceptID="Hyp2" novelty="None" type="Hyp"/><text>If such clusters are not common then their study would be merely an academic exercise.</text></s>
<s sid="241"><CoreSc1 advantage="None" conceptID="Hyp3" novelty="None" type="Hyp"/><text>Conversely, if the clustering is similar for every program then it is unlikely that cluster identification will reveal interesting information about programs.</text></s>
<s sid="242"><CoreSc1 advantage="None" conceptID="Res52" novelty="None" type="Res"/><text>Our findings reveal that, despite the tight constraints inherent in the definition of a coherent dependence cluster, they are, indeed, very common.</text></s>
<s sid="243"><CoreSc1 advantage="None" conceptID="Obs54" novelty="None" type="Obs"/><text>Also, the cluster profiles for programs are sufficiently different and exhibit interesting patterns.</text></s>
<s sid="244"><CoreSc1 advantage="None" conceptID="Res53" novelty="None" type="Res"/><text>These results motivate the remaining research questions.</text></s>
<s sid="245"><CoreSc1 advantage="None" conceptID="Con5" novelty="None" type="Con"/><text>Having demonstrated that our technique is suitable for finding coherent clusters and that such clusters are sufficiently widespread to be worthy of study, we investigate specific coherent clusters in detail.</text></s>
<s sid="246"><CoreSc1 advantage="None" conceptID="Obj25" novelty="None" type="Obj"/><text>RQ4 studies the underlying logical structure of programs revealed by these clusters.</text></s>
<s sid="247"><CoreSc1 advantage="None" conceptID="Obj26" novelty="None" type="Obj"/><text>RQ5 looks explicitly at inter-cluster dependency and considers areas of software engineering where it may be of interest.</text></s>
<s sid="248"><CoreSc1 advantage="None" conceptID="Obj27" novelty="None" type="Obj"/><text>RQ6 presents a study of how program faults relate to coherent clusters, and, finally, RQ7 studies the effect of system evolution on clustering.</text></s>
Experimental subjects and setup
<s sid="249"><CoreSc1 advantage="None" conceptID="Met5" novelty="None" type="Met"/><text>The slices along with the mapping between the SDG vertices and the actual source code are extracted from the mature and widely used slicing tool CodeSurfer (Anderson and Teitelbaum, 2001) (version 2.1).</text></s>
<s sid="250"><CoreSc1 advantage="None" conceptID="Met6" novelty="None" type="Met"/><text>The cluster visualizations were generated by decluvi (Islam et al., 2010a) using data extracted from CodeSurfer.</text></s>
<s sid="251"><CoreSc1 advantage="None" conceptID="Met7" novelty="None" type="Met"/><text>The data is generated from slices taken with respect to source-code representing SDG vertices.</text></s>
<s sid="252"><CoreSc1 advantage="None" conceptID="Met8" novelty="None" type="Met"/><text>This excludes pseudo vertices introduced into the SDG, e.g., to represent global variables which are modeled as additional pseudo parameters by CodeSurfer.</text></s>
<s sid="253"><CoreSc1 advantage="None" conceptID="Obs55" novelty="None" type="Obs"/><text>Cluster sizes are also measured in terms of source-code representing SDG vertices, which is more consistent than using lines of code as it is not influenced by blank lines, comments, statements spanning multiple lines, multiple statements on one line, or compound statements.</text></s>
<s sid="254"><CoreSc1 advantage="None" conceptID="Obs56" novelty="None" type="Obs"/><text>The decluvi system along with scheme scripts for data acquisition and pre-compiled datasets for several open-source programs can be downloaded from http://www.cs.ucl.ac.uk/staff/s.islam/decluvi.html.</text></s>
<s sid="255"><CoreSc1 advantage="None" conceptID="Res54" novelty="None" type="Res"/><text>The study considers the 30 C programs shown in Table 1, which provides a brief description of each program alongside seven measures: number of files containing executable C code, LoC - lines of code (as counted by the Unix utility wc), SLoC - the non-comment non-blank lines of code (as counted by the utility sloccount (Wheeler, 2004)), ELoC - the number of source code lines that CodeSurfer considers to contain executable code, the number of SDG vertices, the number of SDG edges, the number of slices produced, and finally the size (as a percentage of the program's SDG vertex count) of the largest coherent cluster.</text></s>
<s sid="256"><CoreSc1 advantage="None" conceptID="Res55" novelty="None" type="Res"/><text>All LoC metrics are calculated over source files that CodeSurfer considers to contain executable code and, for example, do not include header files.</text></s>
<s sid="257"><CoreSc1 advantage="None" conceptID="Res56" novelty="None" type="Res"/><text>Columns 10 and 11 provide the runtimes recorded during the empirical study.</text></s>
<s sid="258"><CoreSc1 advantage="None" conceptID="Res57" novelty="None" type="Res"/><text>The runtimes reported are wall clock times captured by the Unix time utility while running the experiments on a 64-bit Linux machine (CentOS 5) with eight Intel(R) Xeon(R) CPU E5450 @ 3.00GHz processors and 32GB of RAM.</text></s>
<s sid="259"><CoreSc1 advantage="None" conceptID="Res58" novelty="None" type="Res"/><text>It should be noted that this machine acts as a group server and is accessed by multiple users.</text></s>
<s sid="260"><CoreSc1 advantage="None" conceptID="Res59" novelty="None" type="Res"/><text>There were other CPU intensive processes intermittently running on the machine while these runtimes were collected, and thus the runtimes are only indicative.</text></s>
<s sid="261"><CoreSc1 advantage="None" conceptID="Res60" novelty="None" type="Res"/><text>Column 10 shows the time needed to build the SDG and CodeSurfer project that is subsequently used for slicing.</text></s>
<s sid="262"><CoreSc1 advantage="None" conceptID="Res61" novelty="None" type="Res"/><text>The build time for the projects were quite small and the longest build time (2m33.456s) was required for gcal with 46,827 SLoC.</text></s>
<s sid="263"><CoreSc1 advantage="None" conceptID="Res62" novelty="None" type="Res"/><text>Column 11 shows the time needed for the clustering algorithm to perform the clustering and create all the data dumps for decluvi to create cluster visualizations.</text></s>
<s sid="264"><CoreSc1 advantage="None" conceptID="Obs57" novelty="None" type="Obs"/><text>The process completes in minutes for small programs and can take hours and longer for larger programs.</text></s>
<s sid="265"><CoreSc1 advantage="None" conceptID="Res63" novelty="None" type="Res"/><text>It should be noted that the runtime includes both the slicing phase which runs in O(ne), where n is the number of SDG vertices and e is the number of edges, and the hashing and clustering algorithm which runs in O(n2).</text></s>
<s sid="266"><CoreSc1 advantage="None" conceptID="Res64" novelty="None" type="Res"/><text>Therefore the overall complexity is O(ne).</text></s>
<s sid="267"><CoreSc1 advantage="None" conceptID="Res65" novelty="None" type="Res"/><text>The long runtime is mainly due to the current research prototype (which performs slicing, clustering and extraction of the data) using the Scheme interface of CodeSurfer in a pipeline architecture.</text></s>
<s sid="268"><CoreSc1 advantage="None" conceptID="Obs58" novelty="None" type="Obs"/><text>In the future we plan to upgrade the tooling with optimizations for fast and massive slicing (Binkley et al., 2007) and to merge the clustering phase into the slicing to reduce the runtime significantly.</text></s>
<s sid="269"><CoreSc1 advantage="None" conceptID="Res66" novelty="None" type="Res"/><text>Although the clustering and building the visualization data can take a long time for large projects, it is still useful because the clustering only needs to be done once (for example during a nightly build) and can then be visualised and reused as many times as needed.</text></s>
<s sid="270"><CoreSc1 advantage="None" conceptID="Res67" novelty="None" type="Res"/><text>During further study of the visualization and the clustering we have also found that small changes to the system does not show a change in the clustering, therefore once the clustering is created it still remains viable through small code changes as the clustering is found to represent the core program architecture (Section 3.9).</text></s>
<s sid="271"><CoreSc1 advantage="None" conceptID="Res68" novelty="None" type="Res"/><text>Furthermore, the number of SDG vertices and edges are quite large, in fact even for very small programs the number of SDG vertices is in the thousands with edge counts in the tens of thousands.</text></s>
<s sid="272"><CoreSc1 advantage="None" conceptID="Res69" novelty="None" type="Res"/><text>Moreover, the analysis produces an is-in-the-slice-of relation and graph with even more edges.</text></s>
<s sid="273"><CoreSc1 advantage="None" conceptID="Res70" novelty="None" type="Res"/><text>We have tried several clustering and visualization tools to cluster the is-in-the-slice-of graph for comparison, but most of the tools (such as Gephi Bastian et al., 2009) failed due to the large dataset.</text></s>
<s sid="274"><CoreSc1 advantage="None" conceptID="Res71" novelty="None" type="Res"/><text>Other tools such as CCVisu (Beyer, 2008) which were able to handle the large data set simply produced a blob as a visualization which was not at all useful.</text></s>
<s sid="275"><CoreSc1 advantage="None" conceptID="Obs59" novelty="None" type="Obs"/><text>The underlying problem is that the is-in-the-slice-of graph is dense and no traditional clustering can handle such dense graphs.</text></s>
<s sid="276"><CoreSc1 advantage="None" conceptID="Obs60" novelty="None" type="Obs"/><text>Impact of pointer analysis precision</text></s>
<s sid="277"><CoreSc1 advantage="None" conceptID="Mod28" novelty="None" type="Mod"/><text>Recall that the definition of a coherent dependence cluster is based on an underlying depends-on relation, which is approximated using program slicing.</text></s>
<s sid="278"><CoreSc1 advantage="None" conceptID="Obj28" novelty="None" type="Obj"/><text>Pointer analysis plays a key role in the precision of slicing and the interplay between pointer analysis and downstream dependence analysis precision is complex (Shapiro and Horwitz, 1997).</text></s>
<s sid="279"><CoreSc1 advantage="None" conceptID="Obj29" novelty="None" type="Obj"/><text>To understand how pointer analysis precision impacts the clustering of the programs we study the effect in this section.</text></s>
<s sid="280"><CoreSc1 advantage="None" conceptID="Bac54" novelty="None" type="Bac"/><text>Usually, one would choose the pointer analysis with the highest precision but there may be situations where this is not possible and one has to revert to lower precision analysis.</text></s>
<s sid="281"><CoreSc1 advantage="None" conceptID="Obj30" novelty="None" type="Obj"/><text>This section presents a study on the effect of various levels of pointer analysis precision on the size of slices and subsequently on coherent clusters.</text></s>
<s sid="282"><CoreSc1 advantage="None" conceptID="Obj31" novelty="None" type="Obj"/><text>It addresses research question RQ1: What is the effect of pointer analysis precision on coherent clusters?</text></s>
<s sid="283"><CoreSc1 advantage="None" conceptID="Res72" novelty="None" type="Res"/><text>CodeSurfer provides three levels of pointer analysis precision (Low, Medium, and High) that provide increasingly precise points-to information at the expense of additional memory and analysis time.</text></s>
<s sid="284"><CoreSc1 advantage="None" conceptID="Met9" novelty="None" type="Met"/><text>The Low setting uses a minimal pointer analysis that assumes every pointer may point to every object that has its address taken (variable or function).</text></s>
<s sid="285"><CoreSc1 advantage="None" conceptID="Met10" novelty="None" type="Met"/><text>At the Medium and High settings, CodeSurfer performs extensive pointer analysis using the algorithm proposed by Fahndrich et al. (1998), which implements a variant of Andersen's pointer analysis algorithm (Andersen, 1994) (this includes parameter aliasing).</text></s>
<s sid="286"><CoreSc1 advantage="None" conceptID="Res73" novelty="None" type="Res"/><text>At the medium setting, fields of a structure are not distinguished while the High level distinguishes structure fields.</text></s>
<s sid="287"><CoreSc1 advantage="None" conceptID="Res74" novelty="None" type="Res"/><text>The High setting should produce the most precise slices but requires more memory and time during SDG construction, which puts a functional limit on the size and complexity of the programs that can be handled by CodeSurfer.</text></s>
<s sid="288"><CoreSc1 advantage="None" conceptID="Res75" novelty="None" type="Res"/><text>There is no automatic way to determine whether the slices are correct and precise.</text></s>
<s sid="289"><CoreSc1 advantage="None" conceptID="Res76" novelty="None" type="Res"/><text>Weiser (1984) considers smaller slices to be better.</text></s>
<s sid="290"><CoreSc1 advantage="None" conceptID="Obj32" novelty="None" type="Obj"/><text>Slice size is often used to measure the impact of the analysis' precision (Shapiro and Horwitz, 1997), similarly we also use slice size as a measure of precision.</text></s>
<s sid="291"><CoreSc1 advantage="None" conceptID="Obj33" novelty="None" type="Obj"/><text>The study compares slice and cluster size for CodeSurfer's three precision options (Low, Medium, High) to study the impact of pointer analysis precision.</text></s>
<s sid="292"><CoreSc1 advantage="None" conceptID="Obs61" novelty="None" type="Obs"/><text>The results are shown in Table 2.</text></s>
<s sid="293"><CoreSc1 advantage="None" conceptID="Obs62" novelty="None" type="Obs"/><text>Column 1 lists the programs and the other columns present the average slice size, maximum slice size, average cluster size, and maximum cluster size, respectively, for each of the three precision settings.</text></s>
<s sid="294"><CoreSc1 advantage="None" conceptID="Res77" novelty="None" type="Res"/><text>The results for average slice size deviation and largest cluster size deviation are visualized in Figs.</text></s>
5 and 6.
<s sid="295"><CoreSc1 advantage="None" conceptID="Obs63" novelty="None" type="Obs"/><text>The graphs use the High setting as the base line and show the percentage deviation when using the Low and Medium settings.</text></s>
<s sid="296"><CoreSc1 advantage="None" conceptID="Obs64" novelty="None" type="Obs"/><text>Fig. 5 shows the average slice size deviation when using the lower two settings compared to the highest.</text></s>
<s sid="297"><CoreSc1 advantage="None" conceptID="Res78" novelty="None" type="Res"/><text>On average, the Low setting produces slices that are 14% larger than the High setting.</text></s>
<s sid="298"><CoreSc1 advantage="None" conceptID="Res79" novelty="None" type="Res"/><text>Program userv has the largest deviation of 37% when using the Low setting.</text></s>
<s sid="299"><CoreSc1 advantage="None" conceptID="Con6" novelty="None" type="Con"/><text>For example, in userv the minimal pointer analysis fails to recognize that the function pointer oip can never point to functions sighandler_alrm and sighandler_child and includes them as called functions at call sites using *oip, increasing slice size significantly.</text></s>
<s sid="300"><CoreSc1 advantage="None" conceptID="Res80" novelty="None" type="Res"/><text>In all 30 programs, the Low setting yields larger slices compared to the High setting.</text></s>
<s sid="301"><CoreSc1 advantage="None" conceptID="Res81" novelty="None" type="Res"/><text>The Medium setting always yields smaller slices when compared to the Low setting.</text></s>
<s sid="302"><CoreSc1 advantage="None" conceptID="Res82" novelty="None" type="Res"/><text>For eight programs, the medium setting produces the same average slice size as the High setting.</text></s>
<s sid="303"><CoreSc1 advantage="None" conceptID="Res83" novelty="None" type="Res"/><text>For the remaining programs the Medium setting produces slices that are on average 4% larger than when using the High setting.</text></s>
<s sid="304"><CoreSc1 advantage="None" conceptID="Res84" novelty="None" type="Res"/><text>The difference in slice size occurs because the Medium setting does not differentiate between structure fields, which the High setting does.</text></s>
<s sid="305"><CoreSc1 advantage="None" conceptID="Res85" novelty="None" type="Res"/><text>The largest deviation is seen in findutils at 29%.</text></s>
<s sid="306"><CoreSc1 advantage="None" conceptID="Res86" novelty="None" type="Res"/><text>With the medium setting, the structure fields (options, regex_map, stat_buf and state) of findutils are lumped together as if each structure were a scalar variable, resulting in larger, less precise, slices.</text></s>
<s sid="307"><CoreSc1 advantage="None" conceptID="Obs65" novelty="None" type="Obs"/><text>Fig. 6 visualizes the deviation of the largest coherent cluster size when using the lower two settings compared to the highest.</text></s>
<s sid="308"><CoreSc1 advantage="None" conceptID="Obs66" novelty="None" type="Obs"/><text>The graph shows that the size of the largest coherent clusters found when using the lower settings is larger in most of the programs.</text></s>
<s sid="309"><CoreSc1 advantage="None" conceptID="Obs67" novelty="None" type="Obs"/><text>On average there is a 22% increase in the size of the largest coherent cluster when using the Low setting and a 10% increase when using the Medium setting.</text></s>
<s sid="310"><CoreSc1 advantage="None" conceptID="Res87" novelty="None" type="Res"/><text>In a2ps and cflow the size of the largest cluster increases over 100% when using the Medium setting and over 150% when using the Low setting.</text></s>
<s sid="311"><CoreSc1 advantage="None" conceptID="Res88" novelty="None" type="Res"/><text>The increase in slice size is expected to result in larger clusters due to the loss of precision.</text></s>
<s sid="312"><CoreSc1 advantage="None" conceptID="Obs68" novelty="None" type="Obs"/><text>The B-SCGs for a2ps for the three settings is shown in Fig. 7a.</text></s>
<s sid="313"><CoreSc1 advantage="None" conceptID="Obs69" novelty="None" type="Obs"/><text>In the graphs it is seen that the slice sizes get smaller and have increased steps in the (black) landscape indicating that the slices become more precise.</text></s>
<s sid="314"><CoreSc1 advantage="None" conceptID="Obs70" novelty="None" type="Obs"/><text>The red landscape shows that there is a large coherent cluster detected when using the Low setting running from approx.</text></s>
60-80% on the x-axis.
<s sid="315"><CoreSc1 advantage="None" conceptID="Obs71" novelty="None" type="Obs"/><text>This cluster drops in size when using the Medium setting.</text></s>
<s sid="316"><CoreSc1 advantage="None" conceptID="Res89" novelty="None" type="Res"/><text>At the High setting this coherent cluster breaks up into multiple smaller clusters.</text></s>
<s sid="317"><CoreSc1 advantage="None" conceptID="Res90" novelty="None" type="Res"/><text>In this case, a drop in the cluster size also leads to breaking of the cluster in to multiple smaller clusters.</text></s>
<s sid="318"><CoreSc1 advantage="None" conceptID="Obs72" novelty="None" type="Obs"/><text>In the SCGs for cflow (Fig. 7b) a similar drop in the slice size and cluster size is observed.</text></s>
<s sid="319"><CoreSc1 advantage="None" conceptID="Obs73" novelty="None" type="Obs"/><text>However, unlike a2ps the large coherent cluster does not break into smaller clusters but only drops in size.</text></s>
<s sid="320"><CoreSc1 advantage="None" conceptID="Obs74" novelty="None" type="Obs"/><text>The largest cluster when using the Low setting runs from 60% to 85% on the x-axis.</text></s>
<s sid="321"><CoreSc1 advantage="None" conceptID="Obs75" novelty="None" type="Obs"/><text>This cluster reduces in size and shifts position running 30% to 45% x-axis when using the Medium setting.</text></s>
<s sid="322"><CoreSc1 advantage="None" conceptID="Obs76" novelty="None" type="Obs"/><text>The cluster further drops in size down to 5% running 25-30% on the x-axis when using the High setting.</text></s>
<s sid="323"><CoreSc1 advantage="None" conceptID="Obs77" novelty="None" type="Obs"/><text>In this case the largest cluster has a significant drop in size but does not break into multiple smaller clusters.</text></s>
<s sid="324"><CoreSc1 advantage="None" conceptID="Obs78" novelty="None" type="Obs"/><text>Surprisingly, Fig. 6 also shows seven programs where the largest coherent cluster size actually increases when using the highest pointer analysis setting on CodeSurfer.</text></s>
<s sid="325"><CoreSc1 advantage="None" conceptID="Obs79" novelty="None" type="Obs"/><text>Fig. 7c shows the B-SCGs for acm which falls in this category.</text></s>
<s sid="326"><CoreSc1 advantage="None" conceptID="Res91" novelty="None" type="Res"/><text>This counter-intuitive result is seen only when the more precise analysis determines that certain functions cannot be called and thus excludes them from the slice.</text></s>
<s sid="327"><CoreSc1 advantage="None" conceptID="Res92" novelty="None" type="Res"/><text>Although in all such instances slices get smaller, the clusters may grow if the smaller slices match other slices already forming a cluster.</text></s>
<s sid="328"><CoreSc1 advantage="None" conceptID="Obs80" novelty="None" type="Obs"/><text>For example, consider replacing function f6 in Fig. 1 with the code shown in Fig. 8, where f depends on a function call to a function referenced through the function pointer p.</text></s>
<s sid="329"><CoreSc1 advantage="None" conceptID="Con7" novelty="None" type="Con"/><text>Assume that the highest precision pointer analysis determines that p does not point to f2 and therefore there is no call to f2 or any other function from f6.</text></s>
<s sid="330"><CoreSc1 advantage="None" conceptID="Con8" novelty="None" type="Con"/><text>The higher precision analysis would therefore determine that the forward slices and backward slices of a, b and c are equal, hence grouping these three vertices in a coherent cluster.</text></s>
<s sid="331"><CoreSc1 advantage="None" conceptID="Con9" novelty="None" type="Con"/><text>Whereas the lower precision is unable to determine that p cannot point to f2, the backward slice on f will conservatively include b.</text></s>
<s sid="332"><CoreSc1 advantage="None" conceptID="Res93" novelty="None" type="Res"/><text>This will lead the higher precision analysis to determine that the set of vertices {a, b, c} is one coherent cluster whereas the lower precision analysis include only the set of vertices {a, c} in the same coherent cluster.</text></s>
<s sid="333"><CoreSc1 advantage="None" conceptID="Obs81" novelty="None" type="Obs"/><text>Although we do not explicitly report the project build times on CodeSurfer and the clustering runtimes for the lower settings, it has been our experience that in the majority of the cases the build times for the lower settings were smaller.</text></s>
<s sid="334"><CoreSc1 advantage="None" conceptID="Obs82" novelty="None" type="Obs"/><text>However, as lower pointer analysis settings yield large points-to sets and subsequently larger slices, the clustering runtimes were higher than when using the highest setting.</text></s>
<s sid="335"><CoreSc1 advantage="None" conceptID="Obs83" novelty="None" type="Obs"/><text>Moreover, in some cases with the lower settings there was an explosive growth in summary edge generation which resulted in exceptionally high project build times and clustering runtimes.</text></s>
<s sid="336"><CoreSc1 advantage="None" conceptID="Obs84" novelty="None" type="Obs"/><text>As an answer to RQ1, we find that in the majority of the cases the Medium and Low settings result in larger coherent clusters when compared to the High setting.</text></s>
<s sid="337"><CoreSc1 advantage="None" conceptID="Res94" novelty="None" type="Res"/><text>For the remaining cases we have identified valid scenarios where more precise pointer analysis can result in larger coherent clusters.</text></s>
<s sid="338"><CoreSc1 advantage="None" conceptID="Res95" novelty="None" type="Res"/><text>The results also confirm that a more precise pointer analysis leads to more precise (smaller) slices.</text></s>
<s sid="339"><CoreSc1 advantage="None" conceptID="Res96" novelty="None" type="Res"/><text>Because it gives the most precise slices and most accurate clusters, the remainder of the paper uses the highest CodeSurfer pointer analysis setting.</text></s>
<s sid="340"><CoreSc1 advantage="None" conceptID="Res97" novelty="None" type="Res"/><text>Validity of the hash function</text></s>
<s sid="341"><CoreSc1 advantage="None" conceptID="Obj34" novelty="None" type="Obj"/><text>This section addresses research question RQ2: How precise is hashing as a proxy for comparing slices?</text></s>
<s sid="342"><CoreSc1 advantage="None" conceptID="Res98" novelty="None" type="Res"/><text>The section first gives a brief description of the hash function and then validates the use of comparing slice hash values in lieu of comparing actual slice content.</text></s>
<s sid="343"><CoreSc1 advantage="None" conceptID="Res99" novelty="None" type="Res"/><text>The use of hash values to represent slices reduces both the memory requirement and runtime, as it is no longer necessary to store or compare entire slices.</text></s>
<s sid="344"><CoreSc1 advantage="None" conceptID="Res100" novelty="None" type="Res"/><text>The hash function, denoted H in Definition 2.6, uses XOR operations iteratively on the unique vertex IDs (of the SDG) which are included in a slice to generate a hash for the entire slice.</text></s>
<s sid="345"><CoreSc1 advantage="None" conceptID="Res101" novelty="None" type="Res"/><text>We chose XOR as the hash operator because we do not have duplicate vertices in a slice and the order of the vertices in the slice does not matter.</text></s>
<s sid="346"><CoreSc1 advantage="None" conceptID="Res102" novelty="None" type="Res"/><text>A slice S is a set of SDG vertices {v1,…,vn} (n≥1) and id(vi) represents the unique vertex ID assigned by CodeSurfer to vertex vi, where 1≤i≤n.</text></s>
<s sid="347"><CoreSc1 advantage="None" conceptID="Res103" novelty="None" type="Res"/><text>The hash function H for S is defined as HS, where</text></s>
(2)HS=⊕i=1nid(vi)
<s sid="348"><CoreSc1 advantage="None" conceptID="Con10" novelty="None" type="Con"/><text>The remainder of this section presents a validation study of the hash function.</text></s>
<s sid="349"><CoreSc1 advantage="None" conceptID="Con11" novelty="None" type="Con"/><text>The validation is needed to confirm that the hash values provide a sufficiently accurate summary of slices to support the correct partitioning of SDG vertices into coherent clusters.</text></s>
<s sid="350"><CoreSc1 advantage="None" conceptID="Con12" novelty="None" type="Con"/><text>Ideally, the hash function would produce a unique hash value for each distinct slice.</text></s>
<s sid="351"><CoreSc1 advantage="None" conceptID="Con13" novelty="None" type="Con"/><text>The validation study aims to find the number of unique slices for which the hash function successfully produces an unique hash value.</text></s>
<s sid="352"><CoreSc1 advantage="None" conceptID="Res104" novelty="None" type="Res"/><text>For the validation study we chose 16 programs from the set of 30 subject programs.</text></s>
<s sid="353"><CoreSc1 advantage="None" conceptID="Res105" novelty="None" type="Res"/><text>The largest programs were not included in the validation study to make the study time-manageable.</text></s>
<s sid="354"><CoreSc1 advantage="None" conceptID="Res106" novelty="None" type="Res"/><text>Results are based on both the backward and forward slices for every vertex of these 16 programs.</text></s>
<s sid="355"><CoreSc1 advantage="None" conceptID="Obj35" novelty="None" type="Obj"/><text>To present the notion of precision we introduce the following formalization.</text></s>
<s sid="356"><CoreSc1 advantage="None" conceptID="Obs85" novelty="None" type="Obs"/><text>Let V be the set of all source-code representing SDG vertices for a given program P and US denote the number of unique slices: US=|{BSlice(x):x∈V}|+|{FSlice(x):x∈V}|.</text></s>
<s sid="357"><CoreSc1 advantage="None" conceptID="Obs86" novelty="None" type="Obs"/><text>Note that if all vertices have the same backward slice then {BSlice(x):x∈V} is a singleton set.</text></s>
<s sid="358"><CoreSc1 advantage="None" conceptID="Obs87" novelty="None" type="Obs"/><text>Finally, let UH be the number of unique hash-values, UH=|{H(BSlice(x)):x∈V}|+|{H(FSlice(x)):x∈V}|.</text></s>
<s sid="359"><CoreSc1 advantage="None" conceptID="Obs88" novelty="None" type="Obs"/><text>The accuracy of hash function H is given as Hashed Slice Precision, HSP=UH/US.</text></s>
<s sid="360"><CoreSc1 advantage="None" conceptID="Res107" novelty="None" type="Res"/><text>A precision of 1.00 (US=UH) means the hash function is 100% accurate (i.e., it produces a unique hash value for every distinct slice) whereas a precision of 1/US means that the hash function produces the same hash value for every slice leaving UH=1.</text></s>
<s sid="361"><CoreSc1 advantage="None" conceptID="Obs89" novelty="None" type="Obs"/><text>Table 3 summarizes the results.</text></s>
<s sid="362"><CoreSc1 advantage="None" conceptID="Obs90" novelty="None" type="Obs"/><text>The first column lists the programs.</text></s>
<s sid="363"><CoreSc1 advantage="None" conceptID="Obs91" novelty="None" type="Obs"/><text>The second and the third columns report the values of US and UH respectively.</text></s>
<s sid="364"><CoreSc1 advantage="None" conceptID="Obs92" novelty="None" type="Obs"/><text>The fourth column reports HSP, the precision attained using hash values to compare slices.</text></s>
<s sid="365"><CoreSc1 advantage="None" conceptID="Obs93" novelty="None" type="Obs"/><text>Considering all 78,587 unique slices the hash function produced unique hash values for 74,575 of them, resulting in an average precision of 94.97%.</text></s>
<s sid="366"><CoreSc1 advantage="None" conceptID="Obs94" novelty="None" type="Obs"/><text>In other words, the hash function fails to produce unique hash values for just over 5% of the slices.</text></s>
<s sid="367"><CoreSc1 advantage="None" conceptID="Res108" novelty="None" type="Res"/><text>Considering the precision of individual programs, five of the programs have a precision greater than 97%, while the lowest precision, for findutils, is 92.37%.</text></s>
<s sid="368"><CoreSc1 advantage="None" conceptID="Res109" novelty="None" type="Res"/><text>This is, however, a significant improvement over previous use of slice size as the hash value, which is only 78.3% accurate in the strict case of zero tolerance for variation in slice contents (Binkley and Harman, 2005).</text></s>
<s sid="369"><CoreSc1 advantage="None" conceptID="Res110" novelty="None" type="Res"/><text>Coherent cluster identification uses two hash values for each vertex (one for the backward slice and other for the forward slice) and the slice sizes.</text></s>
<s sid="370"><CoreSc1 advantage="None" conceptID="Res111" novelty="None" type="Res"/><text>Slice size matching filters out some instances where the hash values happen to be the same by coincidence but the slices are different.</text></s>
<s sid="371"><CoreSc1 advantage="None" conceptID="Res112" novelty="None" type="Res"/><text>The likelihood of both hash values matching those from another vertex with different slices is less than that of a single hash matching.</text></s>
<s sid="372"><CoreSc1 advantage="None" conceptID="Res113" novelty="None" type="Res"/><text>Extending US and UH to clusters, columns 5 and 6 (Table 3) report CC, the number of coherent clusters in a program and HCC, the number of coherent clusters found using hashing.</text></s>
<s sid="373"><CoreSc1 advantage="None" conceptID="Res114" novelty="None" type="Res"/><text>The final column shows the precision attained using hashing to identify clusters, HCP=HCC/CC.</text></s>
<s sid="374"><CoreSc1 advantage="None" conceptID="Res115" novelty="None" type="Res"/><text>The results show that of the 40,169 coherent clusters, 40,083 are uniquely identified using hashing, which yields a precision of 99.72%.</text></s>
<s sid="375"><CoreSc1 advantage="None" conceptID="Res116" novelty="None" type="Res"/><text>Five of the programs show total agreement, furthermore for every program HCP is over 99%, except for userv, which has the lowest precision of 97.76%.</text></s>
<s sid="376"><CoreSc1 advantage="None" conceptID="Res117" novelty="None" type="Res"/><text>This can be attributed to the large percentage (96%) of single vertex clusters in userv.</text></s>
<s sid="377"><CoreSc1 advantage="None" conceptID="Res118" novelty="None" type="Res"/><text>The hash values for slices taken with respect to these single-vertex clusters have a higher potential for collision leading to a reduction in overall precision.</text></s>
<s sid="378"><CoreSc1 advantage="None" conceptID="Res119" novelty="None" type="Res"/><text>In summary, as an answer to RQ2, the hash-based approximation is found to be sufficiently accurate at 94.97% for slices and at 99.72% for clusters (for the studied programs).</text></s>
<s sid="379"><CoreSc1 advantage="None" conceptID="Res120" novelty="None" type="Res"/><text>Thus, comparing hash values can replace the need to compare actual slices.</text></s>
<s sid="380"><CoreSc1 advantage="None" conceptID="Res121" novelty="None" type="Res"/><text>Do large coherent clusters occur in practice?</text></s>
<s sid="381"><CoreSc1 advantage="None" conceptID="Goa15" novelty="None" type="Goa"/><text>Having demonstrated that hash function H can be used to effectively approximate slice contents, this section and the following section consider the validation research question, RQ3: How large are coherent clusters that exist in production source code and which patterns of clustering can be identified?</text></s>
<s sid="382"><CoreSc1 advantage="None" conceptID="Goa16" novelty="None" type="Goa"/><text>The question is first answered quantitatively using the size of the largest coherent cluster in each program and then through visual analysis of the SCGs.</text></s>
<s sid="383"><CoreSc1 advantage="None" conceptID="Goa17" novelty="None" type="Goa"/><text>To assess if a program includes a large coherent cluster, requires making a judgement concerning what threshold constitutes large.</text></s>
<s sid="384"><CoreSc1 advantage="None" conceptID="Bac55" novelty="None" type="Bac"/><text>Following prior empirical work (Binkley and Harman, 2005; Harman et al., 2009; Islam et al., 2010a,b), a threshold of 10% is used.</text></s>
<s sid="385"><CoreSc1 advantage="None" conceptID="Res122" novelty="None" type="Res"/><text>In other words, a program is said to contain a large coherent cluster if 10% of the program's SDG vertices produce the same backward slice as well as the same forward slice.</text></s>
<s sid="386"><CoreSc1 advantage="None" conceptID="Obs95" novelty="None" type="Obs"/><text>Fig. 9 shows the size of the largest coherent cluster found in each of the 30 subject programs.</text></s>
<s sid="387"><CoreSc1 advantage="None" conceptID="Res123" novelty="None" type="Res"/><text>The programs are divided into 3 groups based on the size of the largest cluster present in the program.Small:</text></s>
<s sid="388"><CoreSc1 advantage="None" conceptID="Res124" novelty="None" type="Res"/><text>Small consists of seven programs none of which have a coherent cluster constituting over 10% of the program vertices.</text></s>
<s sid="389"><CoreSc1 advantage="None" conceptID="Res125" novelty="None" type="Res"/><text>These programs are archimedes, time, wdiff, byacc, a2ps, cflow and userv.</text></s>
<s sid="390"><CoreSc1 advantage="None" conceptID="Goa18" novelty="None" type="Goa"/><text>Although it may be interesting to study why large clusters are not present in these programs, this paper focuses on studying the existence and implications of large coherent clusters.</text></s>
Large:
<s sid="391"><CoreSc1 advantage="None" conceptID="Res126" novelty="None" type="Res"/><text>This group consists of programs that have at least one cluster with size 10% or larger.</text></s>
<s sid="392"><CoreSc1 advantage="None" conceptID="Res127" novelty="None" type="Res"/><text>As there are programs containing much larger coherent clusters, a program is placed in this group if it has a large cluster between the size 10% and 50%.</text></s>
<s sid="393"><CoreSc1 advantage="None" conceptID="Res128" novelty="None" type="Res"/><text>Over two-thirds of the programs studied fall in this category.</text></s>
<s sid="394"><CoreSc1 advantage="None" conceptID="Res129" novelty="None" type="Res"/><text>The program at the bottom of this group (acct) has a coherent cluster of size 11% and the largest program in this group (copia) has a coherent cluster of size 48%.</text></s>
<s sid="395"><CoreSc1 advantage="None" conceptID="Res130" novelty="None" type="Res"/><text>We present both these programs as case studies and discuss their clustering in detail in Sections 3.6.1 and 3.6.4, respectively.</text></s>
<s sid="396"><CoreSc1 advantage="None" conceptID="Res131" novelty="None" type="Res"/><text>The program bc which has multiple large clusters with the largest of size 32% falls in the middle of this group and is also presented as a case study in Section 3.6.3.</text></s>
Huge:
<s sid="397"><CoreSc1 advantage="None" conceptID="Res132" novelty="None" type="Res"/><text>The final group consists of programs that have a large coherent cluster whose size is over 50%.</text></s>
<s sid="398"><CoreSc1 advantage="None" conceptID="Res133" novelty="None" type="Res"/><text>Out of the 30 programs 4 fall in this group.</text></s>
<s sid="399"><CoreSc1 advantage="None" conceptID="Res134" novelty="None" type="Res"/><text>These programs are indent, ed, barcode and gcal.</text></s>
<s sid="400"><CoreSc1 advantage="None" conceptID="Res135" novelty="None" type="Res"/><text>From this group, we present indent as a case study in Section 3.6.2.</text></s>
<s sid="401"><CoreSc1 advantage="None" conceptID="Res136" novelty="None" type="Res"/><text>In summary all but 7 of the 30 subject programs contain a large coherent cluster.</text></s>
<s sid="402"><CoreSc1 advantage="None" conceptID="Res137" novelty="None" type="Res"/><text>Therefore, over 75% of the subject programs contain a coherent cluster of size 10% or more.</text></s>
<s sid="403"><CoreSc1 advantage="None" conceptID="Obs96" novelty="None" type="Obs"/><text>Furthermore, half the programs contain a coherent cluster of at least 20% in size.</text></s>
<s sid="404"><CoreSc1 advantage="None" conceptID="Obs97" novelty="None" type="Obs"/><text>It is interesting to note that although this grouping is based only on the largest cluster, many of the programs contain multiple large coherent clusters.</text></s>
<s sid="405"><CoreSc1 advantage="None" conceptID="Obs98" novelty="None" type="Obs"/><text>For example, ed, ctags, nano, less, bc, findutils, flex and garpd all have multiple large coherent clusters.</text></s>
<s sid="406"><CoreSc1 advantage="None" conceptID="Obs99" novelty="None" type="Obs"/><text>It is also interesting to note that there is no correlation between a program's size (measured in SLoC) and the size of its largest coherent cluster.</text></s>
<s sid="407"><CoreSc1 advantage="None" conceptID="Obs100" novelty="None" type="Obs"/><text>For example, in Table 1 two programs of very different sizes, cflow and userv, have similar largest-cluster sizes of 8% and 9%, respectively.</text></s>
<s sid="408"><CoreSc1 advantage="None" conceptID="Res138" novelty="None" type="Res"/><text>Whereas programs acct and ed, of similar size, have very different largest coherent clusters of sizes 11% and 55%.</text></s>
<s sid="409"><CoreSc1 advantage="None" conceptID="Res139" novelty="None" type="Res"/><text>Therefore as an answer to first part of RQ3, the study finds that 23 of the 30 programs studied have a large coherent cluster.</text></s>
<s sid="410"><CoreSc1 advantage="None" conceptID="Res140" novelty="None" type="Res"/><text>Some programs also have a huge cluster covering over 50% of the program vertices.</text></s>
<s sid="411"><CoreSc1 advantage="None" conceptID="Res141" novelty="None" type="Res"/><text>Furthermore, the choice of 10% as a threshold for classifying a cluster as large is a relatively conservative choice.</text></s>
<s sid="412"><CoreSc1 advantage="None" conceptID="Con14" novelty="None" type="Con"/><text>Thus, the results presented in this section can be thought of as a lower bound to the existence question.</text></s>
Patterns of clustering
<s sid="413"><CoreSc1 advantage="None" conceptID="Obj36" novelty="None" type="Obj"/><text>This section presents a visual study of SCGs for the three program groups and addresses the second part of RQ3.</text></s>
Figs.
<s sid="414"><CoreSc1 advantage="None" conceptID="Obs101" novelty="None" type="Obs"/><text>10-12 show graphs for the three categories.</text></s>
<s sid="415"><CoreSc1 advantage="None" conceptID="Obs102" novelty="None" type="Obs"/><text>The graphs in the figures are laid out in ascending order based on the largest coherent cluster present in the program and thus follow the same order as seen in Fig. 9.</text></s>
<s sid="416"><CoreSc1 advantage="None" conceptID="Obs103" novelty="None" type="Obs"/><text>Fig. 10 shows SCGs for the seven programs of the small group.</text></s>
<s sid="417"><CoreSc1 advantage="None" conceptID="Obs104" novelty="None" type="Obs"/><text>In the SCGs of the first three programs (archimedes, time and wdiff) only a small coherent cluster is visible in the red landscape.</text></s>
<s sid="418"><CoreSc1 advantage="None" conceptID="Res142" novelty="None" type="Res"/><text>In the remaining four programs, the red landscape shows the presence of multiple small coherent clusters.</text></s>
<s sid="419"><CoreSc1 advantage="None" conceptID="Con15" novelty="None" type="Con"/><text>It is very likely that, similar to the results of the case studies presented later, these clusters also depict logical constructs within each program.</text></s>
<s sid="420"><CoreSc1 advantage="None" conceptID="Obs105" novelty="None" type="Obs"/><text>Fig. 11 shows SCGs of the 19 programs that have at least one large, but not huge, coherent cluster.</text></s>
<s sid="421"><CoreSc1 advantage="None" conceptID="Res143" novelty="None" type="Res"/><text>That is, each program has at least one coherent cluster covering 10-50% of the program.</text></s>
<s sid="422"><CoreSc1 advantage="None" conceptID="Res144" novelty="None" type="Res"/><text>Most of the programs have multiple coherent clusters as is visible on the red landscape.</text></s>
<s sid="423"><CoreSc1 advantage="None" conceptID="Res145" novelty="None" type="Res"/><text>Some of these have only one large cluster satisfying the definition of large, such as acct.</text></s>
<s sid="424"><CoreSc1 advantage="None" conceptID="Res146" novelty="None" type="Res"/><text>The clustering of acct is discussed in further detail in Section 3.6.1.</text></s>
<s sid="425"><CoreSc1 advantage="None" conceptID="Res147" novelty="None" type="Res"/><text>Most of the remaining programs are seen to have multiple large clusters such as bc, which is also discussed in further detail in Section 3.6.3.</text></s>
<s sid="426"><CoreSc1 advantage="None" conceptID="Res148" novelty="None" type="Res"/><text>The presence of multiple large coherent cluster hints that the program consists of multiple functional components.</text></s>
<s sid="427"><CoreSc1 advantage="None" conceptID="Res149" novelty="None" type="Res"/><text>In three of the programs (which, gnuedma and copia) the landscape is completely dominated by a single large coherent cluster.</text></s>
<s sid="428"><CoreSc1 advantage="None" conceptID="Res150" novelty="None" type="Res"/><text>In which and gnuedma this cluster covers around 40% of the program vertices whereas in copia the cluster covers 50%.</text></s>
<s sid="429"><CoreSc1 advantage="None" conceptID="Res151" novelty="None" type="Res"/><text>The presence of a single large dominating cluster points to a centralized functionality or structure being present in the program.</text></s>
<s sid="430"><CoreSc1 advantage="None" conceptID="Res152" novelty="None" type="Res"/><text>Copia is presented as a case study in Section 3.6.4 where its clustering is discussed in further detail.</text></s>
<s sid="431"><CoreSc1 advantage="None" conceptID="Res153" novelty="None" type="Res"/><text>Finally, SCGs for the four programs that contain huge coherent clusters (covering over 50%) are found in Fig. 12.</text></s>
<s sid="432"><CoreSc1 advantage="None" conceptID="Res154" novelty="None" type="Res"/><text>In all four landscapes there is a very large dominating cluster with other smaller clusters also being visible.</text></s>
<s sid="433"><CoreSc1 advantage="None" conceptID="Res155" novelty="None" type="Res"/><text>This pattern supports the conjecture that the program has one central structure or functionality which consists of most of the program elements, but also has additional logical constructs that work in support of the central idea.</text></s>
<s sid="434"><CoreSc1 advantage="None" conceptID="Res156" novelty="None" type="Res"/><text>Indent is one program that falls in this category and is discussed in further detail in Section 3.6.2.</text></s>
<s sid="435"><CoreSc1 advantage="None" conceptID="Res157" novelty="None" type="Res"/><text>As an answer to second part of RQ3, the study finds that most programs contain multiple coherent clusters.</text></s>
<s sid="436"><CoreSc1 advantage="None" conceptID="Res158" novelty="None" type="Res"/><text>Furthermore, the visual study reveals that a third of the programs have multiple large coherent clusters.</text></s>
<s sid="437"><CoreSc1 advantage="None" conceptID="Res159" novelty="None" type="Res"/><text>Only three programs copia, gnuedma, and which show the presence of only a single (overwhelming) cluster covering most of the program.</text></s>
<s sid="438"><CoreSc1 advantage="None" conceptID="Res160" novelty="None" type="Res"/><text>Having shown that coherent clusters are prevalent in programs and that most programs have multiple significant clusters, the next section presents a series of four case studies that looks at how program structures are represented by these clusters.</text></s>
<s sid="439"><CoreSc1 advantage="None" conceptID="Res161" novelty="None" type="Res"/><text>Coherent cluster and program decomposition</text></s>
<s sid="440"><CoreSc1 advantage="None" conceptID="Con16" novelty="None" type="Con"/><text>This section presents four case studies using acct, indent, bc and copia.</text></s>
<s sid="441"><CoreSc1 advantage="None" conceptID="Goa19" novelty="None" type="Goa"/><text>The case studies form a major contribution of the paper and collectively address research question RQ4: Which structures within a program can coherent cluster analysis reveal? As coherent clusters consist of program vertices that are mutually inter-dependent and share extra-cluster properties we consider such vertices of the cluster to be tightly coupled.</text></s>
<s sid="442"><CoreSc1 advantage="None" conceptID="Goa20" novelty="None" type="Goa"/><text>It is our conjecture that these clusters likely represent logical structures representing a high-level functional decomposition of systems.</text></s>
<s sid="443"><CoreSc1 advantage="None" conceptID="Goa21" novelty="None" type="Goa"/><text>This study will therefore look at how coherent clusters map to logical structures of the program.</text></s>
<s sid="444"><CoreSc1 advantage="None" conceptID="Met11" novelty="None" type="Met"/><text>The case studies have been chosen to represent the large and huge groups identified in the previous section.</text></s>
<s sid="445"><CoreSc1 advantage="None" conceptID="Met12" novelty="None" type="Met"/><text>Three programs are taken from the large group as it consists of the majority of the programs and one from the huge group.</text></s>
<s sid="446"><CoreSc1 advantage="None" conceptID="Met13" novelty="None" type="Met"/><text>Each of the three programs from the large group were chosen because it exhibits specific patterns.</text></s>
<s sid="447"><CoreSc1 advantage="None" conceptID="Res162" novelty="None" type="Res"/><text>acct has multiple coherent clusters visible in its profile and has the smallest large cluster in the group, bc has multiple large coherent clusters, and copia has only a single large coherent cluster dominating the entire landscape.</text></s>
Case study: acct
<s sid="448"><CoreSc1 advantage="None" conceptID="Res163" novelty="None" type="Res"/><text>The first of the series of case studies is acct, an open-source program used for monitoring and printing statistics about users and processes.</text></s>
<s sid="449"><CoreSc1 advantage="None" conceptID="Res164" novelty="None" type="Res"/><text>The program acct is one of the smaller programs with 2600 LoC and 1558 SLoC from which CodeSurfer produced 2834 slices.</text></s>
<s sid="450"><CoreSc1 advantage="None" conceptID="Res165" novelty="None" type="Res"/><text>The program has seven C files, two of which, getopt.c and getopt1.c, contain only conditionally included functions.</text></s>
<s sid="451"><CoreSc1 advantage="None" conceptID="Con17" novelty="None" type="Con"/><text>These functions provide support for command-line argument processing and are included if needed library code is missing.</text></s>
<s sid="452"><CoreSc1 advantage="None" conceptID="Obs106" novelty="None" type="Obs"/><text>Table 4 shows the statistics for the five largest clusters of acct.</text></s>
<s sid="453"><CoreSc1 advantage="None" conceptID="Obs107" novelty="None" type="Obs"/><text>Column 1 gives the cluster number, where 1 is the largest and 5 is the 5th largest cluster measured using the number of vertices.</text></s>
<s sid="454"><CoreSc1 advantage="None" conceptID="Obs108" novelty="None" type="Obs"/><text>Columns 2 and 3 show the size of the cluster as a percentage of the program's vertices and actual vertex count, as well as the line count.</text></s>
<s sid="455"><CoreSc1 advantage="None" conceptID="Res166" novelty="None" type="Res"/><text>Columns 4 and 5 show the number of files and functions where the cluster is found.</text></s>
<s sid="456"><CoreSc1 advantage="None" conceptID="Res167" novelty="None" type="Res"/><text>The cluster sizes range from 11.4% to 2.4%.</text></s>
<s sid="457"><CoreSc1 advantage="None" conceptID="Res168" novelty="None" type="Res"/><text>These five clusters can be readily identified in the Heat-Map visualization (not shown) of decluvi.</text></s>
<s sid="458"><CoreSc1 advantage="None" conceptID="Res169" novelty="None" type="Res"/><text>The rest of the clusters are very small (less than 2% or 30 vertices) in size and are thus of little interest.</text></s>
<s sid="459"><CoreSc1 advantage="None" conceptID="Res170" novelty="None" type="Res"/><text>The B-SCG for acct (row one of Fig. 11) shows the existence of these five coherent clusters along with other same-slice clusters.</text></s>
<s sid="460"><CoreSc1 advantage="None" conceptID="Res171" novelty="None" type="Res"/><text>Splitting of the same-slice cluster is evident in the SCG.</text></s>
<s sid="461"><CoreSc1 advantage="None" conceptID="Res172" novelty="None" type="Res"/><text>Splitting occurs when the vertices of a same-slice cluster become part of different coherent clusters.</text></s>
<s sid="462"><CoreSc1 advantage="None" conceptID="Res173" novelty="None" type="Res"/><text>This happens when vertices have either the same backward slice or the same forward slice but not both.</text></s>
<s sid="463"><CoreSc1 advantage="None" conceptID="Res174" novelty="None" type="Res"/><text>This is because either same-backward-slice or same-forward-slice clusters only capture one of the two external properties captured by coherent clusters (Eq.</text></s>
(1)).
<s sid="464"><CoreSc1 advantage="None" conceptID="Res175" novelty="None" type="Res"/><text>In acct's B-SCG the vertices of the largest same-backward-slice cluster spanning the x-axis from 60% to 75% are not part of the same coherent cluster.</text></s>
<s sid="465"><CoreSc1 advantage="None" conceptID="Res176" novelty="None" type="Res"/><text>This is because the vertices do not share the same forward slice which is also a requirement for coherent clusters.</text></s>
<s sid="466"><CoreSc1 advantage="None" conceptID="Res177" novelty="None" type="Res"/><text>This phenomenon is common in the programs studied and is found in both same-backward-slice and same-forward-slice clusters.</text></s>
<s sid="467"><CoreSc1 advantage="None" conceptID="Res178" novelty="None" type="Res"/><text>This is another reason why coherent clusters are often smaller in size then same-slice clusters.</text></s>
<s sid="468"><CoreSc1 advantage="None" conceptID="Res179" novelty="None" type="Res"/><text>Decluvi visualization (not shown) of acct reveals that the largest cluster spans four files (file_rd.c, common.c, ac.c, and utmp_rd.c), the 2nd largest cluster spans only a single file (hashtab.c), the 3rd largest cluster spans three files (file_rd.c, ac.c, and hashtab.c), the 4th largest cluster spans two files (ac.c and hashtab.c), while the 5th largest cluster includes parts of ac.c only.</text></s>
<s sid="469"><CoreSc1 advantage="None" conceptID="Con18" novelty="None" type="Con"/><text>The largest cluster of acct is spread over six functions, log_in, log_out, file_open, file_reader_get_entry, bad_utmp_record and utmp_get_entry.</text></s>
<s sid="470"><CoreSc1 advantage="None" conceptID="Con19" novelty="None" type="Con"/><text>These functions are responsible for putting accounting records into the hash table used by the program, accessing user-defined files, and reading entries from the file.</text></s>
<s sid="471"><CoreSc1 advantage="None" conceptID="Con20" novelty="None" type="Con"/><text>Thus, the purpose of the code in this cluster is to track user login and logout events.</text></s>
<s sid="472"><CoreSc1 advantage="None" conceptID="Obs109" novelty="None" type="Obs"/><text>The second largest cluster is spread over two functions hashtab_create and hashtab_resize.</text></s>
<s sid="473"><CoreSc1 advantage="None" conceptID="Obs110" novelty="None" type="Obs"/><text>These functions are responsible for creating fresh hash tables and resizing existing hash tables when the number of entries becomes too large.</text></s>
<s sid="474"><CoreSc1 advantage="None" conceptID="Obs111" novelty="None" type="Obs"/><text>The purpose of the code in this cluster is the memory management in support of the program's main data structure.</text></s>
<s sid="475"><CoreSc1 advantage="None" conceptID="Obs112" novelty="None" type="Obs"/><text>The third largest cluster is spread over four functions: hashtab_set_value, log_everyone_out, update_user_time, and hashtab_create.</text></s>
<s sid="476"><CoreSc1 advantage="None" conceptID="Obs113" novelty="None" type="Obs"/><text>These functions are responsible for setting values of an entry, updating all the statistics for users, and resetting the tables.</text></s>
<s sid="477"><CoreSc1 advantage="None" conceptID="Res180" novelty="None" type="Res"/><text>The purpose of the code from this cluster is the modification of the user accounting data.</text></s>
<s sid="478"><CoreSc1 advantage="None" conceptID="Res181" novelty="None" type="Res"/><text>The fourth cluster is spread over three functions: hashtab_delete, do_statistics, and hashtab_find.</text></s>
<s sid="479"><CoreSc1 advantage="None" conceptID="Res182" novelty="None" type="Res"/><text>These functions are responsible for removing entries from the hash table, printing out statistics for users and finding entries in the hash table.</text></s>
<s sid="480"><CoreSc1 advantage="None" conceptID="Res183" novelty="None" type="Res"/><text>The purpose of the code from this cluster is maintaining user accounting data and printing results.</text></s>
<s sid="481"><CoreSc1 advantage="None" conceptID="Res184" novelty="None" type="Res"/><text>The fifth cluster is contained within the function main.</text></s>
<s sid="482"><CoreSc1 advantage="None" conceptID="Res185" novelty="None" type="Res"/><text>This cluster is formed due to the use of a while loop containing various cases based on input to the program.</text></s>
<s sid="483"><CoreSc1 advantage="None" conceptID="Res186" novelty="None" type="Res"/><text>Because of the conservative nature of static analysis, all the code within the loop is part of the same cluster.</text></s>
<s sid="484"><CoreSc1 advantage="None" conceptID="Res187" novelty="None" type="Res"/><text>Finally, it is interesting to note that functions from the same file or with similar names do not necessarily belong to the same cluster.</text></s>
<s sid="485"><CoreSc1 advantage="None" conceptID="Con21" novelty="None" type="Con"/><text>Intuitively, it can be presumed that functions that have similar names or prefixes work together to provide some common functionality.</text></s>
<s sid="486"><CoreSc1 advantage="None" conceptID="Con22" novelty="None" type="Con"/><text>In this case, six functions that have the same common prefix &quot;hashtab&quot; all perform operations on the hash table.</text></s>
<s sid="487"><CoreSc1 advantage="None" conceptID="Con23" novelty="None" type="Con"/><text>However, these six functions are not part of the same cluster.</text></s>
<s sid="488"><CoreSc1 advantage="None" conceptID="Con24" novelty="None" type="Con"/><text>Instead the functions that work together to provide a particular functionality are found in the same cluster.</text></s>
<s sid="489"><CoreSc1 advantage="None" conceptID="Res188" novelty="None" type="Res"/><text>The clusters help identify functionality which is not obvious from the name of program artefacts such as functions and files.</text></s>
<s sid="490"><CoreSc1 advantage="None" conceptID="Res189" novelty="None" type="Res"/><text>As an answer to RQ4, we find that in this case study each of the top five clusters maps to specific logical functionality.</text></s>
Case study: indent
<s sid="491"><CoreSc1 advantage="None" conceptID="Res190" novelty="None" type="Res"/><text>The next case study uses indent to further support the answer found for RQ4 in the acct case study.</text></s>
<s sid="492"><CoreSc1 advantage="None" conceptID="Res191" novelty="None" type="Res"/><text>The characteristics of indent are very different from those of acct as indent has a very large dominant coherent cluster (52%) whereas acct has multiple smaller clusters with the largest being 11%.</text></s>
<s sid="493"><CoreSc1 advantage="None" conceptID="Res192" novelty="None" type="Res"/><text>We include indent as a case study to ensure that the answer for RQ4 is derived from programs with different cluster profiles and sizes giving confidence as to the generality of the answer.</text></s>
<s sid="494"><CoreSc1 advantage="None" conceptID="Res193" novelty="None" type="Res"/><text>Indent is a Unix utility used to format C source code.</text></s>
<s sid="495"><CoreSc1 advantage="None" conceptID="Res194" novelty="None" type="Res"/><text>It consists of 6978 LoC with 7543 vertices in the SDG produced by CodeSurfer.</text></s>
<s sid="496"><CoreSc1 advantage="None" conceptID="Res195" novelty="None" type="Res"/><text>Table 5 shows statistics of the five largest clusters found in the program.</text></s>
<s sid="497"><CoreSc1 advantage="None" conceptID="Res196" novelty="None" type="Res"/><text>Indent has one extremely large coherent cluster that spans 52.1% of the program's vertices.</text></s>
<s sid="498"><CoreSc1 advantage="None" conceptID="Res197" novelty="None" type="Res"/><text>The cluster is formed of vertices from 54 functions spread over 7 source files.</text></s>
<s sid="499"><CoreSc1 advantage="None" conceptID="Res198" novelty="None" type="Res"/><text>This cluster captures most of the logical functionalities of the program.</text></s>
<s sid="500"><CoreSc1 advantage="None" conceptID="Res199" novelty="None" type="Res"/><text>Out of the 54 functions, 26 begin with the common prefix of &quot;handle_token&quot;.</text></s>
<s sid="501"><CoreSc1 advantage="None" conceptID="Con25" novelty="None" type="Con"/><text>These 26 functions are individually responsible for handling a specific token during the formatting process.</text></s>
<s sid="502"><CoreSc1 advantage="None" conceptID="Con26" novelty="None" type="Con"/><text>For example, handle_token_colon, handle_token_comma, handle_token_comment, and handle_token_lbrace are responsible for handling the colon, comma, comment, and left brace tokens, respectively.</text></s>
<s sid="503"><CoreSc1 advantage="None" conceptID="Con27" novelty="None" type="Con"/><text>This cluster also includes multiple handler functions that check the size of the code and labels being handled, such as check_code_size and check_lab_size.</text></s>
<s sid="504"><CoreSc1 advantage="None" conceptID="Con28" novelty="None" type="Con"/><text>Others, such as search_brace, sw_buffer, print_comment, and reduce, help with tracking braces and comments in code.</text></s>
<s sid="505"><CoreSc1 advantage="None" conceptID="Con29" novelty="None" type="Con"/><text>The cluster also spans the main loop of indent (indent_main_loop) that repeatedly calls the parser function parse.</text></s>
<s sid="506"><CoreSc1 advantage="None" conceptID="Con30" novelty="None" type="Con"/><text>Finally, the cluster consists of code for outputting formatted lines such as the functions better_break, computer_code_target, dump_line, dump_line_code, dump_line_label, inhibit_indenting, is_comment_start, output_line_length and slip_horiz_space, and ones that perform flag and memory management (clear_buf_break_list, fill_buffer and set_priority).</text></s>
<s sid="507"><CoreSc1 advantage="None" conceptID="Con31" novelty="None" type="Con"/><text>Cluster 1 therefore consists of the main functionality of this program and provides support for parsing, handling tokens, associated memory management, and output.</text></s>
<s sid="508"><CoreSc1 advantage="None" conceptID="Con32" novelty="None" type="Con"/><text>The parsing, handling of individual tokens and associated memory management are highly inter-twined.</text></s>
<s sid="509"><CoreSc1 advantage="None" conceptID="Res200" novelty="None" type="Res"/><text>For example, the handling of each individual token is dictated by operations of indent and closely depends on the parsing.</text></s>
<s sid="510"><CoreSc1 advantage="None" conceptID="Res201" novelty="None" type="Res"/><text>This code cannot easily be decoupled and, for example, reused.</text></s>
<s sid="511"><CoreSc1 advantage="None" conceptID="Res202" novelty="None" type="Res"/><text>Similarly the memory management code is specific to the data structures used by indent resulting in these many logical constructs to become part of the same cluster.</text></s>
<s sid="512"><CoreSc1 advantage="None" conceptID="Res203" novelty="None" type="Res"/><text>The second largest coherent cluster consists of 7 functions from 3 source files.</text></s>
<s sid="513"><CoreSc1 advantage="None" conceptID="Res204" novelty="None" type="Res"/><text>These functions handle the arguments and parameters passed to indent.</text></s>
<s sid="514"><CoreSc1 advantage="None" conceptID="Res205" novelty="None" type="Res"/><text>For example, set_option and option_prefix along with the helper function eqin to check and verify that the options or parameters passed to indent are valid.</text></s>
<s sid="515"><CoreSc1 advantage="None" conceptID="Res206" novelty="None" type="Res"/><text>When options are specified without the required arguments, the function arg_missing produces an error message by invoking usage followed by a call to DieError to terminate the program.</text></s>
<s sid="516"><CoreSc1 advantage="None" conceptID="Res207" novelty="None" type="Res"/><text>Clusters 3-5 are less than 3% of the program and are too small to warrant a detailed discussion.</text></s>
<s sid="517"><CoreSc1 advantage="None" conceptID="Res208" novelty="None" type="Res"/><text>Cluster 3 includes 6 functions that generate numbered/un-numbered backup for subject files.</text></s>
<s sid="518"><CoreSc1 advantage="None" conceptID="Res209" novelty="None" type="Res"/><text>Cluster 4 has functions for reading and ignoring comments.</text></s>
<s sid="519"><CoreSc1 advantage="None" conceptID="Res210" novelty="None" type="Res"/><text>Cluster 5 consists of a single function that reinitializes the parser and associated data structures.</text></s>
<s sid="520"><CoreSc1 advantage="None" conceptID="Con33" novelty="None" type="Con"/><text>The case study of indent further illustrates that coherent clusters can capture the program's logical structure as an answer to research question RQ4.</text></s>
<s sid="521"><CoreSc1 advantage="None" conceptID="Res211" novelty="None" type="Res"/><text>However, in cases such as this where the internal functionality is tightly knit, a single large coherent cluster maps to the program's core functionality.</text></s>
Case study: bc
<s sid="522"><CoreSc1 advantage="None" conceptID="Res212" novelty="None" type="Res"/><text>The third case study in this series is bc, an open-source calculator, which consists of 9438 LoC and 5450 SLoC.</text></s>
<s sid="523"><CoreSc1 advantage="None" conceptID="Res213" novelty="None" type="Res"/><text>The program has nine C files from which CodeSurfer produced 15,076 slices (backward and forward).</text></s>
<s sid="524"><CoreSc1 advantage="None" conceptID="Res214" novelty="None" type="Res"/><text>Analyzing bc's SCG (row 3, Fig. 11), two interesting observations can be made.</text></s>
<s sid="525"><CoreSc1 advantage="None" conceptID="Res215" novelty="None" type="Res"/><text>First, bc contains two large same-backward-slice clusters visible in the light gray landscapes as opposed to the three large coherent clusters.</text></s>
<s sid="526"><CoreSc1 advantage="None" conceptID="Res216" novelty="None" type="Res"/><text>Second, looking at the B-SCG, it can be seen that the x-axis range spanned by the largest same-backward-slice cluster is occupied by the top two coherent clusters shown in the dashed red (dark gray) landscape.</text></s>
<s sid="527"><CoreSc1 advantage="None" conceptID="Res217" novelty="None" type="Res"/><text>This indicates that the same-backward-slice cluster splits into the two coherent clusters.</text></s>
<s sid="528"><CoreSc1 advantage="None" conceptID="Res218" novelty="None" type="Res"/><text>The statistics for bc's top five clusters are given in Table 6.</text></s>
<s sid="529"><CoreSc1 advantage="None" conceptID="Res219" novelty="None" type="Res"/><text>Sizes of these five clusters range from 32.3% through to 1.4% of the program.</text></s>
<s sid="530"><CoreSc1 advantage="None" conceptID="Res220" novelty="None" type="Res"/><text>Clusters six onwards are less than 1% of the program.</text></s>
<s sid="531"><CoreSc1 advantage="None" conceptID="Obs114" novelty="None" type="Obs"/><text>The Project View (Fig. 13) shows their distribution over the source files.</text></s>
<s sid="532"><CoreSc1 advantage="None" conceptID="Obs115" novelty="None" type="Obs"/><text>In more detail, Cluster 1 spans all of bc's files except for scan.c and bc.c.</text></s>
<s sid="533"><CoreSc1 advantage="None" conceptID="Res221" novelty="None" type="Res"/><text>This cluster encompasses the core functionality of the program - loading and handling of equations, converting to bc's own number format, performing calculations, and accumulating results.</text></s>
<s sid="534"><CoreSc1 advantage="None" conceptID="Res222" novelty="None" type="Res"/><text>Cluster 2 spans five files, util.c, execute.c, main.c, scan.c, and bc.c.</text></s>
<s sid="535"><CoreSc1 advantage="None" conceptID="Obs116" novelty="None" type="Obs"/><text>The majority of the cluster is distributed over the latter two files.</text></s>
<s sid="536"><CoreSc1 advantage="None" conceptID="Obs117" novelty="None" type="Obs"/><text>Even more interestingly, the source code of these two files (scan.c and bc.c) map only to Cluster 2 and none of the other top five clusters.</text></s>
<s sid="537"><CoreSc1 advantage="None" conceptID="Res223" novelty="None" type="Res"/><text>This indicates a clear purpose to the code in these files.</text></s>
<s sid="538"><CoreSc1 advantage="None" conceptID="Res224" novelty="None" type="Res"/><text>These two files are solely used for lexical analysis and parsing of equations.</text></s>
<s sid="539"><CoreSc1 advantage="None" conceptID="Con34" novelty="None" type="Con"/><text>To aid in this task, some utility functions from util.c are employed.</text></s>
<s sid="540"><CoreSc1 advantage="None" conceptID="Res225" novelty="None" type="Res"/><text>Only five lines of code in execute.c are also part of Cluster 2 and are used for flushing output and clearing interrupt signals.</text></s>
<s sid="541"><CoreSc1 advantage="None" conceptID="Res226" novelty="None" type="Res"/><text>The third cluster is completely contained within the file number.c.</text></s>
<s sid="542"><CoreSc1 advantage="None" conceptID="Con35" novelty="None" type="Con"/><text>It encompasses functions such as _bc_do_sub, _bc_init_num, _bc_do_compare, _bc_do_add, _bc_simp_mul, _bc_shift_addsub, and _bc_rm_leading_zeros, which are responsible for initializing bc's number formatter, performing comparisons, modulo and other arithmetic operations.</text></s>
<s sid="543"><CoreSc1 advantage="None" conceptID="Obs118" novelty="None" type="Obs"/><text>Clusters 4 and 5 are also completely contained within number.c.</text></s>
<s sid="544"><CoreSc1 advantage="None" conceptID="Res227" novelty="None" type="Res"/><text>These clusters encompass functions to perform bcd operations for base ten numbers and arithmetic division, respectively.</text></s>
<s sid="545"><CoreSc1 advantage="None" conceptID="Res228" novelty="None" type="Res"/><text>As an answer to RQ4, the results of the cluster visualizations for bc reveal its high-level structure.</text></s>
<s sid="546"><CoreSc1 advantage="None" conceptID="Con36" novelty="None" type="Con"/><text>This aids an engineer in understanding how the artifacts (e.g., functions and files) of the program interact, thus aiding in program comprehension.</text></s>
<s sid="547"><CoreSc1 advantage="None" conceptID="Con37" novelty="None" type="Con"/><text>The remainder of this subsection illustrates a side-effect of decluvi's multi-level visualization, how it can help find potential problems with the structure of a program.</text></s>
<s sid="548"><CoreSc1 advantage="None" conceptID="Con38" novelty="None" type="Con"/><text>Util.c consists of small utility functions called from various parts of the program.</text></s>
<s sid="549"><CoreSc1 advantage="None" conceptID="Res229" novelty="None" type="Res"/><text>This file contains code from Clusters 1 and 2 (Fig. 13).</text></s>
<s sid="550"><CoreSc1 advantage="None" conceptID="Res230" novelty="None" type="Res"/><text>Five of the utility functions belong with Cluster 1, while six belong with Cluster 2.</text></s>
<s sid="551"><CoreSc1 advantage="None" conceptID="Res231" novelty="None" type="Res"/><text>Furthermore, Fig. 14 shows that the distribution of the two clusters in red (dark gray) and blue (medium gray) within the file are well separated.</text></s>
<s sid="552"><CoreSc1 advantage="None" conceptID="Res232" novelty="None" type="Res"/><text>Both clusters do not occur together inside any function with the exception of init_gen (highlighted by the rectangle in first column of Fig. 14).</text></s>
<s sid="553"><CoreSc1 advantage="None" conceptID="Res233" novelty="None" type="Res"/><text>The other functions of util.c thus belong to either Cluster 1 or Cluster 2.</text></s>
<s sid="554"><CoreSc1 advantage="None" conceptID="Res234" novelty="None" type="Res"/><text>Separating these utility functions into two separate source files where each file is dedicated to functions belonging to a single cluster would improve the code's logical separation and file-level cohesion.</text></s>
<s sid="555"><CoreSc1 advantage="None" conceptID="Con39" novelty="None" type="Con"/><text>This would make the code easier to understand and maintain at the expense of a very simple refactoring.</text></s>
<s sid="556"><CoreSc1 advantage="None" conceptID="Con40" novelty="None" type="Con"/><text>In general, this example illustrates how decluvi visualization can provide an indicator of potential points of code degradation during evolution.</text></s>
<s sid="557"><CoreSc1 advantage="None" conceptID="Res235" novelty="None" type="Res"/><text>Finally, the Code View for function init_gen shown in Fig. 15 includes Lines 244, 251, 254, and 255 in red (dark gray) from Cluster 1 and Lines 247, 248, 249, and 256 in blue (medium gray) from Cluster 2.</text></s>
<s sid="558"><CoreSc1 advantage="None" conceptID="Res236" novelty="None" type="Res"/><text>Other lines, shown in light gray, belong to smaller clusters and lines containing no executable code.</text></s>
<s sid="559"><CoreSc1 advantage="None" conceptID="Con41" novelty="None" type="Con"/><text>Ideally, clusters should capture a particular functionality; thus, functions should generally not contain code from multiple clusters (unless perhaps the clusters are completely contained within the function).</text></s>
<s sid="560"><CoreSc1 advantage="None" conceptID="Res237" novelty="None" type="Res"/><text>Functions with code from multiple clusters reduce code separation (hindering comprehension) and increase the likelihood of ripple-effects (Black, 2001).</text></s>
<s sid="561"><CoreSc1 advantage="None" conceptID="Res238" novelty="None" type="Res"/><text>Like other initialization functions, bc'sinit_gen is an exception to this guideline.</text></s>
<s sid="562"><CoreSc1 advantage="None" conceptID="Res239" novelty="None" type="Res"/><text>This case study not only provides support for the answer to research question RQ4 found in previous case studies, but also illustrates that the visualization is able to reveal structural defects in programs.</text></s>
Case study: copia
<s sid="563"><CoreSc1 advantage="None" conceptID="Res240" novelty="None" type="Res"/><text>The final case study in this series is copia, an industrial program used by the ESA to perform signal processing.</text></s>
<s sid="564"><CoreSc1 advantage="None" conceptID="Res241" novelty="None" type="Res"/><text>Copiais the smallest program considered in this series of case studies with 1168 LoC and 1111 SLoC all in a single C file.</text></s>
<s sid="565"><CoreSc1 advantage="None" conceptID="Res242" novelty="None" type="Res"/><text>Its largest coherent cluster covers 48% of the program.</text></s>
<s sid="566"><CoreSc1 advantage="None" conceptID="Res243" novelty="None" type="Res"/><text>The program is at the top of the group with large coherent clusters.</text></s>
<s sid="567"><CoreSc1 advantage="None" conceptID="Res244" novelty="None" type="Res"/><text>CodeSurfer extracts 6654 slices (backward and forward).</text></s>
<s sid="568"><CoreSc1 advantage="None" conceptID="Res245" novelty="None" type="Res"/><text>The B-SCG for copia is shown in Fig. 16a.</text></s>
<s sid="569"><CoreSc1 advantage="None" conceptID="Res246" novelty="None" type="Res"/><text>The single large coherent cluster spanning 48% of the program is shown by the dashed red (dark gray) line (running approx.</text></s>
<s sid="570"><CoreSc1 advantage="None" conceptID="Res247" novelty="None" type="Res"/><text>from 2% to 50% on the x-axis).</text></s>
<s sid="571"><CoreSc1 advantage="None" conceptID="Res248" novelty="None" type="Res"/><text>The plots for same-backward-slice cluster sizes (light gray line) and the coherent cluster sizes (dashed line) are identical.</text></s>
<s sid="572"><CoreSc1 advantage="None" conceptID="Res249" novelty="None" type="Res"/><text>This is because the size of the coherent clusters are restricted by the size of the same-backward-slice clusters.</text></s>
<s sid="573"><CoreSc1 advantage="None" conceptID="Res250" novelty="None" type="Res"/><text>Although the plot for the size of the backward slices (black line) seems to be the same from the 10% mark to 95% mark on the x-axis, the slices are not exactly the same.</text></s>
<s sid="574"><CoreSc1 advantage="None" conceptID="Res251" novelty="None" type="Res"/><text>Only vertices plotted from 2% through to 50% have exactly same backward and forward slice resulting in the large coherent cluster.</text></s>
<s sid="575"><CoreSc1 advantage="None" conceptID="Res252" novelty="None" type="Res"/><text>Table 7 shows statistics for the top five coherent clusters found in copia.</text></s>
<s sid="576"><CoreSc1 advantage="None" conceptID="Res253" novelty="None" type="Res"/><text>Other than the largest cluster which covers 48% of the program, the rest of the clusters are extremely small.</text></s>
<s sid="577"><CoreSc1 advantage="None" conceptID="Res254" novelty="None" type="Res"/><text>Clusters 2-5 include no more than 0.1% of the program (four vertices) rendering them too small to be of interest.</text></s>
<s sid="578"><CoreSc1 advantage="None" conceptID="Res255" novelty="None" type="Res"/><text>This suggests a program with a single functionality or structure.</text></s>
<s sid="579"><CoreSc1 advantage="None" conceptID="Res256" novelty="None" type="Res"/><text>During analysis of copiausing decluvi, the File View (Fig. 17) reveals an intriguing structure.</text></s>
<s sid="580"><CoreSc1 advantage="None" conceptID="Res257" novelty="None" type="Res"/><text>There is a large block of code with the same spatial arrangement (bounded by the dotted black rectangle in Fig. 17) that belongs to the largest cluster of the program.</text></s>
<s sid="581"><CoreSc1 advantage="None" conceptID="Res258" novelty="None" type="Res"/><text>It is unusual for so many consecutive source code lines to have nearly identical length and indentation.</text></s>
<s sid="582"><CoreSc1 advantage="None" conceptID="Res259" novelty="None" type="Res"/><text>Inspection of the source code reveals that this block of code is a switch statement handling 234 cases.</text></s>
<s sid="583"><CoreSc1 advantage="None" conceptID="Res260" novelty="None" type="Res"/><text>Further investigation shows that copiahas 234 small functions that eventually call one large function, seleziona, which in turn calls the smaller functions effectively implementing a finite state machine.</text></s>
<s sid="584"><CoreSc1 advantage="None" conceptID="Res261" novelty="None" type="Res"/><text>Each of the smaller functions returns a value that is the next state for the machine and is used by the switch statement to call the appropriate next function.</text></s>
<s sid="585"><CoreSc1 advantage="None" conceptID="Res262" novelty="None" type="Res"/><text>The primary reason for the high level of dependence in the program lies with the statement switch(next_state), which controls the calls to the smaller functions.</text></s>
<s sid="586"><CoreSc1 advantage="None" conceptID="Con42" novelty="None" type="Con"/><text>This causes what might be termed 'conservative dependence analysis collateral damage' because the static analysis cannot determine that when function f() returns the constant value 5 this leads the switch statement to eventually invoke function g().</text></s>
<s sid="587"><CoreSc1 advantage="None" conceptID="Con43" novelty="None" type="Con"/><text>Instead, the analysis makes the conservative assumption that a call to f() might be followed by a call to any of the functions called in the switch statement, resulting in a mutual recursion involving most of the program.</text></s>
<s sid="588"><CoreSc1 advantage="None" conceptID="Con44" novelty="None" type="Con"/><text>Although the coherent cluster still shows the structure of the program and includes all these stub functions that work together, this is a clear case of dependence pollution (Binkley and Harman, 2005), which is avoidable.</text></s>
<s sid="589"><CoreSc1 advantage="None" conceptID="Res263" novelty="None" type="Res"/><text>To illustrate this, the code was re-factored to simulate the replacement of the integer next_state with direct recursive function calls.</text></s>
<s sid="590"><CoreSc1 advantage="None" conceptID="Obs119" novelty="None" type="Obs"/><text>The SCG for the modified version of copiais shown in Fig. 16b where the large cluster has clearly disappeared.</text></s>
<s sid="591"><CoreSc1 advantage="None" conceptID="Con45" novelty="None" type="Con"/><text>As a result of this reduction, the potential impact of changes to the program will be greatly reduced, making it easier to understand and maintain.</text></s>
<s sid="592"><CoreSc1 advantage="None" conceptID="Con46" novelty="None" type="Con"/><text>This is even further amplified for automatic static analysis tools such as CodeSurfer.</text></s>
<s sid="593"><CoreSc1 advantage="None" conceptID="Con47" novelty="None" type="Con"/><text>Of course, in order to do a proper re-factoring, the programmer will have to consider ways in which the program can be re-written to change the flow of control.</text></s>
<s sid="594"><CoreSc1 advantage="None" conceptID="Con48" novelty="None" type="Con"/><text>Whether such a re-factoring is deemed cost-effective is a decision that can only be taken by the engineers and managers responsible for maintaining the program in question.</text></s>
<s sid="595"><CoreSc1 advantage="None" conceptID="Con49" novelty="None" type="Con"/><text>This case study reiterates the answer for RQ4 by showing the structure and dependency within the program.</text></s>
<s sid="596"><CoreSc1 advantage="None" conceptID="Con50" novelty="None" type="Con"/><text>It also identifies potential refactoring points which can improve the performance of static analysis tools and make the program easier to understand.</text></s>
Inter-cluster dependence
<s sid="597"><CoreSc1 advantage="None" conceptID="Res264" novelty="None" type="Res"/><text>This section addresses research question RQ5: What are the implications of inter-cluster dependence between coherent clusters?</text></s>
<s sid="598"><CoreSc1 advantage="None" conceptID="Res265" novelty="None" type="Res"/><text>The question attempts to reveal whether there is dependence (slice inclusion) relationship between the vertices of different coherent clusters.</text></s>
<s sid="599"><CoreSc1 advantage="None" conceptID="Res266" novelty="None" type="Res"/><text>A slice inclusion relationship between two clusters X and Y exist, if ∃x∈X:BSlice(x)∩Y≠∅.</text></s>
<s sid="600"><CoreSc1 advantage="None" conceptID="Res267" novelty="None" type="Res"/><text>If such containment occurs, it must be a strict containment relationship (BSlice(x)∩Y=Y, see Eq.</text></s>
1).
<s sid="601"><CoreSc1 advantage="None" conceptID="Res268" novelty="None" type="Res"/><text>Defining this relation using forward slices produces the inverse relation.</text></s>
<s sid="602"><CoreSc1 advantage="None" conceptID="Goa22" novelty="None" type="Goa"/><text>In the series of case studies presented earlier we have seen that coherent clusters map to logical components of a system and can be used to gain an understanding of the architecture of the program.</text></s>
<s sid="603"><CoreSc1 advantage="None" conceptID="Con51" novelty="None" type="Con"/><text>If such dependencies exist that allows entire clusters to depend on other clusters, then this dependence relationship can be used to group clusters to form a hierarchical decomposition of the system where coherent clusters are regarded as sub-systems, opening up the potential use of coherent clusters in reverse engineering.</text></s>
<s sid="604"><CoreSc1 advantage="None" conceptID="Res269" novelty="None" type="Res"/><text>Secondly, if there are mutual dependency relations between clusters then such mutual dependency relationships can be used to provide a better estimate of slice-based clusters.</text></s>
<s sid="605"><CoreSc1 advantage="None" conceptID="Res270" novelty="None" type="Res"/><text>All vertices of a coherent cluster share the same external and internal dependence, that is, all vertices have the same backward slice and also the same forward slice.</text></s>
<s sid="606"><CoreSc1 advantage="None" conceptID="Res271" novelty="None" type="Res"/><text>Because of this, any backward/forward slice that includes a vertex from a cluster will also include all other vertices of the same cluster (Eq.</text></s>
1).
<s sid="607"><CoreSc1 advantage="None" conceptID="Goa23" novelty="None" type="Goa"/><text>The study exploits this unique property of coherent clusters to investigate whether or not a backward slice taken with respect to a vertex of a coherent cluster includes vertices of another cluster.</text></s>
<s sid="608"><CoreSc1 advantage="None" conceptID="Mod29" novelty="None" type="Mod"/><text>Note that if vertices of coherent cluster X are contained in the slice taken with respect to a vertex of coherent cluster Y, then all vertices of X are contained in the slice taken with respect to each vertex of Y (follows from Eq. 1).</text></s>
<s sid="609"><CoreSc1 advantage="None" conceptID="Obs120" novelty="None" type="Obs"/><text>Fig. 18 shows Cluster Dependence Graphs (CDG) for each of the four case study subjects.</text></s>
<s sid="610"><CoreSc1 advantage="None" conceptID="Obj37" novelty="None" type="Obj"/><text>Only the five largest clusters of the case study subjects are considered during this study.</text></s>
<s sid="611"><CoreSc1 advantage="None" conceptID="Obs121" novelty="None" type="Obs"/><text>The graphs depict slice containment relationships between the top five clusters of each program.</text></s>
<s sid="612"><CoreSc1 advantage="None" conceptID="Obs122" novelty="None" type="Obs"/><text>In these graphs, the top five clusters are represented by nodes (1 depicts the largest coherent cluster, while 5 is the 5th largest cluster) and the directional edges denote backward slice22</text></s>
<s sid="613"><CoreSc1 advantage="None" conceptID="Res272" novelty="None" type="Res"/><text>A definition based on forward slices will have the same results with reversed edges.</text></s>
<s sid="614"><CoreSc1 advantage="None" conceptID="Res273" novelty="None" type="Res"/><text>inclusion relationships: A→B depicts that vertices of cluster B depend on vertices of cluster A, that is, a backward slice of any vertex of cluster B will include all vertices of cluster A (∀x∈B:BSlice(x)∩A=A).</text></s>
<s sid="615"><CoreSc1 advantage="None" conceptID="Res274" novelty="None" type="Res"/><text>Bi-directional edges show mutual dependencies, whereas uni-directional edges show dependency in one direction only.</text></s>
<s sid="616"><CoreSc1 advantage="None" conceptID="Res275" novelty="None" type="Res"/><text>In the graph for copia(Fig. 18a), the top five clusters have no slice inclusion relationships between them (absence of edges between the nodes of the CDG).</text></s>
<s sid="617"><CoreSc1 advantage="None" conceptID="Res276" novelty="None" type="Res"/><text>Looking at Table 7, only the largest cluster of copiais truly large at 48%, while the other four clusters are extremely small making them unlikely candidates for inter-cluster dependence.</text></s>
<s sid="618"><CoreSc1 advantage="None" conceptID="Res277" novelty="None" type="Res"/><text>For acct(Fig. 18b) there is a dependence between all of the top five clusters.</text></s>
<s sid="619"><CoreSc1 advantage="None" conceptID="Res278" novelty="None" type="Res"/><text>In fact, there is mutual dependence between clusters 1, 2, 3 and 4, while cluster 5 depends on all the other four clusters but not mutually.</text></s>
<s sid="620"><CoreSc1 advantage="None" conceptID="Res279" novelty="None" type="Res"/><text>Clusters 1 through 4 contain logic for manipulating, accessing, and maintaining the hash tables, making them interdependent.</text></s>
<s sid="621"><CoreSc1 advantage="None" conceptID="Obs123" novelty="None" type="Obs"/><text>Cluster 5 on the other hand is a loop structure within the main function for executing different cases based on command line inputs.</text></s>
<s sid="622"><CoreSc1 advantage="None" conceptID="Obs124" novelty="None" type="Obs"/><text>Similarly for indent (Fig. 18c), clusters 1, 2, 4, and 5 are mutually dependent and 3 depends on all the other top five clusters but not mutually.</text></s>
<s sid="623"><CoreSc1 advantage="None" conceptID="Obs125" novelty="None" type="Obs"/><text>Finally, in the case of bc (Fig. 18d), all the vertices from the top five clusters are mutually inter-dependent.</text></s>
<s sid="624"><CoreSc1 advantage="None" conceptID="Res280" novelty="None" type="Res"/><text>The rest of this section uses bcas an example where this mutual dependence is used to identify larger dependence structures by grouping of the inter-dependent coherent clusters.</text></s>
<s sid="625"><CoreSc1 advantage="None" conceptID="Res281" novelty="None" type="Res"/><text>At first glance it may seem that the grouping of the coherent clusters is simply reversing the splitting of same-backward-slice or same-forward-slice clusters observed earlier in Section 3.6.3.</text></s>
<s sid="626"><CoreSc1 advantage="None" conceptID="Res282" novelty="None" type="Res"/><text>However, examining the sizes of the top five same-backward-slice clusters, same-forward-slice clusters and coherent clusters for bcillustrates that it is not the case.</text></s>
<s sid="627"><CoreSc1 advantage="None" conceptID="Res283" novelty="None" type="Res"/><text>Table 8 shows the size of these clusters both in terms of number of vertices and as a percentage of the program.</text></s>
<s sid="628"><CoreSc1 advantage="None" conceptID="Res284" novelty="None" type="Res"/><text>The combined size of the group of top five inter-dependent coherent clusters is 70.43%, which is 15.67% larger than the largest same-backward-slice cluster (54.86%) and 37.91% larger than the same-forward-slice cluster (32.35%).</text></s>
<s sid="629"><CoreSc1 advantage="None" conceptID="Res285" novelty="None" type="Res"/><text>Therefore, the set of all (mutually dependent) vertices from the top five coherent clusters when taken together form a larger dependence structure, an estimate of a slice-based cluster.</text></s>
<s sid="630"><CoreSc1 advantage="None" conceptID="Res286" novelty="None" type="Res"/><text>As an answer to RQ5, this section shows that there are dependence relationships between coherent clusters and in some cases there are mutual dependences between large coherent clusters.</text></s>
<s sid="631"><CoreSc1 advantage="None" conceptID="Res287" novelty="None" type="Res"/><text>It also shows that it may be possible to leverage this inter-cluster relationship to build a hierarchical system decomposition.</text></s>
<s sid="632"><CoreSc1 advantage="None" conceptID="Res288" novelty="None" type="Res"/><text>Furthermore, groups of inter-dependent coherent clusters form larger dependence structures than same-slice clusters and provides a better approximation for slice-based clusters.</text></s>
<s sid="633"><CoreSc1 advantage="None" conceptID="Bac56" novelty="None" type="Bac"/><text>This indicates that the sizes of dependence clusters reported by previous studies (Binkley et al., 2008; Binkley and Harman, 2005, 2009; Harman et al., 2009; Islam et al., 2010b) maybe conservative and mutual dependence clusters are larger and more prevalent than previously reported.</text></s>
<s sid="634"><CoreSc1 advantage="None" conceptID="Res289" novelty="None" type="Res"/><text>Dependence clusters and bug fixes</text></s>
<s sid="635"><CoreSc1 advantage="None" conceptID="Con52" novelty="None" type="Con"/><text>Initial work on dependence clusters advised that they might cause problems in software maintenance, and thus even be considered harmful, because they represent an intricate interweaving of mutual dependencies between program elements.</text></s>
<s sid="636"><CoreSc1 advantage="None" conceptID="Res290" novelty="None" type="Res"/><text>Thus a large dependence cluster might be thought of as a bad code smell (Elssamadisy and Schalliol, 2002) or a anti-pattern (Binkley et al., 2008).</text></s>
<s sid="637"><CoreSc1 advantage="None" conceptID="Res291" novelty="None" type="Res"/><text>Black et al. (2006) suggested that dependence clusters are potentially where bugs may be located and suggested the possibility of a link between clusters and program faults.</text></s>
<s sid="638"><CoreSc1 advantage="None" conceptID="Obj38" novelty="None" type="Obj"/><text>This section further investigates this issue using a study that explores the relationship between program faults and dependence clusters.</text></s>
<s sid="639"><CoreSc1 advantage="None" conceptID="Obj39" novelty="None" type="Obj"/><text>In doing so, it addresses research question RQ6: How do program faults relate to coherent clusters?</text></s>
<s sid="640"><CoreSc1 advantage="None" conceptID="Obj40" novelty="None" type="Obj"/><text>Barcode, an open source utility tool for converting text strings to printed bars (barcodes) is used in this study.</text></s>
<s sid="641"><CoreSc1 advantage="None" conceptID="Obj41" novelty="None" type="Obj"/><text>A series of versions of the system are available for download from GNU repository.33</text></s>
http://gnu.mirror.iweb.com/gnu/barcode/.
<s sid="642"><CoreSc1 advantage="None" conceptID="Obs126" novelty="None" type="Obs"/><text>There are nine public releases for barcode, details of which are shown in Table 9.</text></s>
<s sid="643"><CoreSc1 advantage="None" conceptID="Obs127" novelty="None" type="Obs"/><text>Column 1 shows the release version, columns 3-6 show various metrics about the size of the system in terms of number of source files and various source code size measures.</text></s>
<s sid="644"><CoreSc1 advantage="None" conceptID="Res292" novelty="None" type="Res"/><text>Columns 7-9 report the number of SDG vertices, SDG edges and the number of slices produced for each release.</text></s>
<s sid="645"><CoreSc1 advantage="None" conceptID="Res293" novelty="None" type="Res"/><text>Finally, Column 10 reports the number of faults that were fixed since the previous release of the system.</text></s>
<s sid="646"><CoreSc1 advantage="None" conceptID="Obs128" novelty="None" type="Obs"/><text>In Table 9 the size of barcode increases from 1352 lines of code in version 0.90 to 3968 lines of code in version 0.98.</text></s>
<s sid="647"><CoreSc1 advantage="None" conceptID="Res294" novelty="None" type="Res"/><text>The total number of faults that were fixed during this time was 39.</text></s>
<s sid="648"><CoreSc1 advantage="None" conceptID="Res295" novelty="None" type="Res"/><text>Fault data, gathered by manually analyzing the publicly available version control repository44</text></s>
cvs.savannah.gnu.org:/sources/barcode.
<s sid="649"><CoreSc1 advantage="None" conceptID="Res296" novelty="None" type="Res"/><text>for the system, showed that total number of commits for barcode during these releases were 137.</text></s>
<s sid="650"><CoreSc1 advantage="None" conceptID="Met14" novelty="None" type="Met"/><text>Each update was manually checked using CVSAnaly (Robles et al., 2004) to determine whether the update was a bug fix or simply an enhancement or upgrade to the system.</text></s>
<s sid="651"><CoreSc1 advantage="None" conceptID="Res297" novelty="None" type="Res"/><text>Those commits that were identified as bug fixes were isolated and mapped to the release that contained the update.</text></s>
<s sid="652"><CoreSc1 advantage="None" conceptID="Res298" novelty="None" type="Res"/><text>All the bug fixes made during a certain release cycle were then accumulated to give the total number of bugs fixed during a particular release cycle (Column 10 of Table 9).</text></s>
<s sid="653"><CoreSc1 advantage="None" conceptID="Res299" novelty="None" type="Res"/><text>The reported number only includes bug fixes and does not include enhancement or addition of new functionality.</text></s>
<s sid="654"><CoreSc1 advantage="None" conceptID="Obs129" novelty="None" type="Obs"/><text>Fig. 19 shows the backward slice size plots for all versions of barcode in a single graph.</text></s>
<s sid="655"><CoreSc1 advantage="None" conceptID="Obs130" novelty="None" type="Obs"/><text>The values of the axises in Fig. 19 are shown as vertex counts rather than relative values (percentages).</text></s>
<s sid="656"><CoreSc1 advantage="None" conceptID="Res300" novelty="None" type="Res"/><text>This allows the growth of barcode to be easily visualized.</text></s>
<s sid="657"><CoreSc1 advantage="None" conceptID="Res301" novelty="None" type="Res"/><text>From the plots it is seen that the size of the program increases progressively with each new release.</text></s>
<s sid="658"><CoreSc1 advantage="None" conceptID="Res302" novelty="None" type="Res"/><text>The graphs also show that a significant number of vertices in each revision of the program yields identical backward slices and the proportion of vertices in the program that have identical backward slices stays roughly the same.</text></s>
<s sid="659"><CoreSc1 advantage="None" conceptID="Res303" novelty="None" type="Res"/><text>Overall, the profile of the clusters and slices remains consistent.</text></s>
<s sid="660"><CoreSc1 advantage="None" conceptID="Res304" novelty="None" type="Res"/><text>The graph also shows that the plots do not show any significant change in their overall shape or structure.</text></s>
<s sid="661"><CoreSc1 advantage="None" conceptID="Res305" novelty="None" type="Res"/><text>Interestingly, the plot for version 0.92 with 9 fault fixes is not different in shape from revision 0.94 where only a single fault was fixed.</text></s>
<s sid="662"><CoreSc1 advantage="None" conceptID="Res306" novelty="None" type="Res"/><text>As coherent clusters are composed of both backward and forward slices, the stability of the backward slice profile itself does not guarantee the stability of coherent cluster profile.</text></s>
<s sid="663"><CoreSc1 advantage="None" conceptID="Res307" novelty="None" type="Res"/><text>The remainder of this section looks at how the clustering profile is affected by bug fixes.</text></s>
<s sid="664"><CoreSc1 advantage="None" conceptID="Obs131" novelty="None" type="Obs"/><text>Fig. 20 shows individual SCGs for each version of barcode.</text></s>
<s sid="665"><CoreSc1 advantage="None" conceptID="Res308" novelty="None" type="Res"/><text>As coherent clusters are dependent on both backward and forward slices, such clusters will be more sensitive to changes in dependences within the program.</text></s>
<s sid="666"><CoreSc1 advantage="None" conceptID="Res309" novelty="None" type="Res"/><text>The SCGs show that from the initial version barcode-0.90 there were two coherent clusters in the system.</text></s>
<s sid="667"><CoreSc1 advantage="None" conceptID="Res310" novelty="None" type="Res"/><text>The smaller one is around 10% of the code while the larger is around 40% of the code.</text></s>
<s sid="668"><CoreSc1 advantage="None" conceptID="Res311" novelty="None" type="Res"/><text>As the system evolved and went through various modifications and enhancements, the number of clusters and the profile of the clusters remained consistent other than its scaled growth with the increase in program size.</text></s>
<s sid="669"><CoreSc1 advantage="None" conceptID="Res312" novelty="None" type="Res"/><text>It is also evident that during evolution of the system, the enhancement code or newly added code formed part of the larger cluster.</text></s>
<s sid="670"><CoreSc1 advantage="None" conceptID="Res313" novelty="None" type="Res"/><text>This is why in the later stages of the evolution we see an increase in the size of the largest cluster, but not the smaller one.</text></s>
<s sid="671"><CoreSc1 advantage="None" conceptID="Res314" novelty="None" type="Res"/><text>However, we do not see any significant changes in the slice and cluster profile of the program that can be attributed to bug fixes.</text></s>
<s sid="672"><CoreSc1 advantage="None" conceptID="Res315" novelty="None" type="Res"/><text>For example, the single bug fixed between revisions 0.93 and 0.94 was on a single line of code from the file code128.c.</text></s>
<s sid="673"><CoreSc1 advantage="None" conceptID="Obs132" novelty="None" type="Obs"/><text>The changes to the line is shown in Fig. 21 (in version 0.93 there is an error in calculating the checksum value, which was corrected in version 0.94).</text></s>
<s sid="674"><CoreSc1 advantage="None" conceptID="Res316" novelty="None" type="Res"/><text>As illustrated by this example, the data and control flow of the program and thus the dependencies between program points are not affected by the bug fix and hence no change is observed between the SCGs of the two releases (Fig. 20).</text></s>
<s sid="675"><CoreSc1 advantage="None" conceptID="Res317" novelty="None" type="Res"/><text>If dependence clusters correlated to faults, or, if dependence clusters were directly related to the number of faults in a program, then a significant difference would be expected in the shape of the SCG when faults were rectified.</text></s>
<s sid="676"><CoreSc1 advantage="None" conceptID="Res318" novelty="None" type="Res"/><text>The SCGs for program barcode (Fig. 20) show no change in their profile when faults within the program are fixed.</text></s>
<s sid="677"><CoreSc1 advantage="None" conceptID="Con53" novelty="None" type="Con"/><text>This provides evidence that faults may not be dictated by the presence or absence of dependence clusters.</text></s>
<s sid="678"><CoreSc1 advantage="None" conceptID="Con54" novelty="None" type="Con"/><text>As an answer to RQ6, the study of barcode finds no correlation between the existence of dependence clusters and program faults and their fix.</text></s>
<s sid="679"><CoreSc1 advantage="None" conceptID="Con55" novelty="None" type="Con"/><text>We have to be careful in generalising the answer to this question because of the small dataset considered in this study, further extended research is needed to derive a more generalised answer.</text></s>
<s sid="680"><CoreSc1 advantage="None" conceptID="Con56" novelty="None" type="Con"/><text>Moreover, this does not exclude the possibility that most program faults occur in code that are part of large clusters.</text></s>
<s sid="681"><CoreSc1 advantage="None" conceptID="Con57" novelty="None" type="Con"/><text>In future we plan to extend this experiment in a qualitative form to study whether program faults lie within large or small clusters, or outside them altogether.</text></s>
Clusters and system evolution
<s sid="682"><CoreSc1 advantage="None" conceptID="Res319" novelty="None" type="Res"/><text>The previous section showed that for barcode the slice and cluster profiles remain quite stable through bug fixes during system evolution and its growth of almost 2.5 times over a period of 3 years.</text></s>
<s sid="683"><CoreSc1 advantage="None" conceptID="Con58" novelty="None" type="Con"/><text>This section extends that study by looking for cluster changes during system evolution.</text></s>
<s sid="684"><CoreSc1 advantage="None" conceptID="Obj42" novelty="None" type="Obj"/><text>It addresses RQ7: How stable are coherent clusters during system evolution? using longitudinal analysis of the case studies presented earlier.</text></s>
<s sid="685"><CoreSc1 advantage="None" conceptID="Con59" novelty="None" type="Con"/><text>From the GNU repository we were able to retrieve four releases for bc, four releases for acct and 14 releases for indent.</text></s>
<s sid="686"><CoreSc1 advantage="None" conceptID="Con60" novelty="None" type="Con"/><text>As copia is an industrial closed-source program, we were unable to obtain any previous versions of the program and thus the program is excluded from this study.</text></s>
<s sid="687"><CoreSc1 advantage="None" conceptID="Obs133" novelty="None" type="Obs"/><text>The graphs in Fig. 22 show backward slice size overlays for every version of each program.</text></s>
<s sid="688"><CoreSc1 advantage="None" conceptID="Obs134" novelty="None" type="Obs"/><text>Fig. 22a and c for bc and indent show that these systems grow in size during its evolution.</text></s>
<s sid="689"><CoreSc1 advantage="None" conceptID="Obs135" novelty="None" type="Obs"/><text>The growth is more prominent in indent (Fig. 22c) where the program grows from around 4800 vertices in its initial version to around 7000 vertices in the final version.</text></s>
<s sid="690"><CoreSc1 advantage="None" conceptID="Obs136" novelty="None" type="Obs"/><text>The growth for bc is smaller, it grows from around 6000 vertices to 7000 vertices.</text></s>
<s sid="691"><CoreSc1 advantage="None" conceptID="Res320" novelty="None" type="Res"/><text>This is partly because the versions considered for bc are all minor revisions.</text></s>
<s sid="692"><CoreSc1 advantage="None" conceptID="Obs137" novelty="None" type="Obs"/><text>For both bc and indent the slice-size graphs show very little change in their profile.</text></s>
<s sid="693"><CoreSc1 advantage="None" conceptID="Obs138" novelty="None" type="Obs"/><text>The graphs mainly show a scale up that parallels the growth of the system.</text></s>
<s sid="694"><CoreSc1 advantage="None" conceptID="Obs139" novelty="None" type="Obs"/><text>For acct (Fig. 22b) the plots do not simply show a scale up but show a significant difference.</text></s>
<s sid="695"><CoreSc1 advantage="None" conceptID="Res321" novelty="None" type="Res"/><text>In the 4 plots, the revisions that belong to the same major release are seen to be similar and show a scaling, whereas those from different major releases show very different landscapes.</text></s>
<s sid="696"><CoreSc1 advantage="None" conceptID="Res322" novelty="None" type="Res"/><text>The remainder of this section gives detail of these clustering profile changes.</text></s>
<s sid="697"><CoreSc1 advantage="None" conceptID="Obs140" novelty="None" type="Obs"/><text>Fig. 23 shows the BSCGs for the four versions of bc.</text></s>
<s sid="698"><CoreSc1 advantage="None" conceptID="Obs141" novelty="None" type="Obs"/><text>Initially, the backward slice size plots (solid black lines) show very little difference.</text></s>
<s sid="699"><CoreSc1 advantage="None" conceptID="Res323" novelty="None" type="Res"/><text>However, upon closer inspection of the last three versions we see that the backward slice size plot changes slightly at around the 80% mark on the x-axis.</text></s>
<s sid="700"><CoreSc1 advantage="None" conceptID="Res324" novelty="None" type="Res"/><text>This is highlighted by the fact that the later three versions show an additional coherent cluster spanning from 85% to 100% on the x-axis which is absent from the initial release.</text></s>
<s sid="701"><CoreSc1 advantage="None" conceptID="Res325" novelty="None" type="Res"/><text>Upon inspection of the source code changes between versions bc-1.03 and bc-1.04 the following types of updates were found:1</text></s>
bug fixes,
2
<s sid="702"><CoreSc1 advantage="None" conceptID="Res326" novelty="None" type="Res"/><text>addition of command line options,</text></s>
3
<s sid="703"><CoreSc1 advantage="None" conceptID="Res327" novelty="None" type="Res"/><text>reorganization of the source tree, and</text></s>
4
<s sid="704"><CoreSc1 advantage="None" conceptID="Res328" novelty="None" type="Res"/><text>addition of new commands for dc.</text></s>
<s sid="705"><CoreSc1 advantage="None" conceptID="Res329" novelty="None" type="Res"/><text>The reorganization of the program involved significant architectural changes that separated out the code supporting bc's related dc functionality into a separate hierarchy and moved files common to both bc and dc to a library.</text></s>
<s sid="706"><CoreSc1 advantage="None" conceptID="Res330" novelty="None" type="Res"/><text>This refactoring of the code broke up the largest cluster into two clusters, where a new third cluster is formed as seen in the SCG.</text></s>
<s sid="707"><CoreSc1 advantage="None" conceptID="Res331" novelty="None" type="Res"/><text>Thus, the major restructuring of the code between revisions 1.03 and 1.04 causes a significant change in the cluster profile.</text></s>
<s sid="708"><CoreSc1 advantage="None" conceptID="Obs142" novelty="None" type="Obs"/><text>Almost no other change is seen in the cluster profile between the remaining three bc revisions 1.04, 1.05, and 1.06, where no significant restructuring took place.</text></s>
<s sid="709"><CoreSc1 advantage="None" conceptID="Obs143" novelty="None" type="Obs"/><text>Fig. 24 shows the SCGs for the four versions of acct considered in this study.</text></s>
<s sid="710"><CoreSc1 advantage="None" conceptID="Obs144" novelty="None" type="Obs"/><text>The slice profile and the cluster profile show very little change between acct-6.3 and acct-6.3.2.</text></s>
<s sid="711"><CoreSc1 advantage="None" conceptID="Res332" novelty="None" type="Res"/><text>Similarly, not much change is seen between acct-6.5 and acct-6.5.5.</text></s>
<s sid="712"><CoreSc1 advantage="None" conceptID="Res333" novelty="None" type="Res"/><text>However, the slice and the cluster profiles change significantly between major revisions, 6.3.X and 6.5.X.</text></s>
<s sid="713"><CoreSc1 advantage="None" conceptID="Res334" novelty="None" type="Res"/><text>The change log of release 6.5 notes &quot;Huge code-refactoring.&quot; The refactoring of the code is primarily in the way system log files are handled using utmp_rd.c, file_rd.c, dump-utmp.c and stored using hash tables whose operations are defined in hashtab.c and uid_hash.c.</text></s>
<s sid="714"><CoreSc1 advantage="None" conceptID="Obs145" novelty="None" type="Obs"/><text>Finally, Fig. 25 shows the SCGs for the 14 versions of indent.</text></s>
<s sid="715"><CoreSc1 advantage="None" conceptID="Res335" novelty="None" type="Res"/><text>These revisions include two major releases.</text></s>
<s sid="716"><CoreSc1 advantage="None" conceptID="Res336" novelty="None" type="Res"/><text>It is evident from the SCGs that the slice profile during the evolution hardly changes.</text></s>
<s sid="717"><CoreSc1 advantage="None" conceptID="Res337" novelty="None" type="Res"/><text>The cluster profile also remains similar through the evolution.</text></s>
<s sid="718"><CoreSc1 advantage="None" conceptID="Res338" novelty="None" type="Res"/><text>The system grows from 4466 to 6521 SLoC during its evolution which is supported by Fig. 22c showing the growth of the system SDG size.</text></s>
<s sid="719"><CoreSc1 advantage="None" conceptID="Res339" novelty="None" type="Res"/><text>Indent is a program for formatting C programs.</text></s>
<s sid="720"><CoreSc1 advantage="None" conceptID="Res340" novelty="None" type="Res"/><text>A study of the change logs for indent did not reveal any major refactoring or restructuring.</text></s>
<s sid="721"><CoreSc1 advantage="None" conceptID="Res341" novelty="None" type="Res"/><text>The changes to the system were mostly bug fixes and upgrades to support new command line options.</text></s>
<s sid="722"><CoreSc1 advantage="None" conceptID="Res342" novelty="None" type="Res"/><text>This results in almost negligible changes in the slice and cluster profiles despite the system evolution and growth.</text></s>
<s sid="723"><CoreSc1 advantage="None" conceptID="Con61" novelty="None" type="Con"/><text>As an answer to RQ7, this study finds that unless there is significant refactoring of the system, coherent cluster profiles remain stable during system evolution and thus captures the core architecture of the program in all three case studies.</text></s>
<s sid="724"><CoreSc1 advantage="None" conceptID="Con62" novelty="None" type="Con"/><text>Future work will replicate this longitudinal study on a large code corpus to ascertain whether this stability holds for other programs.</text></s>
Threats to validity
<s sid="725"><CoreSc1 advantage="None" conceptID="Con63" novelty="None" type="Con"/><text>This section presents threats to the validity of the results presented.</text></s>
<s sid="726"><CoreSc1 advantage="None" conceptID="Con64" novelty="None" type="Con"/><text>Threats to three types of validity (external, internal and construct) are considered.</text></s>
<s sid="727"><CoreSc1 advantage="None" conceptID="Res343" novelty="None" type="Res"/><text>The primary external threat arises from the possibility that the programs selected are not representative of programs in general (i.e., the findings of the experiments do not apply to 'typical' programs).</text></s>
<s sid="728"><CoreSc1 advantage="None" conceptID="Res344" novelty="None" type="Res"/><text>This is a reasonable concern that applies to any study of program properties.</text></s>
<s sid="729"><CoreSc1 advantage="None" conceptID="Obj43" novelty="None" type="Obj"/><text>To address this issue, a set of thirty open-source and industrial programs were analyzed in the quantitative study.</text></s>
<s sid="730"><CoreSc1 advantage="None" conceptID="Res345" novelty="None" type="Res"/><text>The programs were not selected based on any criteria or property and thus represent a random selection from various domains.</text></s>
<s sid="731"><CoreSc1 advantage="None" conceptID="Con65" novelty="None" type="Con"/><text>However, these were from the set of programs that were studied in previous work on dependence clusters to facilitate comparison with previous results.</text></s>
<s sid="732"><CoreSc1 advantage="None" conceptID="Con66" novelty="None" type="Con"/><text>In addition, all of the programs studied were C programs, so there is greater uncertainty that the results will hold for other programming paradigms such as object-oriented or aspect-oriented programming.</text></s>
<s sid="733"><CoreSc1 advantage="None" conceptID="Con67" novelty="None" type="Con"/><text>Internal validity is the degree to which conclusions can be drawn about the causal effect of the independent variables on the dependent variable.</text></s>
<s sid="734"><CoreSc1 advantage="None" conceptID="Res346" novelty="None" type="Res"/><text>The use of hash values to approximate slice content during clustering is a source of potential internal threat.</text></s>
<s sid="735"><CoreSc1 advantage="None" conceptID="Con68" novelty="None" type="Con"/><text>The approach assumes that hash values uniquely identify slice contents.</text></s>
<s sid="736"><CoreSc1 advantage="None" conceptID="Con69" novelty="None" type="Con"/><text>Hash functions are prone to hash collision which in our approach can cause clustering errors.</text></s>
<s sid="737"><CoreSc1 advantage="None" conceptID="Con70" novelty="None" type="Con"/><text>The hash function used is carefully crafted to minimize collision and its use is validated in Section 3.3.</text></s>
<s sid="738"><CoreSc1 advantage="None" conceptID="Con71" novelty="None" type="Con"/><text>Furthermore, the identification of logical structure in programs were done by the authors of the paper who are not involved in the development of any of the case study subjects.</text></s>
<s sid="739"><CoreSc1 advantage="None" conceptID="Con72" novelty="None" type="Con"/><text>This brings about the possibility that the identified structures do not represent actual logical constructs of the programs.</text></s>
<s sid="740"><CoreSc1 advantage="None" conceptID="Con73" novelty="None" type="Con"/><text>As the case studies are Unix utilities, their design specification are not available for evaluation.</text></s>
<s sid="741"><CoreSc1 advantage="None" conceptID="Con74" novelty="None" type="Con"/><text>Future work will entail consultation with the development team of the systems to further validate the results.</text></s>
<s sid="742"><CoreSc1 advantage="None" conceptID="Con75" novelty="None" type="Con"/><text>Construct validity refers to the validity that observations or measurement tools actually represent or measure the construct being investigated.</text></s>
<s sid="743"><CoreSc1 advantage="None" conceptID="Con76" novelty="None" type="Con"/><text>In this paper, one possible threat to construct arises from the potential for faults in the slicer.</text></s>
<s sid="744"><CoreSc1 advantage="None" conceptID="Con77" novelty="None" type="Con"/><text>A mature and widely used slicing tool (CodeSurfer) is used to mitigate this concern.</text></s>
<s sid="745"><CoreSc1 advantage="None" conceptID="Con78" novelty="None" type="Con"/><text>Another possible concern surrounds the precision of the pointer analysis used.</text></s>
<s sid="746"><CoreSc1 advantage="None" conceptID="Con79" novelty="None" type="Con"/><text>An overly conservative, and therefore imprecise, analysis would tend to increase the levels of dependence and potentially also increase the size of clusters.</text></s>
<s sid="747"><CoreSc1 advantage="None" conceptID="Con80" novelty="None" type="Con"/><text>There is no automatic way to tell whether a cluster arises because of imprecision in the computation of dependence or whether it is 'real'.</text></s>
<s sid="748"><CoreSc1 advantage="None" conceptID="Con81" novelty="None" type="Con"/><text>Section 3.2 discusses the various pointer analysis settings and validates its precision.</text></s>
<s sid="749"><CoreSc1 advantage="None" conceptID="Con82" novelty="None" type="Con"/><text>CodeSurfer's most precise pointer analysis option was used for the study.</text></s>
Related work
<s sid="750"><CoreSc1 advantage="None" conceptID="Con83" novelty="None" type="Con"/><text>In testing, dependence analysis has been shown to be effective at reducing the computational effort required to automate the test-data generation process (Ali et al., 2010).</text></s>
<s sid="751"><CoreSc1 advantage="None" conceptID="Con84" novelty="None" type="Con"/><text>In software maintenance, dependence analysis is used to protect a software maintainer against the potentially unforeseen side effects of a maintenance change.</text></s>
<s sid="752"><CoreSc1 advantage="None" conceptID="Con85" novelty="None" type="Con"/><text>This can be achieved by measuring the impact of the proposed change (Black, 2001) or by attempting to identify portions of code for which a change can be safely performed free from side effects (Gallagher and Lyle, 1991; Tonella, 2003).</text></s>
<s sid="753"><CoreSc1 advantage="None" conceptID="Con86" novelty="None" type="Con"/><text>A recently proposed impact analysis framework (Acharya and Robinson, 2011) reports that impact sets are often part of large dependence clusters when using time consuming but high precision slicing.</text></s>
<s sid="754"><CoreSc1 advantage="None" conceptID="Con87" novelty="None" type="Con"/><text>When low precision slicing is used, the study reports smaller dependence clusters.</text></s>
<s sid="755"><CoreSc1 advantage="None" conceptID="Con88" novelty="None" type="Con"/><text>This paper uses the most precise static slicing available.</text></s>
<s sid="756"><CoreSc1 advantage="None" conceptID="Con89" novelty="None" type="Con"/><text>There has also been recent work on finding dependence communities in software (Hamilton and Danicic, 2012) where social network community structure detection algorithms are applied to slice-inclusion graphs to identify communities.</text></s>
<s sid="757"><CoreSc1 advantage="None" conceptID="Bac57" novelty="None" type="Bac"/><text>Dependence clusters have previously been linked to software faults (Black et al., 2006) and have been identified as a potentially harmful 'dependence anti-pattern' (Binkley et al., 2008).</text></s>
<s sid="758"><CoreSc1 advantage="None" conceptID="Bac58" novelty="None" type="Bac"/><text>The presence of large dependence cluster was thought to reduce the effectiveness of testing and maintenance support techniques.</text></s>
<s sid="759"><CoreSc1 advantage="None" conceptID="Goa24" novelty="None" type="Goa"/><text>Having considered dependence clusters harmful, previous work on dependence clusters focuses on locating dependence clusters, understanding their cause, and removing them.</text></s>
<s sid="760"><CoreSc1 advantage="None" conceptID="Goa25" novelty="None" type="Goa"/><text>The first of these studies (Binkley and Harman, 2005; Harman et al., 2009) were based on efficient technique for locating dependence clusters and identifying dependence pollution (avoidable dependence clusters).</text></s>
<s sid="761"><CoreSc1 advantage="None" conceptID="Con90" novelty="None" type="Con"/><text>One common cause of large dependence clusters is the use of global variables.</text></s>
<s sid="762"><CoreSc1 advantage="None" conceptID="Bac59" novelty="None" type="Bac"/><text>A study of 21 programs found that 50% of the programs had a global variable that was responsible for holding together large dependence clusters (Binkley et al., 2009).</text></s>
<s sid="763"><CoreSc1 advantage="None" conceptID="Bac60" novelty="None" type="Bac"/><text>Other work on dependence clusters in software engineering has considered clusters at both low-level (Binkley and Harman, 2005; Harman et al., 2009) (SDG based) and high-level (Eisenbarth et al., 2003; Mitchell and Mancoridis, 2006) (models and functions) abstractions.</text></s>
<s sid="764"><CoreSc1 advantage="None" conceptID="Bac61" novelty="None" type="Bac"/><text>This paper extends our previous work which introduced coherent dependence clusters (Islam et al., 2010b) and decluvi (Islam et al., 2010a).</text></s>
<s sid="765"><CoreSc1 advantage="None" conceptID="Con91" novelty="None" type="Con"/><text>Previous work established the existence of coherent dependence clusters and detailed the functionalities of the visualization tool.</text></s>
<s sid="766"><CoreSc1 advantage="None" conceptID="Con92" novelty="None" type="Con"/><text>This paper extends previous work in many ways, firstly by introducing an efficient hashing algorithm for slice approximation.</text></s>
<s sid="767"><CoreSc1 advantage="None" conceptID="Con93" novelty="None" type="Con"/><text>This improves on the precision of previous slice approximation from 78% to 95%, resulting in precise and accurate clustering.</text></s>
<s sid="768"><CoreSc1 advantage="None" conceptID="Con94" novelty="None" type="Con"/><text>The coherent cluster existence study is extended to empirically validate the results by considering 30 production programs.</text></s>
<s sid="769"><CoreSc1 advantage="None" conceptID="Con95" novelty="None" type="Con"/><text>Additional case studies show that coherent clusters can help reveal the structure of a program and identify structural defects.</text></s>
<s sid="770"><CoreSc1 advantage="None" conceptID="Con96" novelty="None" type="Con"/><text>We also introduce the notion of inter-cluster dependence which will form the base of reverse engineering efforts in future.</text></s>
<s sid="771"><CoreSc1 advantage="None" conceptID="Res347" novelty="None" type="Res"/><text>Finally, we also present studies which show the lack of correlation between coherent clusters and bug fixes and show that coherent clusters remain surprisingly stable during system evolution.</text></s>
<s sid="772"><CoreSc1 advantage="None" conceptID="Con97" novelty="None" type="Con"/><text>In some ways our work follows the evolutionary development of the study of software clones (Bellon et al., 2007), which were thought to be harmful and problematic when first observed.</text></s>
<s sid="773"><CoreSc1 advantage="None" conceptID="Con98" novelty="None" type="Con"/><text>Further reflection and analysis revealed that these code clone structures were a widespread phenomena that deserved study and consideration.</text></s>
<s sid="774"><CoreSc1 advantage="None" conceptID="Con99" novelty="None" type="Con"/><text>While engineers needed to be aware of them, it remains a subject of much debate as to whether or not they should be refactored, tolerated or even nurtured (Bouktif et al., 2006; Kapser and Godfrey, 2008).</text></s>
<s sid="775"><CoreSc1 advantage="None" conceptID="Con100" novelty="None" type="Con"/><text>We believe the same kind of discussion may apply to dependence clusters.</text></s>
<s sid="776"><CoreSc1 advantage="None" conceptID="Con101" novelty="None" type="Con"/><text>While dependence clusters may have significant impact on comprehension and maintenance and though there is evidence that these clusters are a widespread phenomena, it is not always obvious whether they can be or should be removed or refactored.</text></s>
<s sid="777"><CoreSc1 advantage="None" conceptID="Con102" novelty="None" type="Con"/><text>There may be a (good) reason for the presence of a cluster and/or it may not be obvious how it can be removed (though its presence should surely be brought to the attention of the software maintainer).</text></s>
<s sid="778"><CoreSc1 advantage="None" conceptID="Con103" novelty="None" type="Con"/><text>These observations motivate further study to investigate and understand dependence clusters, and to provide tools to support software engineers in their analysis.</text></s>
<s sid="779"><CoreSc1 advantage="None" conceptID="Con104" novelty="None" type="Con"/><text>In support of future research, we make available all data from our study at the website http://www.cs.ucl.ac.uk/staff/s.islam/decluvi.html.</text></s>
<s sid="780"><CoreSc1 advantage="None" conceptID="Con105" novelty="None" type="Con"/><text>The reader can obtain the slices for each program studied and the clusters they form, facilitating replication of our results and other studies of dependence and dependence clusters.</text></s>
<s sid="781"><CoreSc1 advantage="None" conceptID="Con106" novelty="None" type="Con"/><text>The visualizations used in this paper are similar to those used for program comprehension.</text></s>
<s sid="782"><CoreSc1 advantage="None" conceptID="Con107" novelty="None" type="Con"/><text>Seesoft (Eick et al., 1992) is a seminal tool for line oriented visualization of software statistics.</text></s>
<s sid="783"><CoreSc1 advantage="None" conceptID="Con108" novelty="None" type="Con"/><text>The system pioneered four key ideas: reduced representation, coloring by statistic, direct manipulation, and capability to read actual code.</text></s>
<s sid="784"><CoreSc1 advantage="None" conceptID="Obs146" novelty="None" type="Obs"/><text>The reduced representation was achieved by displaying files in columns with lines of code as lines of pixels.</text></s>
<s sid="785"><CoreSc1 advantage="None" conceptID="Res348" novelty="None" type="Res"/><text>This approach allows 50,000 lines of code to be shown on a single screen.</text></s>
<s sid="786"><CoreSc1 advantage="None" conceptID="Res349" novelty="None" type="Res"/><text>The SeeSys System (Baker and Eick, 1995) introduced tree maps to show hierarchical data.</text></s>
<s sid="787"><CoreSc1 advantage="None" conceptID="Res350" novelty="None" type="Res"/><text>It displays code organized hierarchically into subsystems, directories, and files by representing the whole system as a rectangle and recursively representing the various sub-units with interior rectangles.</text></s>
<s sid="788"><CoreSc1 advantage="None" conceptID="Res351" novelty="None" type="Res"/><text>The area of each rectangle is used to reflect statistic associated with the sub-unit.</text></s>
<s sid="789"><CoreSc1 advantage="None" conceptID="Con109" novelty="None" type="Con"/><text>Decluvi builds on the SeeSoft concepts through different abstractions and dynamic mapping of line statistics removing the 50,000 line limitation.</text></s>
<s sid="790"><CoreSc1 advantage="None" conceptID="Con110" novelty="None" type="Con"/><text>An alternative software visualization approach often used in program comprehension does not use the &quot;line of pixels&quot; approach, but instead uses nested graphs for hierarchical fish-eye views.</text></s>
<s sid="791"><CoreSc1 advantage="None" conceptID="Con111" novelty="None" type="Con"/><text>Most of these tools focus on visualizing high-level system abstractions (often referred to as 'clustering' or 'aggregation') such as classes, modules, and packages.</text></s>
<s sid="792"><CoreSc1 advantage="None" conceptID="Con112" novelty="None" type="Con"/><text>A popular example is the reverse engineering tool Rigi (Storey et al., 1997).</text></s>
Summary and future work
<s sid="793"><CoreSc1 advantage="None" conceptID="Con113" novelty="None" type="Con"/><text>Previous work has deemed dependence clusters to be problematic as they inhibit program understanding and maintenance.</text></s>
<s sid="794"><CoreSc1 advantage="None" conceptID="Con114" novelty="None" type="Con"/><text>This paper views them in a new light, it introduces and evaluates a specialized form of dependence cluster: the coherent cluster.</text></s>
<s sid="795"><CoreSc1 advantage="None" conceptID="Con115" novelty="None" type="Con"/><text>Such clusters have vertices that share the same internal and external dependencies.</text></s>
<s sid="796"><CoreSc1 advantage="None" conceptID="Con116" novelty="None" type="Con"/><text>The paper shows that such clusters are not necessarily problems but rather can aid an engineer understand program components and their interactions.</text></s>
<s sid="797"><CoreSc1 advantage="None" conceptID="Con117" novelty="None" type="Con"/><text>Developers can exploit knowledge of coherent clusters as they aid in program comprehension as the clusters bring out interactions between logical constructs of the system.</text></s>
<s sid="798"><CoreSc1 advantage="None" conceptID="Con118" novelty="None" type="Con"/><text>We also lay a foundation for research into this new application area and encourage further research.</text></s>
<s sid="799"><CoreSc1 advantage="None" conceptID="Con119" novelty="None" type="Con"/><text>Moreover, future research could compare the aspects of various definitions of dependence clusters and the properties they capture.</text></s>
<s sid="800"><CoreSc1 advantage="None" conceptID="Con120" novelty="None" type="Con"/><text>This paper presents new approximations that support the efficient and accurate identification of coherent clusters.</text></s>
<s sid="801"><CoreSc1 advantage="None" conceptID="Con121" novelty="None" type="Con"/><text>Empirical evaluation finds that 23 of the 30 subject programs have at least one large coherent cluster.</text></s>
<s sid="802"><CoreSc1 advantage="None" conceptID="Con122" novelty="None" type="Con"/><text>A series of four case studies illustrate that coherent clusters map to a logical functional decomposition and can be used to depict the structure of a program.</text></s>
<s sid="803"><CoreSc1 advantage="None" conceptID="Con123" novelty="None" type="Con"/><text>In all four case studies, coherent clusters map to subsystems, each of which is responsible for implementing concise functionality.</text></s>
<s sid="804"><CoreSc1 advantage="None" conceptID="Con124" novelty="None" type="Con"/><text>As side-effects of the study, we find that the visualization of coherent clusters can identify potential structural problems as well as refactoring opportunities.</text></s>
<s sid="805"><CoreSc1 advantage="None" conceptID="Con125" novelty="None" type="Con"/><text>The paper also discusses inter-cluster dependence and how mutual dependencies between clusters may be exploited to reveal large dependence structure that form the basis of reverse engineering efforts.</text></s>
<s sid="806"><CoreSc1 advantage="None" conceptID="Con126" novelty="None" type="Con"/><text>Furthermore, the paper presents a study on how bug fixes relate to the presence of coherent clusters, and finds no relationship between program faults and coherent clusters in barcode.</text></s>
<s sid="807"><CoreSc1 advantage="None" conceptID="Con127" novelty="None" type="Con"/><text>Finally, a longitudinal study of three subjects shows that coherent clusters remain surprisingly stable through system evolution.</text></s>
<s sid="808"><CoreSc1 advantage="None" conceptID="Con128" novelty="None" type="Con"/><text>The paper is one of the first in the area of dependence clusters to suggest that dependence clusters (coherent clusters) are not problematic but represent program structure and give evidence to that cause.</text></s>
<s sid="809"><CoreSc1 advantage="None" conceptID="Con129" novelty="None" type="Con"/><text>Future work in this area is rife with opportunities beginning with enabling the use of coherent clusters in a program comprehension and reverse engineering tools.</text></s>
<s sid="810"><CoreSc1 advantage="None" conceptID="Con130" novelty="None" type="Con"/><text>The inter-cluster dependence study lays out the ground work in this context.</text></s>
<s sid="811"><CoreSc1 advantage="None" conceptID="Con131" novelty="None" type="Con"/><text>There is also room for further research aimed at understanding the formation and impact of coherent clusters on software quality.</text></s>
<s sid="812"><CoreSc1 advantage="None" conceptID="Con132" novelty="None" type="Con"/><text>For example, by studying how well dependence clusters can capture functionality.</text></s>
<s sid="813"><CoreSc1 advantage="None" conceptID="Con133" novelty="None" type="Con"/><text>Furthermore, application of dynamic slicing in formation of dependence clusters might by considered as static analysis can suffer from over approximation caused by its conservative nature.</text></s>
</BODY>
<OTHER>
Acknowledgements
This work is supported by EPSRC (EP/G060525/2, EP/F059442/2), EU (ICT-2009.1.2 no 257574), and NSF (CCF 0916081).
Data from the EPSRC-funded portions of this work may be available by contacting Dr. Krinke.
Please note that intellectual property or other restrictions may prevent the full disclosure of this data.

</OTHER>
</PAPER>