<?xml version="1.0" ?><PAPER><mode2 hasDoc="yes" name="S0950705113001895.tmf1" version="elsevier"/>
<TITLE>Incremental approaches for updating approximations in set-valued ordered information systems
</TITLE>
<ABSTRACT>

Abstract
<s sid="1"><CoreSc1 advantage="None" conceptID="Mot1" novelty="None" type="Mot"/><text>Incremental learning is an efficient technique for knowledge discovery in a dynamic database, which enables acquiring additional knowledge from new data without forgetting prior knowledge.</text></s>
<s sid="2"><CoreSc1 advantage="None" conceptID="Mot2" novelty="None" type="Mot"/><text>Rough set theory has been successfully used in information systems for classification analysis.</text></s>
<s sid="3"><CoreSc1 advantage="None" conceptID="Mot3" novelty="None" type="Mot"/><text>Set-valued information systems are generalized models of single-valued information systems, which can be classified into two categories: disjunctive and conjunctive.</text></s>
<s sid="4"><CoreSc1 advantage="None" conceptID="Mot4" novelty="None" type="Mot"/><text>Approximations are fundamental concepts of rough set theory, which need to be updated incrementally while the object set varies over time in the set-valued information systems.</text></s>
<s sid="5"><CoreSc1 advantage="None" conceptID="Obj1" novelty="None" type="Obj"/><text>In this paper, we analyze the updating mechanisms for computing approximations with the variation of the object set.</text></s>
<s sid="6"><CoreSc1 advantage="None" conceptID="Obj2" novelty="None" type="Obj"/><text>Two incremental algorithms for updating the approximations in disjunctive/conjunctive set-valued information systems are proposed, respectively.</text></s>
<s sid="7"><CoreSc1 advantage="None" conceptID="Goa1" novelty="None" type="Goa"/><text>Furthermore, extensive experiments are carried out on several data sets to verify the performance of the proposed algorithms.</text></s>
<s sid="8"><CoreSc1 advantage="None" conceptID="Con1" novelty="None" type="Con"/><text>The results indicate the incremental approaches significantly outperform non-incremental approaches with a dramatic reduction in the computational speed.</text></s>
</ABSTRACT>
<BODY>

Introduction
<s sid="9"><CoreSc1 advantage="None" conceptID="Con2" novelty="None" type="Con"/><text>Granular Computing (GrC), a new concept for information processing based on Zadeh's &quot;information granularity&quot;, is a term of theories, methodologies, techniques, and tools that makes use of granules in the process of problem solving [1,2].</text></s>
<s sid="10"><CoreSc1 advantage="None" conceptID="Bac1" novelty="None" type="Bac"/><text>With the development of artificial intelligence, the study on the theory of GrC has aroused the concern of more and more researchers [3-5].</text></s>
<s sid="11"><CoreSc1 advantage="None" conceptID="Mot5" novelty="None" type="Mot"/><text>Up to now, GrC has been successfully applied to many branches of artificial intelligence.</text></s>
<s sid="12"><CoreSc1 advantage="None" conceptID="Mot6" novelty="None" type="Mot"/><text>The basic notions and principles of GrC have appeared in many related fields, such as concept formation [6], data mining [7] and knowledge discovery [8,9].</text></s>
<s sid="13"><CoreSc1 advantage="None" conceptID="Mot7" novelty="None" type="Mot"/><text>Rough Set Theory (RST) is a powerful mathematical tool for dealing with inexact, uncertain or vague information [10].</text></s>
<s sid="14"><CoreSc1 advantage="None" conceptID="Bac2" novelty="None" type="Bac"/><text>It is also known as one of three primary models of GrC [11].</text></s>
<s sid="15"><CoreSc1 advantage="None" conceptID="Mot8" novelty="None" type="Mot"/><text>In recent years, there has been a rapid growth of interest in RST and its applications.</text></s>
<s sid="16"><CoreSc1 advantage="None" conceptID="Mot9" novelty="None" type="Mot"/><text>It seems to be of fundamental importance to artificial intelligence and cognitive sciences, especially in the areas of machine learning, decision analysis, expert systems, inductive reasoning and pattern recognition [13-16].</text></s>
<s sid="17"><CoreSc1 advantage="None" conceptID="Met1" novelty="None" type="Met"/><text>The data acquired for rough set analysis is represented in form of attribute-value tables, consisting of objects (rows) and attributes (columns), called information systems [17].</text></s>
<s sid="18"><CoreSc1 advantage="None" conceptID="Met2" novelty="None" type="Met"/><text>In real-life applications, data in information systems is generated and collected dynamically, and the knowledge discovered by RST need to be updating accordingly [12].</text></s>
<s sid="19"><CoreSc1 advantage="None" conceptID="Met3" novelty="None" type="Met"/><text>The incremental technique is an effective method to update knowledge by dealing with the new added-in data set without re-implementing the original data mining algorithm [18,19].</text></s>
<s sid="20"><CoreSc1 advantage="None" conceptID="Met4" novelty="None" type="Met"/><text>Many studies have been done towards the topic of incremental learning techniques under RST.</text></s>
<s sid="21"><CoreSc1 advantage="None" conceptID="Met5" novelty="None" type="Met"/><text>Considering the problem of discretization of continuous attributes in the dynamic databases, Dey et al. developed a dynamic discreduction method based on RST and notions of Statistics, which merges the two tasks of discretization and reduction of attributes into a single seamless process, so as to reduce the computation time by using samples instead of the whole data to discretize the variables [20].</text></s>
<s sid="22"><CoreSc1 advantage="None" conceptID="Met6" novelty="None" type="Met"/><text>Considering the problem of dynamic attribute reduction, Hu et al. proposed an incremental positive region reduction algorithm based on elementary set, which can generate a new positive region reduction quickly when a new object is added into the decision information systems [28].</text></s>
<s sid="23"><CoreSc1 advantage="None" conceptID="Met7" novelty="None" type="Met"/><text>From the view of information theory, Wang et al. proposed an incremental attribute reduction algorithm based on three representative entropies by considering changes of data values, which can generate a feasible reduct in a much shorter time.</text></s>
<s sid="24"><CoreSc1 advantage="None" conceptID="Met8" novelty="None" type="Met"/><text>However, the algorithm is only applicable on the case of the variation of data one by one [21].</text></s>
<s sid="25"><CoreSc1 advantage="None" conceptID="Met9" novelty="None" type="Met"/><text>Furthermore, Wang et al. developed a dimension incremental strategy for attribute reduction based on information entropy for data sets with dynamically increasing attributes [22].</text></s>
<s sid="26"><CoreSc1 advantage="None" conceptID="Met10" novelty="None" type="Met"/><text>Since the core of a decision table is the start point to many existing algorithms of attribute reduction, Yang et al. introduced an incremental updating algorithm of the computation of a core based on the discernibility matrix, which only inserts a new row and column, or deletes one row and updates corresponding column when updating the discernibility matrix [29].</text></s>
<s sid="27"><CoreSc1 advantage="None" conceptID="Met11" novelty="None" type="Met"/><text>Considering the problem of dynamic rule induction, Fan et al. proposed an incremental rule-extraction algorithm (REA) based on RST, which updates rule sets by partly modifying original rule sets without re-computing rule sets from the very beginning and the proposal approach is especially useful in a large database, since it does not re-compute the reducts/rules that are not influenced by the incremental data set [23].</text></s>
<s sid="28"><CoreSc1 advantage="None" conceptID="Bac3" novelty="None" type="Bac"/><text>Nevertheless, alternative rules which are as preferred as the original desired rules might exist since the maximum of strength index is not unique.</text></s>
<s sid="29"><CoreSc1 advantage="None" conceptID="Bac4" novelty="None" type="Bac"/><text>The REA may lead to non-complete rules, then an incremental alternative rule extraction algorithm (IAREA) was proposed to exclude the repetitive rules and to avoid the problem of redundant rules [24].</text></s>
<s sid="30"><CoreSc1 advantage="None" conceptID="Mot10" novelty="None" type="Mot"/><text>Zheng et al. developed a rough set and rule tree based incremental algorithm for knowledge acquisition, which is not only obviously quicker than that of classic algorithm, but also has a better performance of knowledge learned by the proposed algorithm to a certain degree [25].</text></s>
<s sid="31"><CoreSc1 advantage="None" conceptID="Mot11" novelty="None" type="Mot"/><text>Liu et al. defined a new concept of interesting knowledge based on both accuracy and coverage of the generated rules in the information system, and presented an optimization model using the incremental matrix for generating interesting knowledge when the object set varies over time [26,27].</text></s>
<s sid="32"><CoreSc1 advantage="None" conceptID="Goa2" novelty="None" type="Goa"/><text>The main goal of RST is to synthesize approximations of concepts from the acquired data, which is a necessary step for expressing and reducing incomplete and uncertain knowledge based on RST [30-32].</text></s>
<s sid="33"><CoreSc1 advantage="None" conceptID="Met12" novelty="None" type="Met"/><text>The knowledge hidden in information systems can be discovered and expressed in the form of decision rules according to the lower and upper approximations [36-39].</text></s>
<s sid="34"><CoreSc1 advantage="None" conceptID="Met13" novelty="None" type="Met"/><text>In order to resolve the problem of high computation complexity in computing approximations under the dynamic information systems, many incremental updating algorithms have been proposed.</text></s>
<s sid="35"><CoreSc1 advantage="None" conceptID="Met14" novelty="None" type="Met"/><text>Therefore, extensive efforts have been devoted to efficient algorithms for computing approximations.</text></s>
<s sid="36"><CoreSc1 advantage="None" conceptID="Met15" novelty="None" type="Met"/><text>Li et al. presented an incremental method for updating approximations in an incomplete information system through the characteristic relation when the attribute set varies over time, which can deal with the case of adding and removing some attributes simultaneously in the information system [40].</text></s>
<s sid="37"><CoreSc1 advantage="None" conceptID="Met16" novelty="None" type="Met"/><text>Since the domain of attributes may change in real-life applications, attributes values may be added to or deleted from the domain, Chen et al. proposed the incremental updating approach of approximations while attributes values coarsening or refining in the complete and incomplete information systems [35].</text></s>
<s sid="38"><CoreSc1 advantage="None" conceptID="Met17" novelty="None" type="Met"/><text>Zhang et al. discussed the change of approximations in neighborhood decision systems when the object set evolves over time, and proposed two fast incremental algorithms for updating approximations when multiple objects enter into or get out of the neighborhood decision table [33].</text></s>
<s sid="39"><CoreSc1 advantage="None" conceptID="Met18" novelty="None" type="Met"/><text>Li et al. firstly introduced a kind of dominance matrix to calculate P-dominating sets and P-dominated sets in dominance-based rough sets approach, and proposed the incremental algorithms for updating approximations of an upward union and downward union of decision classes [34].</text></s>
<s sid="40"><CoreSc1 advantage="None" conceptID="Obj3" novelty="None" type="Obj"/><text>Instead of considering the incremental updating strategies of rough sets, Cheng proposed two incremental methods for fast computing the rough fuzzy approximations, which are established respectively based on the redefined boundary set and the relation between a fuzzy set and its cut sets [41].</text></s>
<s sid="41"><CoreSc1 advantage="None" conceptID="Mot12" novelty="None" type="Mot"/><text>However, to our best knowledge, previous studies on incremental computing approximations mainly concerned in the single-valued information systems, but little attention has been paid to the set-valued information systems.</text></s>
<s sid="42"><CoreSc1 advantage="None" conceptID="Mot13" novelty="None" type="Mot"/><text>Set-valued information systems are an important type of data tables, and generalized models of single-valued information systems [42].</text></s>
<s sid="43"><CoreSc1 advantage="None" conceptID="Mot14" novelty="None" type="Mot"/><text>In many practical decision-making issues, set-valued information systems have very wide applications, which can be used in intelligent decision-making and knowledge discovery from information systems with uncertain information and set-valued information.</text></s>
<s sid="44"><CoreSc1 advantage="None" conceptID="Bac5" novelty="None" type="Bac"/><text>In such systems, some of the attribute values of an object may be set-valued, which are always used to characterize the incomplete information, i.e., the values of some attributes are unknown or multi-values.</text></s>
<s sid="45"><CoreSc1 advantage="None" conceptID="Bac6" novelty="None" type="Bac"/><text>On the other hand, we often encounter the scenario where the ordering of properties of the considering attributes plays a crucial role in the analysis of information systems.</text></s>
<s sid="46"><CoreSc1 advantage="None" conceptID="Mot15" novelty="None" type="Mot"/><text>Considering attributes with preference-ordered domains is an important characteristic of multi-attribute decision making problems in practice.</text></s>
<s sid="47"><CoreSc1 advantage="None" conceptID="Bac7" novelty="None" type="Bac"/><text>Greco et al. proposed the Dominance-based Rough Sets Approach (DRSA) [44,45].</text></s>
<s sid="48"><CoreSc1 advantage="None" conceptID="Bac8" novelty="None" type="Bac"/><text>This innovation is mainly based on the substitution of the indiscernibility relation by a dominance relation.</text></s>
<s sid="49"><CoreSc1 advantage="None" conceptID="Bac9" novelty="None" type="Bac"/><text>Furthermore, Qian et al. established a rough set approach in Set-valued Ordered Information Systems (SOIS) to take into account the ordering properties of attributes in set-valued information systems, and classified the SOIS into two categories: disjunctive and conjunctive systems [43].</text></s>
<s sid="50"><CoreSc1 advantage="None" conceptID="Bac10" novelty="None" type="Bac"/><text>Since the characteristics of the set-valued information systems is different from that of single-valued information systems (such as: some of the attribute values for an object are set-valued), the method for knowledge acquisition in the single-valued information systems cannot be applied directly to the set-valued ones.</text></s>
<s sid="51"><CoreSc1 advantage="None" conceptID="Obj4" novelty="None" type="Obj"/><text>For this reason, the incremental method for updating approximations in the dynamic set-valued information systems is discussed in this paper.</text></s>
<s sid="52"><CoreSc1 advantage="None" conceptID="Obj5" novelty="None" type="Obj"/><text>In [46], Zhang et al. proposed an incremental method for computing approximations in set-valued information systems under the tolerance relation, when the attribute set varies with time.</text></s>
<s sid="53"><CoreSc1 advantage="None" conceptID="Obj6" novelty="None" type="Obj"/><text>In this paper, we focus on updating knowledge under the variation of the object set in SOIS.</text></s>
<s sid="54"><CoreSc1 advantage="None" conceptID="Obj7" novelty="None" type="Obj"/><text>Firstly, we discuss the principles of incremental updating approximations when the objects in the universe change (increase or decrease) dynamically in the conjunctive/disjunctive SOIS.</text></s>
<s sid="55"><CoreSc1 advantage="None" conceptID="Obj8" novelty="None" type="Obj"/><text>Then two incremental updating algorithms are proposed based on the principles.</text></s>
<s sid="56"><CoreSc1 advantage="None" conceptID="Obj9" novelty="None" type="Obj"/><text>Finally, the performances of two incremental algorithms are evaluated on a variety of data sets.</text></s>
<s sid="57"><CoreSc1 advantage="None" conceptID="Bac11" novelty="None" type="Bac"/><text>The remainder of the paper is organized as follows.</text></s>
<s sid="58"><CoreSc1 advantage="None" conceptID="Bac12" novelty="None" type="Bac"/><text>In Section 2, some basic concepts of RST in SOIS are introduced.</text></s>
<s sid="59"><CoreSc1 advantage="None" conceptID="Res1" novelty="None" type="Res"/><text>The principles and some illustrated examples for incremental updating approximations with the variation of the object set are presented in Section 3.</text></s>
<s sid="60"><CoreSc1 advantage="None" conceptID="Res2" novelty="None" type="Res"/><text>In Section 4, we propose the incremental algorithms for computing approximations based on the updating principles.</text></s>
<s sid="61"><CoreSc1 advantage="None" conceptID="Res3" novelty="None" type="Res"/><text>Performance evaluations are illustrated in Section 5.</text></s>
<s sid="62"><CoreSc1 advantage="None" conceptID="Res4" novelty="None" type="Res"/><text>The paper ends with conclusions and further research topics in Section 6.</text></s>
Preliminaries
<s sid="63"><CoreSc1 advantage="None" conceptID="Obj10" novelty="None" type="Obj"/><text>For convenience, some basic concepts of rough sets and SOIS are reviewed in this section [42,43].</text></s>
<s sid="64"><CoreSc1 advantage="None" conceptID="Mod1" novelty="None" type="Mod"/><text>A set-valued information system is an ordered quadruple S=(U,C∪{d},V,f), where U={x1,x2,…,xn} is a non-empty finite set of objects, called the universe.</text></s>
<s sid="65"><CoreSc1 advantage="None" conceptID="Res5" novelty="None" type="Res"/><text>C is a non-empty finite set of condition attributes and d is a decision attribute with C∩{d}=∅; V=VC∪Vd, where V is the domain of all attributes, VC is the domain of all condition attributes and Vd is the domain of the decision attribute; f is a mapping from U×(C∪{d}) to V such that f:U×{C}→2Vc is a set-valued mapping and f: U×{d}→Vd is a single-valued mapping.</text></s>
<s sid="66"><CoreSc1 advantage="None" conceptID="Con3" novelty="None" type="Con"/><text>In an information system, if the domain (scale) of a condition attribute is ordered according to a decreasing or increasing preference, then the attribute is a criterion.Definition 1</text></s>
<s sid="67"><CoreSc1 advantage="None" conceptID="Bac13" novelty="None" type="Bac"/><text>A set-valued information system S=(U,C∪{d},V,f) is called a SOIS if all condition attributes are criterions.</text></s>
<s sid="68"><CoreSc1 advantage="None" conceptID="Bac14" novelty="None" type="Bac"/><text>In real problems, many ways to present the semantic interpretations of set-valued information systems have been provided [47-50].</text></s>
<s sid="69"><CoreSc1 advantage="None" conceptID="Bac15" novelty="None" type="Bac"/><text>Qian et al. summarized two types of set-valued information systems with two kinds of semantics, which are known as conjunctive (∀x∈U and c∈C, f(x,c) is interpreted conjunctively) and disjunctive (∀x∈U and c∈C, f(x,c) is interpreted disjunctively) set-valued information systems.</text></s>
<s sid="70"><CoreSc1 advantage="None" conceptID="Mod2" novelty="None" type="Mod"/><text>According to the introduction of the following two dominance relations to these types of set-valued information systems, SOIS can be also classified into two categories: conjunctive and disjunctive SOIS [43].</text></s>
<s sid="71"><CoreSc1 advantage="None" conceptID="Mod3" novelty="None" type="Mod"/><text>Assume the domain of a criterion a∈C is completely pre-ordered by an outranking relation ⪰a; x⪰ay means &quot;x is at least as good as (outranks) y with respect to criterion a&quot;.</text></s>
<s sid="72"><CoreSc1 advantage="None" conceptID="Mod4" novelty="None" type="Mod"/><text>For a subset of attributes A⊆C, we define x⪰Ay⇔∀a∈A,x⪰ay, which means &quot;x is at least as good as (outranks) y with respect to all attributes in A&quot;.Definition 2</text></s>
<s sid="73"><CoreSc1 advantage="None" conceptID="Mod5" novelty="None" type="Mod"/><text>Let S=(U,C∪{d},V,f) be a conjunctive SOIS and A⊆C.</text></s>
<s sid="74"><CoreSc1 advantage="None" conceptID="Mod6" novelty="None" type="Mod"/><text>The dominance relation in terms of A is defined as:(1)RA∧⩾={(y,x)∈U×U|y⪰Ax}={(y,x)∈U×U|f(y,a)⊇f(x,a),∀a∈A}</text></s>
Example 1
<s sid="75"><CoreSc1 advantage="None" conceptID="Mod7" novelty="None" type="Mod"/><text>Table 1 illustrates a conjunctive SOIS, where U={x1,x2,x3,x4,x5,x6}, C={a1,a2,a3,a4}, d is the decision attribute, VC={e,f,g} and Vd={1,2,4}.</text></s>
<s sid="76"><CoreSc1 advantage="None" conceptID="Mod8" novelty="None" type="Mod"/><text>Here, we can obtain that f(x1,a1)={e}, f(x2,a1)={e,f,g}.</text></s>
<s sid="77"><CoreSc1 advantage="None" conceptID="Mod9" novelty="None" type="Mod"/><text>Since {e,f,g}⊇{e}, we have x2⪰a1x1, that is, x2 is at least as good as x1 with respect to a1.</text></s>
Definition 3
<s sid="78"><CoreSc1 advantage="None" conceptID="Mod10" novelty="None" type="Mod"/><text>Let S=(U,C∪{d},V,f) be a disjunctive SOIS and A⊆C.</text></s>
<s sid="79"><CoreSc1 advantage="None" conceptID="Mod11" novelty="None" type="Mod"/><text>The dominance relation in terms of A is defined as:(2)RA∨⩾={(y,x)∈U×U|y⪰Ax}={(y,x)∈U×U|maxf(y,a)⩾minf(x,a),∀a∈A}</text></s>
Example 2
<s sid="80"><CoreSc1 advantage="None" conceptID="Mod12" novelty="None" type="Mod"/><text>Table 2 illustrates a disjunctive SOIS, where U={x1,x2,x3,x4,x5,x6},C={a1,a2,a3,a4}, D={d}, VC={0,1,2} and Vd={1,2,4}.</text></s>
<s sid="81"><CoreSc1 advantage="None" conceptID="Mod13" novelty="None" type="Mod"/><text>Here, we can obtain that f(x1,a1)={1}, f(x2,a1)={0,1}.</text></s>
<s sid="82"><CoreSc1 advantage="None" conceptID="Mod14" novelty="None" type="Mod"/><text>Since maxf(x1,a1)=1⩾minf(x2,a1)=0, we have x1⪰a1x2, that is, x1 is at least as good as x2 with respect to a1.</text></s>
<s sid="83"><CoreSc1 advantage="None" conceptID="Mod15" novelty="None" type="Mod"/><text>For convenience, we denote RAΔ⩾(Δ∈{∧,∨}) as the dominance relation in SOIS, where ∧ represents the conjunctive SOIS and ∨ represents the disjunctive SOIS.</text></s>
<s sid="84"><CoreSc1 advantage="None" conceptID="Mod16" novelty="None" type="Mod"/><text>Furthermore, we denote the granules of knowledge induced by the dominance relation RAΔ⩾(Δ∈{∧,∨}) as follows:•</text></s>
[x]AΔ⩾={y|(y,x)∈RAΔ⩾},(Δ=∧,∨)
•
[x]AΔ⩽={y|(x,y)∈RAΔ⩾},(Δ=∧,∨)
<s sid="85"><CoreSc1 advantage="None" conceptID="Mod17" novelty="None" type="Mod"/><text>where [x]AΔ⩾ is called the A-dominating set, describes the objects that dominate x in terms of A.</text></s>
<s sid="86"><CoreSc1 advantage="None" conceptID="Mod18" novelty="None" type="Mod"/><text>[x]AΔ⩽ is called the A-dominated set, describes the objects that are dominated by x in terms of A, respectively.</text></s>
<s sid="87"><CoreSc1 advantage="None" conceptID="Mod19" novelty="None" type="Mod"/><text>Let U/RA∧⩾ denote a classification on the universe, which is the family set {[x]AΔ⩾|x∈U}.</text></s>
<s sid="88"><CoreSc1 advantage="None" conceptID="Mod20" novelty="None" type="Mod"/><text>Any element from U/RA∧⩾ is called a dominance class with respect to A.</text></s>
<s sid="89"><CoreSc1 advantage="None" conceptID="Obs1" novelty="None" type="Obs"/><text>Dominance classes in U/RA∧⩾ do not constitute a partition of U in general.</text></s>
<s sid="90"><CoreSc1 advantage="None" conceptID="Res6" novelty="None" type="Res"/><text>They constitute a covering of U.Example 3</text></s>
<s sid="91"><CoreSc1 advantage="None" conceptID="Res7" novelty="None" type="Res"/><text>Continuation of Examples 1 and 2</text></s>
<s sid="92"><CoreSc1 advantage="None" conceptID="Obs2" novelty="None" type="Obs"/><text>From Table 1, U/RC∧⩾={[x1]C∧⩾,[x2]C∧⩾,…,[x6]C∧⩾}, where [x1]C∧⩾={x1,x2,x3},[x2]C∧⩾={x2},[x3]C∧⩾={x2,x3},[x4]C∧⩾={x2,x4},[x5]C∧⩾={x2,x5},[x6]C∧⩾={x6}.</text></s>
Analogously, U/RC∧⩽={[x1]C∧⩽,[x2]C∧⩽,…,[x6]C∧⩽}, where [x1]C∧⩽={x1},[x2]C∧⩽={x1,x2,x3,x4,x5},[x3]C∧⩽={x1,x3},[x4]C∧⩽={x4},[x5]C∧⩽={x5},[x6]C∧⩽={x6}.
<s sid="93"><CoreSc1 advantage="None" conceptID="Obs3" novelty="None" type="Obs"/><text>From Table 2, U/RC∨⩾={[x1]C∨⩾,[x2]C∨⩾,…,[x6]C∨⩾}, where [x1]C∨⩾={x1,x5},[x2]C∨⩾={x2,x3},[x3]C∨⩾={x2,x3,x4,x5,x6},[x4]C∨⩾={x4,x6},[x5]C∨⩾={x5},[x6]C∨⩾={x4,x6}.</text></s>
Analogously, U/RC∨⩽={[x1]C∨⩽,[x2]C∨⩽,…,[x6]C∨⩽}, where [x1]C∨⩽={x1,x6},[x2]C∨⩽={x2,x6},[x3]C∨⩽={x2,x3,x6},[x4]C∨⩽={x3,x4,x6},[x5]C∨⩽={x1,x3,x5},[x6]C∨⩽={x3,x4,x6}.
<s sid="94"><CoreSc1 advantage="None" conceptID="Res8" novelty="None" type="Res"/><text>Assume that the decision attribute d makes a partition of U into a finite number of classes.</text></s>
<s sid="95"><CoreSc1 advantage="None" conceptID="Hyp1" novelty="None" type="Hyp"/><text>Let D={D1,D2,…,Dr} be a set of these classes that are ordered, that is, ∀i, j⩽r, if i⩾j, then the objects from Di are preferred to the objects from Dj.</text></s>
<s sid="96"><CoreSc1 advantage="None" conceptID="Mod21" novelty="None" type="Mod"/><text>The sets to be approximated in DRSA are upward and downward unions of classes, which are defined respectively as Di⩾=⋃i⩽jDj,Di⩽=⋃j⩽iDj,1⩽i⩽j⩽r.</text></s>
<s sid="97"><CoreSc1 advantage="None" conceptID="Mod22" novelty="None" type="Mod"/><text>The statement x∈Di⩾ means &quot;x belongs to at least class Di&quot;, where x∈Di⩽ means &quot;x belongs to at most class Di&quot;.Definition 4</text></s>
<s sid="98"><CoreSc1 advantage="None" conceptID="Mod23" novelty="None" type="Mod"/><text>Let S=(U,C∪{d},V,f) be a SOIS.</text></s>
<s sid="99"><CoreSc1 advantage="None" conceptID="Mod24" novelty="None" type="Mod"/><text>A⊆C,∀Di⩾(1⩽i⩽r), the lower and upper approximations of Di⩾ with respect to the dominance relation RAΔ⩾(Δ∈{∧,∨}) are defined respectively as follows:(3)RAΔ⩾̲Di⩾=x∈U|[x]AΔ⩾⊆Di⩾,(4)RAΔ⩾¯Di⩾=⋃x∈Di⩾[x]AΔ⩾.Analogously, ∀Di⩽(1⩽i⩽r), the lower and upper approximations of Di⩽ are defined as:(5)RAΔ⩾̲Di⩽=x∈U|[x]AΔ⩽⊆Di⩽,(6)RAΔ⩾¯Di⩽=⋃x∈Di⩽[x]AΔ⩽.</text></s>
Example 4
Continuation of Example 3
(1)
<s sid="100"><CoreSc1 advantage="None" conceptID="Obs4" novelty="None" type="Obs"/><text>From Table 1, we have D={D1,D2,D3}, where D1={x3,x5},D2={x1,x4}, D3={x2,x6}.</text></s>
<s sid="101"><CoreSc1 advantage="None" conceptID="Res9" novelty="None" type="Res"/><text>Thus, we get the unions of classes as follows: D1⩽=D1,D2⩽=D1∪D2,D2⩾=D2∪D3,D3⩾=D3.</text></s>
<s sid="102"><CoreSc1 advantage="None" conceptID="Res10" novelty="None" type="Res"/><text>From Definition 4, we have: RCΔ⩾̲D1⩽={x5},RCΔ⩾¯D1⩽={x1,x3,x5},RCΔ⩾̲D2⩽={x1,x3,x4,x5},RCΔ⩾¯D2⩽={x1,x3,x4,x5},RCΔ⩾̲D2⩾={x2,x4,x6},RCΔ⩾¯D2⩾={x1,x2,x3,x4,x6},RCΔ⩾̲D3⩾={x2,x6},RCΔ⩾¯D3⩾={x2,x6}.</text></s>
(2)
<s sid="103"><CoreSc1 advantage="None" conceptID="Res11" novelty="None" type="Res"/><text>Analogously, from Table 2, we have D={D1,D2,D3}, where D1={x4},D2={x1,x3,x6}, D3={x2,x5}.</text></s>
<s sid="104"><CoreSc1 advantage="None" conceptID="Res12" novelty="None" type="Res"/><text>Thus, we get the unions of classes as follows: D1⩽=D1,D2⩽=D1∪D2,D2⩾=D2∪D3,D3⩾=D3.</text></s>
<s sid="105"><CoreSc1 advantage="None" conceptID="Res13" novelty="None" type="Res"/><text>From Definition 4, we have: RCΔ⩾̲D1⩽=∅,RCΔ⩾¯D1⩽={x3,x4,x6},RCΔ⩾̲D2⩽={x1,x4,x6},RCΔ⩾¯D2⩽={x1,x2,x3,x4,x6},RCΔ⩾̲D2⩾={x1,x2,x5},RCΔ⩾¯D2⩾={x1,x2,x3,x4,x5,x6},RCΔ⩾̲D3⩾=∅,RCΔ⩾¯D3⩾={x2,x3,x5}.</text></s>
<s sid="106"><CoreSc1 advantage="None" conceptID="Res14" novelty="None" type="Res"/><text>Incremental updating approximations in SOIS when the object set varies with time</text></s>
<s sid="107"><CoreSc1 advantage="None" conceptID="Con4" novelty="None" type="Con"/><text>With the variation of an information system, the structure of information granules in the information system may vary over time which leads to the change of knowledge induced by RST.</text></s>
<s sid="108"><CoreSc1 advantage="None" conceptID="Obj11" novelty="None" type="Obj"/><text>For example, let us consider a practical information system from the test for foreign language ability of undergraduates in Shanxi University, the test results can be expressed as a set-valued information system where the attributes are all inclusion increasing preferences and the value of each student under each attribute is given by an evaluation expert through a set-value [43].</text></s>
<s sid="109"><CoreSc1 advantage="None" conceptID="Mot16" novelty="None" type="Mot"/><text>However, during the process of evaluating the undergraduates language ability, data in an information system does not usually remain a stable condition.</text></s>
<s sid="110"><CoreSc1 advantage="None" conceptID="Hyp2" novelty="None" type="Hyp"/><text>Some objects may be inserted into the original information system due to the arrival of the new students.</text></s>
<s sid="111"><CoreSc1 advantage="None" conceptID="Hyp3" novelty="None" type="Hyp"/><text>On the other hand, some objects will be deleted from the original information system with the graduation of the senior students.</text></s>
<s sid="112"><CoreSc1 advantage="None" conceptID="Hyp4" novelty="None" type="Hyp"/><text>Then the discovered knowledge may become invalid, or some new implicit information may emerge in the whole updated information system.</text></s>
<s sid="113"><CoreSc1 advantage="None" conceptID="Met19" novelty="None" type="Met"/><text>Rather than restarting from scratch by the non-incremental or batch learning algorithm for each update, developing an efficient incremental algorithm to avoid unnecessary computations by utilizing the previous data structures or results is thus desired.</text></s>
<s sid="114"><CoreSc1 advantage="None" conceptID="Obj12" novelty="None" type="Obj"/><text>In this section, we discuss the variation of approximations in the dynamic SOIS when the object set evolves over time while the attribute set remains constant.</text></s>
<s sid="115"><CoreSc1 advantage="None" conceptID="Mod25" novelty="None" type="Mod"/><text>For convenience, we assume the incremental learning process lasts two periods from time t to time t+1.</text></s>
<s sid="116"><CoreSc1 advantage="None" conceptID="Mod26" novelty="None" type="Mod"/><text>We denote a dynamic SOIS at time t as S=(U,C∪{d},V,f), and at time t+1, with the insertion or deletion of objects, the original SOIS will change into a new one, denoted as S′=(U′,C′∪{d′},V′,f′).</text></s>
<s sid="117"><CoreSc1 advantage="None" conceptID="Mod27" novelty="None" type="Mod"/><text>Similarly, we denote the union of classes and the A-dominating set as Di⩾ and [x]AΔ⩾, respectively at time t, which are denoted as Di⩾′ and [x]AΔ⩾′, respectively at time t+1.</text></s>
<s sid="118"><CoreSc1 advantage="None" conceptID="Mod28" novelty="None" type="Mod"/><text>According to Definition 4, the lower and upper approximations of Di⩾ with respect to A⊆C are denoted as RAΔ⩾̲Di⩾ and RAΔ⩾¯Di⩾, respectively at time t, which are denoted as RAΔ⩾̲Di⩾′ and RAΔ⩾¯Di⩾′, respectively at time t+1, respectively.</text></s>
<s sid="119"><CoreSc1 advantage="None" conceptID="Res15" novelty="None" type="Res"/><text>Here, we only discuss the incremental approach for updating approximations in the cases that a single object enter and go out of the information system.</text></s>
<s sid="120"><CoreSc1 advantage="None" conceptID="Res16" novelty="None" type="Res"/><text>The change of multiple objects can be seen as the cumulative change of a single object.</text></s>
<s sid="121"><CoreSc1 advantage="None" conceptID="Res17" novelty="None" type="Res"/><text>The approximations can be updated step by step through the updating principles in the case that a single object varies.</text></s>
<s sid="122"><CoreSc1 advantage="None" conceptID="Res18" novelty="None" type="Res"/><text>Principles for incrementally updating approximations with the deletion of a single object</text></s>
<s sid="123"><CoreSc1 advantage="None" conceptID="Mod29" novelty="None" type="Mod"/><text>Given a SOIS S=(U,C∪{d},V,f) at time t, the deletion of object x¯∈U (x¯ denotes the deleted object) will change the original information granules [x]AΔ⩾ (x∈U,A⊆C) and the union of decision classes Di⩾ (1⩽i⩽r).</text></s>
<s sid="124"><CoreSc1 advantage="None" conceptID="Mod30" novelty="None" type="Mod"/><text>The approximations of Di⩾ will change accordingly.</text></s>
<s sid="125"><CoreSc1 advantage="None" conceptID="Mod31" novelty="None" type="Mod"/><text>Here, we discuss the principles for updating approximations of Di⩾ from two cases: (1) The deleted object belongs to Di⩾, i.e., x¯∈Di⩾; (2) The deleted object does not belong to Di⩾, i.e., x¯∉Di⩾.Case 1:</text></s>
<s sid="126"><CoreSc1 advantage="None" conceptID="Mod32" novelty="None" type="Mod"/><text>The deleted object x¯ belongs to Di, i.e., x¯∈Di⩾.</text></s>
Proposition 1
<s sid="127"><CoreSc1 advantage="None" conceptID="Mod33" novelty="None" type="Mod"/><text>Let S=(U,C∪{d},V,f) be a SOIS, A⊆C.</text></s>
<s sid="128"><CoreSc1 advantage="None" conceptID="Mod34" novelty="None" type="Mod"/><text>When x¯∈Di⩾ is deleted from U, for RAΔ⩾̲Di⩾′, we have:(1)</text></s>
If x¯∈RAΔ⩾̲Di⩾, then RAΔ⩾̲Di⩾′=RAΔ⩾̲Di⩾-{x¯};
(2)
Otherwise, RAΔ⩾̲Di⩾′=RAΔ⩾̲Di⩾.
Proof
<s sid="129"><CoreSc1 advantage="None" conceptID="Mod35" novelty="None" type="Mod"/><text>When x¯∈Di⩾ is deleted from U, we have U′=U-{x¯},Di⩾′=Di⩾-{x¯}.</text></s>
For x∈U′,[x]AΔ⩾′=[x]AΔ⩾-{x¯}.
<s sid="130"><CoreSc1 advantage="None" conceptID="Con5" novelty="None" type="Con"/><text>∀x∈U′, if [x]AΔ⩾⊆Di⩾, then [x]AΔ⩾′⊆Di⩾′; Analogously, if [x]AΔ⩾⊈Di⩾, then [x]AΔ⩾′⊈Di⩾′; Thus, from the definition of lower approximation in Definition 4, we have ∀x∈U′, if x∈RAΔ⩾̲Di⩾, then x∈RAΔ⩾̲Di⩾′; If x∉RAΔ⩾̲Di⩾, then x∉RAΔ⩾̲Di⩾′.</text></s>
<s sid="131"><CoreSc1 advantage="None" conceptID="Con6" novelty="None" type="Con"/><text>Hence, it is easy to get if x¯∈RAΔ⩾̲Di⩾, then RAΔ⩾̲Di⩾′=RAΔ⩾̲Di⩾-{x¯}; Otherwise, the lower approximation of Di⩾ will remain constant, i.e., RAΔ⩾̲Di⩾′=RAΔ⩾̲Di⩾.□</text></s>
Example 5
Continuation of Example 4
(1)
<s sid="132"><CoreSc1 advantage="None" conceptID="Res19" novelty="None" type="Res"/><text>For Table 1, according to Proposition 1, we compute the lower approximations of D2⩾ by deleting x1 and x2 from U, respectively.•</text></s>
<s sid="133"><CoreSc1 advantage="None" conceptID="Obs5" novelty="None" type="Obs"/><text>Assume the object x1 is deleted from Table 1, and U′=U-{x1}.</text></s>
<s sid="134"><CoreSc1 advantage="None" conceptID="Obs6" novelty="None" type="Obs"/><text>We have x1∈D2⩾ and x1∉RCΔ⩾̲D2⩾.</text></s>
Therefore, RAΔ⩾̲D2⩾′=RCΔ⩾̲D2⩾={x2,x4,x6}.
•
<s sid="135"><CoreSc1 advantage="None" conceptID="Obs7" novelty="None" type="Obs"/><text>Assume the object x2 is deleted from Table 1, and U′=U-{x2}.</text></s>
<s sid="136"><CoreSc1 advantage="None" conceptID="Obs8" novelty="None" type="Obs"/><text>We have x2∈D2⩾ and x2∈RCΔ⩾̲D2⩾.</text></s>
Therefore, RAΔ⩾̲D2⩾′=RCΔ⩾̲D2⩾-{x2}={x4,x6}.
(2)
<s sid="137"><CoreSc1 advantage="None" conceptID="Obs9" novelty="None" type="Obs"/><text>For Table 2, according to Proposition 1, we compute the lower approximations of D2⩾ by deleting x1 and x3 from U, respectively.•</text></s>
<s sid="138"><CoreSc1 advantage="None" conceptID="Obs10" novelty="None" type="Obs"/><text>Assume the object x1 is deleted from Table 2, and U′=U-{x1}.</text></s>
<s sid="139"><CoreSc1 advantage="None" conceptID="Obs11" novelty="None" type="Obs"/><text>We have x1∈D2⩾ and x1∈RCΔ⩾̲D2⩾.</text></s>
Therefore, RAΔ⩾̲D2⩾′=RCΔ⩾̲D2⩾-{x1}={x2,x5}.
•
<s sid="140"><CoreSc1 advantage="None" conceptID="Obs12" novelty="None" type="Obs"/><text>Assume the object x3 is deleted from Table 2, and U′=U-{x3}.</text></s>
<s sid="141"><CoreSc1 advantage="None" conceptID="Res20" novelty="None" type="Res"/><text>We have x3∈D2⩾ and x3∉RCΔ⩾̲D2⩾.</text></s>
Therefore, RAΔ⩾̲D2⩾′=RCΔ⩾̲D2⩾={x1,x2,x5}.
Proposition 2
<s sid="142"><CoreSc1 advantage="None" conceptID="Res21" novelty="None" type="Res"/><text>Let S=(U,C∪{d},V,f) be a SOIS, A⊆C.</text></s>
<s sid="143"><CoreSc1 advantage="None" conceptID="Mod36" novelty="None" type="Mod"/><text>When x¯∈Di⩾ is deleted from U, for RAΔ⩾¯Di⩾′, we haveRAΔ⩾¯Di⩾′=RAΔ⩾¯Di⩾-[x¯]AΔ⩾∪Kwhere K={x|x∈[x¯]AΔ⩾∩K′},K′=⋃x∈Di⩾-{x¯}[x]AΔ⩾.</text></s>
Proof
<s sid="144"><CoreSc1 advantage="None" conceptID="Mod37" novelty="None" type="Mod"/><text>According to Definition 4, we have RAΔ⩾¯Di⩾=⋃x∈Di⩾[x]AΔ⩾.</text></s>
<s sid="145"><CoreSc1 advantage="None" conceptID="Mod38" novelty="None" type="Mod"/><text>Thus, when the object x¯∈Di⩾ is deleted from U, the A-dominating set [x¯]AΔ⩾ should be removed from the upper approximation RAΔ⩾¯Di⩾, i.e., RAΔ⩾¯Di⩾′=RAΔ⩾¯Di⩾-[x¯]AΔ⩾.</text></s>
<s sid="146"><CoreSc1 advantage="None" conceptID="Mod39" novelty="None" type="Mod"/><text>However, ∃x∈Di⩾-{x¯} satisfies that K=[x¯]AΔ⩾∩[x]AΔ⩾≠∅, and the object x∈[y]AΔ⩾ (y∈Di⩾-{x¯}) should not be removed from RAΔ⩾¯Di⩾.</text></s>
<s sid="147"><CoreSc1 advantage="None" conceptID="Mod40" novelty="None" type="Mod"/><text>Therefore, we have RAΔ⩾¯Di⩾′=RAΔ⩾¯Di⩾-[x¯]AΔ⩾∪K, where K={x|x∈[x¯]AΔ⩾∩K′},K′=⋃x∈Di⩾-{x¯}[x]AΔ⩾.□</text></s>
Example 6
Continuation of Example 4
(1)
<s sid="148"><CoreSc1 advantage="None" conceptID="Obs13" novelty="None" type="Obs"/><text>For Table 1, according to Proposition 2, we compute the upper approximation of D2⩾ by deleting x1 from U.</text></s>
<s sid="149"><CoreSc1 advantage="None" conceptID="Obs14" novelty="None" type="Obs"/><text>Assume the object x1 is deleted from Table 1, and U′=U-{x1}.</text></s>
We have x1∈D2⩾,K′=⋃x∈D2⩾-{x1}[x]CΔ⩾={x2,x4,x6}.
Then K={x|x∈[x1]CΔ⩾∩K′}={x2},RCΔ⩾¯D2⩾′=RAΔ⩾¯Di⩾-[x¯]AΔ⩾∪K={x2,x4,x6}.
(2)
<s sid="150"><CoreSc1 advantage="None" conceptID="Obs15" novelty="None" type="Obs"/><text>For Table 2, according to Proposition 2, we compute the upper approximation of D2⩾ by deleting x1 from U.</text></s>
<s sid="151"><CoreSc1 advantage="None" conceptID="Obs16" novelty="None" type="Obs"/><text>Assume the object x1 is deleted from Table 2, and U′=U-{x1}.</text></s>
We have x1∈D2⩾,K′=⋃x∈D2⩾-{x1}[x]CΔ⩾={x2,x3,x4,x5,x6}.
Then K={x∣x∈[x1]CΔ⩾∩K′}={x5},RCΔ⩾¯D2⩾′=RAΔ⩾¯Di⩾-[x¯]AΔ⩾∪K={x2,x3,x4,x5,x6}.
Case 2:
<s sid="152"><CoreSc1 advantage="None" conceptID="Obs17" novelty="None" type="Obs"/><text>The deleted object x¯ does not belong to Di, i.e. x¯∉Di⩾.</text></s>
Proposition 3
<s sid="153"><CoreSc1 advantage="None" conceptID="Obs18" novelty="None" type="Obs"/><text>Let S=(U,C∪{d},V,f) be a SOIS, A⊆C.</text></s>
<s sid="154"><CoreSc1 advantage="None" conceptID="Obs19" novelty="None" type="Obs"/><text>When x¯∉Di⩾ is deleted from U, for RAΔ⩾̲Di⩾′, we haveRAΔ⩾̲Di⩾′=RAΔ⩾̲Di⩾∪Kwhere K=x|x∈Di⩾-RAΔ⩾̲Di⩾,Di⩾⊇[x]AΔ⩾′.</text></s>
<s sid="155"><CoreSc1 advantage="None" conceptID="Obs20" novelty="None" type="Obs"/><text>If x¯∈[x]AΔ⩾, then [x]AΔ⩾′=[x]AΔ⩾-{x¯}; Otherwise, [x]AΔ⩾′=[x]AΔ⩾.</text></s>
Proof
<s sid="156"><CoreSc1 advantage="None" conceptID="Res22" novelty="None" type="Res"/><text>According to Definition 4, we have ∀x∈Di⩾, if x∈RAΔ⩾̲Di⩾, then Di⩾⊇[x]AΔ⩾.</text></s>
<s sid="157"><CoreSc1 advantage="None" conceptID="Res23" novelty="None" type="Res"/><text>When the object x¯∉Di⩾ is deleted from U, we have U′=U-{x¯},Di⩾′=Di⩾, and ∀x∈U′,[x]AΔ⩾′=[x]AΔ⩾-{x¯}.</text></s>
<s sid="158"><CoreSc1 advantage="None" conceptID="Con7" novelty="None" type="Con"/><text>It is easy to get if Di⩾⊇[x]AΔ⩾, then Di⩾′⊇[x]AΔ⩾′; Thus, ∀x∈RAΔ⩾̲Di⩾,x∈RAΔ⩾̲Di⩾′.</text></s>
<s sid="159"><CoreSc1 advantage="None" conceptID="Con8" novelty="None" type="Con"/><text>On the other hand, ∀x∈Di⩾-RAΔ⩾̲Di⩾, we know that Di⩾⊉[x]AΔ⩾.</text></s>
<s sid="160"><CoreSc1 advantage="None" conceptID="Con9" novelty="None" type="Con"/><text>However, it may exist that x¯∈[x]AΔ⩾, and after the deletion of x¯,Di⩾⊇([x]AΔ⩾)′.</text></s>
<s sid="161"><CoreSc1 advantage="None" conceptID="Con10" novelty="None" type="Con"/><text>Then x should be added to RAΔ⩾̲Di⩾′, that is, RAΔ⩾̲Di⩾′=RAΔ⩾̲Di⩾∪{x}.</text></s>
<s sid="162"><CoreSc1 advantage="None" conceptID="Con11" novelty="None" type="Con"/><text>Therefore, we have RAΔ⩾̲Di⩾′=RAΔ⩾̲Di⩾∪K, where K=x|x∈Di⩾-RAΔ⩾̲Di⩾,Di⩾⊇[x]AΔ⩾′,[x]AΔ⩾′=[x]AΔ⩾-{x¯}.□</text></s>
Example 7
Continuation of Example 4
(1)
<s sid="163"><CoreSc1 advantage="None" conceptID="Res24" novelty="None" type="Res"/><text>For Table 1, according to Proposition 3, we compute the lower approximation of D2⩾ by deleting x3 from U.</text></s>
<s sid="164"><CoreSc1 advantage="None" conceptID="Obs21" novelty="None" type="Obs"/><text>Assume the object x3 is deleted from Table 1, and U′=U-{x3}.</text></s>
We have x3∉D2⩾,D2⩾-RCΔ⩾̲D2⩾={x1},D2⩾⊇[x1]CΔ⩾-{x3}={x1,x2}.
Therefore, K={x1} and RAΔ⩾̲Di⩾′=RAΔ⩾̲Di⩾∪K={x1,x2,x4,x6}.
(2)
<s sid="165"><CoreSc1 advantage="None" conceptID="Obs22" novelty="None" type="Obs"/><text>For Table 2, according to Proposition 3, we compute the upper approximation of D2⩾ by deleting x4 from U.</text></s>
<s sid="166"><CoreSc1 advantage="None" conceptID="Obs23" novelty="None" type="Obs"/><text>Assume the object x4 is deleted from Table 2, and U′=U-{x4}.</text></s>
<s sid="167"><CoreSc1 advantage="None" conceptID="Res25" novelty="None" type="Res"/><text>We have x4∉D2⩾,D2⩾-RCΔ⩾̲D2⩾={x3,x6},D2⩾⊇[x3]CΔ⩾-{x4}={x2,x3,x5,x6} and D2⩾⊇[x6]CΔ⩾-{x6}={x6}.</text></s>
Therefore, K={x3,x6} and RAΔ⩾̲Di⩾′=RAΔ⩾̲Di⩾∪K={x1,x2,x3,x5,x6}.
Proposition 4
<s sid="168"><CoreSc1 advantage="None" conceptID="Res26" novelty="None" type="Res"/><text>Let S=(U,C∪d,V,f) be a SOIS, A⊆C.</text></s>
<s sid="169"><CoreSc1 advantage="None" conceptID="Mod41" novelty="None" type="Mod"/><text>When the object x¯∉Di⩾ is deleted from U, for RAΔ⩾¯Di⩾′, we have:(1)</text></s>
If x¯∈RAΔ⩾¯Di⩾, then RAΔ⩾¯Di⩾′=RAΔ⩾¯Di⩾-{x¯};
(2)
Otherwise, RAΔ⩾¯Di⩾′=RAΔ⩾¯Di⩾.
Proof
<s sid="170"><CoreSc1 advantage="None" conceptID="Mod42" novelty="None" type="Mod"/><text>According to Definition 4, we have that RAΔ⩾¯Di⩾=⋃x∈Di⩾[x]AΔ⩾.</text></s>
<s sid="171"><CoreSc1 advantage="None" conceptID="Mod43" novelty="None" type="Mod"/><text>Since the deleted object x¯∉Di⩾, there exists an object x∈Di⩾ satisfies x¯∈[x]AΔ⩾ if x¯∈RAΔ⩾¯Di⩾.</text></s>
<s sid="172"><CoreSc1 advantage="None" conceptID="Mod44" novelty="None" type="Mod"/><text>Therefore, when x¯ is deleted, we have [x]AΔ⩾′=[x]AΔ⩾-{x¯}.</text></s>
Then RAΔ⩾¯Di⩾′=⋃x∈Di⩾[x]AΔ⩾′=RAΔ⩾¯Di⩾-{x¯}.
<s sid="173"><CoreSc1 advantage="None" conceptID="Mod45" novelty="None" type="Mod"/><text>On the other hand, if x¯∉RAΔ⩾¯Di⩾, we have ∀x∈Di⩾,x¯∉[x]AΔ⩾.</text></s>
<s sid="174"><CoreSc1 advantage="None" conceptID="Mod46" novelty="None" type="Mod"/><text>Hence, the upper approximation of Di⩾ will remain constant, i.e., RAΔ⩾¯Di⩾′=RAΔ⩾¯Di⩾.□</text></s>
Example 8
Continuation of Example 4
(1)
<s sid="175"><CoreSc1 advantage="None" conceptID="Res27" novelty="None" type="Res"/><text>For Table 1, according to Proposition 4, we compute the lower approximations of D2⩾ by deleting x3 and x5 from U, respectively.•</text></s>
<s sid="176"><CoreSc1 advantage="None" conceptID="Res28" novelty="None" type="Res"/><text>Assume the object x3 is deleted from Table 1, and U′=U-{x3}.</text></s>
<s sid="177"><CoreSc1 advantage="None" conceptID="Res29" novelty="None" type="Res"/><text>We have x3∉D2⩾ and x3∈RCΔ⩾¯D2⩾.</text></s>
Therefore, RAΔ⩾¯D2⩾′=RCΔ⩾¯D2⩾-{x3}={x1,x2,x4,x6}.
•
<s sid="178"><CoreSc1 advantage="None" conceptID="Res30" novelty="None" type="Res"/><text>Assume the object x5 is deleted from Table 1, and U′=U-{x5}.</text></s>
<s sid="179"><CoreSc1 advantage="None" conceptID="Res31" novelty="None" type="Res"/><text>We have x5∉D2⩾ and x5∉RCΔ⩾¯D2⩾.</text></s>
Therefore, RAΔ⩾¯D2⩾′=RCΔ⩾¯D2⩾={x1,x2,x3,x4,x6}.
(2)
<s sid="180"><CoreSc1 advantage="None" conceptID="Res32" novelty="None" type="Res"/><text>For Table 2, according to Proposition 4, we compute the upper approximation of D3⩾ by deleting x3 and x4 from U, respectively.•</text></s>
<s sid="181"><CoreSc1 advantage="None" conceptID="Res33" novelty="None" type="Res"/><text>Assume the object x3 is deleted from Table 2, and U′=U-{x3}.</text></s>
<s sid="182"><CoreSc1 advantage="None" conceptID="Res34" novelty="None" type="Res"/><text>We have x3∉D3⩾ and x3∈RCΔ⩾¯D3⩾.</text></s>
Therefore, RAΔ⩾¯D2⩾′=RCΔ⩾¯D3⩾-{x3}={x2,x5}.
•
<s sid="183"><CoreSc1 advantage="None" conceptID="Res35" novelty="None" type="Res"/><text>Assume the object x4 is deleted from Table 2, and U′=U-{x4}.</text></s>
<s sid="184"><CoreSc1 advantage="None" conceptID="Res36" novelty="None" type="Res"/><text>We have x4∉D3⩾ and x4∉RCΔ⩾¯D3⩾.</text></s>
Therefore, RAΔ⩾¯D3⩾′=RCΔ⩾¯D3⩾={x2,x3,x5}.
<s sid="185"><CoreSc1 advantage="None" conceptID="Res37" novelty="None" type="Res"/><text>Principles for incrementally updating approximations with the insertion of a new object</text></s>
<s sid="186"><CoreSc1 advantage="None" conceptID="Mod47" novelty="None" type="Mod"/><text>Given a SOIS (U,C∪{d},V,f) at time t, when the information system is updated by inserting a new object x̃ (x̃ denotes the inserted object) into the unverse U at time t+1, two situations may occur: (1) x̃ forms a new decision class, i.e., ∀x∈U,f(x̃,d)≠f(x,d); (2) x̃ does not form a new decision class, i.e., ∃x∈U,f(x̃,d)=f(x,d).</text></s>
<s sid="187"><CoreSc1 advantage="None" conceptID="Mod48" novelty="None" type="Mod"/><text>The difference between the two situations is: in the first situation, in addition to updating the approximations of union of the existing decision classes, we need to compute the approximations for the new decision class.</text></s>
<s sid="188"><CoreSc1 advantage="None" conceptID="Mod49" novelty="None" type="Mod"/><text>Firstly, for updating the approximations of the union of the existing decision classes Di⩾ (1⩽i⩽r) when inserting an object, we discuss the principles through two cases similar to the approach taken in the model of deletion: (1) The inserted object will belong to Di⩾, i.e., x̃⪰dx, where x∈Di; (2) The inserted object will not belong to Di⩾, i.e., x̃⪰dx, where x∈Di.</text></s>
<s sid="189"><CoreSc1 advantage="None" conceptID="Obs24" novelty="None" type="Obs"/><text>To illustrate our incremental methods for updating approximations when inserting a new object into SOIS, two tables (Tables 3 and 4) are given as follows.</text></s>
<s sid="190"><CoreSc1 advantage="None" conceptID="Obs25" novelty="None" type="Obs"/><text>We assume that the objects in Table 3 will be inserted into Table 1, and the objects in Table 4 will be inserted into Table 2.Case 1:</text></s>
<s sid="191"><CoreSc1 advantage="None" conceptID="Res38" novelty="None" type="Res"/><text>The inserted object x̃ will belong to Di.</text></s>
Proposition 5
<s sid="192"><CoreSc1 advantage="None" conceptID="Res39" novelty="None" type="Res"/><text>Let S=(U,C∪{d},V,f) be a SOIS, A⊆C.</text></s>
<s sid="193"><CoreSc1 advantage="None" conceptID="Res40" novelty="None" type="Res"/><text>When x̃ is inserted into U, for RAΔ⩾̲Di⩾′, we have:(1)</text></s>
<s sid="194"><CoreSc1 advantage="None" conceptID="Res41" novelty="None" type="Res"/><text>If Di⩾′⊇[x̃]AΔ⩾, where Di⩾′=Di⩾∪{x̃}, then RAΔ⩾̲Di⩾′=RAΔ⩾̲Di⩾∪{x̃};</text></s>
(2)
Otherwise, RAΔ⩾̲Di⩾′=RAΔ⩾̲Di⩾.
Proof
<s sid="195"><CoreSc1 advantage="None" conceptID="Con12" novelty="None" type="Con"/><text>According to Definition 4, we have ∀x∈Di⩾, if [x]AΔ⩾⊆Di⩾, then x∈RAΔ⩾̲Di⩾.</text></s>
<s sid="196"><CoreSc1 advantage="None" conceptID="Con13" novelty="None" type="Con"/><text>Thus, when the object x̃ is inserted into U, we have Di⩾′=Di⩾∪{x̃}; ∀x∈Di⩾, if x̃∈[x]AΔ⩾, then [x]AΔ⩾′=[x]AΔ⩾∪{x̃}.</text></s>
<s sid="197"><CoreSc1 advantage="None" conceptID="Con14" novelty="None" type="Con"/><text>That is, if Di⩾⊇[x]AΔ⩾, then Di⩾′⊇[x]AΔ⩾′; If Di⩾⊉[x]AΔ⩾, then Di⩾′⊉[x]AΔ⩾′.</text></s>
<s sid="198"><CoreSc1 advantage="None" conceptID="Con15" novelty="None" type="Con"/><text>It follows that if x∈RAΔ⩾̲Di⩾, then x∈RAΔ⩾̲Di⩾′; If x∉RAΔ⩾̲Di⩾, then x∉RAΔ⩾̲Di⩾′.</text></s>
<s sid="199"><CoreSc1 advantage="None" conceptID="Con16" novelty="None" type="Con"/><text>Therefore, according to Definition 4, if [x̃]AΔ⩾⊆Di⩾′, we have x̃∈RAΔ⩾̲Di⩾′, and RAΔ⩾̲Di⩾′=RAΔ⩾̲Di⩾∪{x̃}.</text></s>
Otherwise, RAΔ⩾̲Di⩾′=RAΔ⩾̲Di⩾.□
Example 9
Continuation of Example 4
(1)
<s sid="200"><CoreSc1 advantage="None" conceptID="Obs26" novelty="None" type="Obs"/><text>For Table 1, according to Proposition 5, we compute the lower approximations of D2⩾ when the object x7 and x8 in Table 3 insert into Table 1, respectively.•</text></s>
<s sid="201"><CoreSc1 advantage="None" conceptID="Obs27" novelty="None" type="Obs"/><text>Assume the object x7 in Table 3 is inserted into Table 1, and U′=U∪{x7}.</text></s>
Since f(x7,d)=3, then D2⩾′=D2⩾∪{x7}.
<s sid="202"><CoreSc1 advantage="None" conceptID="Res42" novelty="None" type="Res"/><text>Because of Di⩾′⊇[x7]CΔ⩾={x2,x7}, we have RCΔ⩾̲D2⩾′=RCΔ⩾̲D2⩾∪{x7}={x2,x4,x6,x7}.</text></s>
•
<s sid="203"><CoreSc1 advantage="None" conceptID="Obs28" novelty="None" type="Obs"/><text>Assume the object x8 in Table 3 is inserted into Table 1, and U′=U∪{x8}.</text></s>
Since f(x8,d)=3, then D2⩾′=D2⩾∪{x8}.
<s sid="204"><CoreSc1 advantage="None" conceptID="Res43" novelty="None" type="Res"/><text>Because of D2⩾′⊉[x8]CΔ⩾={x4,x6,x8}, we have RCΔ⩾̲D2⩾′=RCΔ⩾̲D2⩾={x2,x4,x6}.</text></s>
(2)
<s sid="205"><CoreSc1 advantage="None" conceptID="Obs29" novelty="None" type="Obs"/><text>For Table 2, according to Proposition 4, we compute the lower approximation of D2⩾ when the objects x7 and x8 in Table 4 insert into Table 2, respectively.•</text></s>
<s sid="206"><CoreSc1 advantage="None" conceptID="Obs30" novelty="None" type="Obs"/><text>Assume the object x7 in Table 4 is inserted into Table 2, and U′=U∪{x7}.</text></s>
Since f(x7,d)=2, then D2⩾′=D2⩾∪{x7}.
<s sid="207"><CoreSc1 advantage="None" conceptID="Res44" novelty="None" type="Res"/><text>Because of D2⩾′⊇[x7]CΔ⩾={x5,x7}, we have RCΔ⩾̲D2⩾′=RCΔ⩾̲D2⩾∪{x7}={x1,x2,x5,x7}.</text></s>
•
<s sid="208"><CoreSc1 advantage="None" conceptID="Obs31" novelty="None" type="Obs"/><text>Assume the object x8 in Table 4 is inserted into Table 2, and U′=U∪{x8}.</text></s>
Since f(x8,d)=2, then D2⩾′=D2⩾∪{x8}.
<s sid="209"><CoreSc1 advantage="None" conceptID="Res45" novelty="None" type="Res"/><text>Because of D2⩾′⊉[x8]CΔ⩾={x4,x6,x8}, we have RCΔ⩾̲D2⩾′=RCΔ⩾̲D2⩾={x1,x2,x5}.</text></s>
Proposition 6
<s sid="210"><CoreSc1 advantage="None" conceptID="Res46" novelty="None" type="Res"/><text>Let S=(U,C∪d,V,f) be a SOIS, A⊆C.</text></s>
<s sid="211"><CoreSc1 advantage="None" conceptID="Obs32" novelty="None" type="Obs"/><text>When x̃ is inserted into U, for RAΔ⩾¯Di⩾′, we haveRAΔ⩾¯Di⩾′=RAΔ⩾¯Di⩾∪[x̃]AΔ⩾</text></s>
Proof
<s sid="212"><CoreSc1 advantage="None" conceptID="Obs33" novelty="None" type="Obs"/><text>When the object x̃ is inserted into U,U′=U∪{x̃}.</text></s>
<s sid="213"><CoreSc1 advantage="None" conceptID="Res47" novelty="None" type="Res"/><text>According to Definition 4, we have RAΔ⩾¯Di⩾′=⋃x∈Di⩾′[x]AΔ⩾′.</text></s>
<s sid="214"><CoreSc1 advantage="None" conceptID="Res48" novelty="None" type="Res"/><text>Since Di⩾′=Di⩾∪{x̃}, then we have RAΔ⩾¯Di⩾′=⋃x∈Di⩾[x]AΔ⩾′∪[x̃]AΔ⩾.</text></s>
<s sid="215"><CoreSc1 advantage="None" conceptID="Res49" novelty="None" type="Res"/><text>Because ∀x∈U,[x]AΔ⩾′=[x]AΔ⩾∪{x̃} or [x]AΔ⩾′=[x]AΔ⩾, and x̃∈[x̃]AΔ⩾, we can obtain that RAΔ⩾¯Di⩾′=⋃x∈Di+1⩾[x]AΔ⩾∪[x̃]AΔ⩾=RAΔ⩾¯Di⩾∪[x̃]AΔ⩾.□</text></s>
Example 10
Continuation of Example 4
(1)
<s sid="216"><CoreSc1 advantage="None" conceptID="Obs34" novelty="None" type="Obs"/><text>For Table 1, according to Proposition 6, we compute the upper approximations of D2⩾ when the object x7 in Table 3 inserts into Table 1.</text></s>
<s sid="217"><CoreSc1 advantage="None" conceptID="Obs35" novelty="None" type="Obs"/><text>Assume the object x7 in Table 3 inserts into Table 1, and U′=U∪{x7}.</text></s>
<s sid="218"><CoreSc1 advantage="None" conceptID="Obs36" novelty="None" type="Obs"/><text>Since f(x7,d)=3, then D2⩾′=D2⩾∪{x7} and RCΔ⩾¯D2⩾′=RCΔ⩾¯D2⩾∪[x7]CΔ⩾={x1,x2,x3,x4,x6,x7}.</text></s>
(2)
<s sid="219"><CoreSc1 advantage="None" conceptID="Obs37" novelty="None" type="Obs"/><text>For Table 2, according to Proposition 6, we compute the upper approximations of D2⩾ when the object x7 in Table 4 inserts into Table 2.</text></s>
<s sid="220"><CoreSc1 advantage="None" conceptID="Obs38" novelty="None" type="Obs"/><text>Assume the object x7 in Table 4 inserts into Table 2, and U′=U∪{x7}.</text></s>
<s sid="221"><CoreSc1 advantage="None" conceptID="Res50" novelty="None" type="Res"/><text>Since f(x7,d)=2, then D2⩾′=D2⩾∪{x7} and RCΔ⩾¯D2⩾′=RCΔ⩾¯D2⩾∪[x7]CΔ⩾={x1,x2,x3,x4,x5,x6,x7}.</text></s>
Case 2:
<s sid="222"><CoreSc1 advantage="None" conceptID="Res51" novelty="None" type="Res"/><text>The inserted object x̃ will not belong to Di.</text></s>
Proposition 7
<s sid="223"><CoreSc1 advantage="None" conceptID="Res52" novelty="None" type="Res"/><text>Let S=(U,C∪d,V,f) be a SOIS, A⊆C.</text></s>
<s sid="224"><CoreSc1 advantage="None" conceptID="Res53" novelty="None" type="Res"/><text>When x̃ is inserted into U, for RAΔ⩾̲Di⩾′, we haveRAΔ⩾̲Di⩾′=RAΔ⩾̲Di⩾-Kwhere K=x|x∈RAΔ⩾̲Di⩾,x̃∈[x]AΔ⩾′.</text></s>
Proof
<s sid="225"><CoreSc1 advantage="None" conceptID="Res54" novelty="None" type="Res"/><text>When the object x̃ is inserted into U, since x̃⪰dx (x∈Di), we have U′=U∪{x̃},Di⩾′=Di⩾.</text></s>
∀x∈Di⩾′,[x]AΔ⩾′=[x]AΔ⩾ or [x]AΔ⩾′=[x]AΔ⩾∪{x̃}.
<s sid="226"><CoreSc1 advantage="None" conceptID="Res55" novelty="None" type="Res"/><text>We have if [x]AΔ⩾⊈Di⩾, then [x]AΔ⩾⊈Di⩾′.</text></s>
<s sid="227"><CoreSc1 advantage="None" conceptID="Res56" novelty="None" type="Res"/><text>That is, if x∉RAΔ⩾̲Di⩾, then x∉RAΔ⩾̲Di⩾′.</text></s>
<s sid="228"><CoreSc1 advantage="None" conceptID="Res57" novelty="None" type="Res"/><text>Hence, we only consider the object x∈RAΔ⩾̲Di⩾, i.e., [x]AΔ⩾⊆Di⩾.</text></s>
<s sid="229"><CoreSc1 advantage="None" conceptID="Con17" novelty="None" type="Con"/><text>When x̃ is deleted, there may exist that [x]AΔ⩾′=[x]AΔ⩾∪{x̃}.</text></s>
Then [x]AΔ⩾′⊈Di⩾′=Di⩾, i.e., x∉RAΔ⩾̲Di⩾′.
<s sid="230"><CoreSc1 advantage="None" conceptID="Con18" novelty="None" type="Con"/><text>Therefore, we have RAΔ⩾̲Di⩾′=RAΔ⩾̲Di⩾-K, where K=x|x∈RAΔ⩾̲Di⩾,x̃∈[x]AΔ⩾′.□</text></s>
Example 11
Continuation of Example 4
(1)
<s sid="231"><CoreSc1 advantage="None" conceptID="Obs39" novelty="None" type="Obs"/><text>For Table 1, according to Proposition 7, we compute the lower approximations of D2⩾ when the object x9 in Table 3 inserts into Table 1.</text></s>
<s sid="232"><CoreSc1 advantage="None" conceptID="Obs40" novelty="None" type="Obs"/><text>Assume the object x9 in Table 3 inserts into Table 1, and U′=U∪{x9}.</text></s>
<s sid="233"><CoreSc1 advantage="None" conceptID="Res58" novelty="None" type="Res"/><text>Since f(x9,d)=1, then D2⩾ remains unchanged.</text></s>
<s sid="234"><CoreSc1 advantage="None" conceptID="Res59" novelty="None" type="Res"/><text>Because of RCΔ⩾̲D2⩾={x2,x4,x6},x9⪰Cx6, that is, x9∈[x6]CΔ⩾′.</text></s>
Hence, we have K={x|x∈RCΔ⩾̲D2⩾,x9∈[x]CΔ⩾′}={x6},RCΔ⩾̲D2⩾′=RCΔ⩾̲D2⩾-K={x2,x4}.
(2)
<s sid="235"><CoreSc1 advantage="None" conceptID="Obs41" novelty="None" type="Obs"/><text>For Table 2, according to Proposition 7, we compute the lower approximations of D2⩾ when the object x9 in Table 4 inserts into Table 2.</text></s>
<s sid="236"><CoreSc1 advantage="None" conceptID="Obs42" novelty="None" type="Obs"/><text>Assume the object x9 in Table 4 is inserted into Table 2, and U′=U∪{x9}.</text></s>
<s sid="237"><CoreSc1 advantage="None" conceptID="Res60" novelty="None" type="Res"/><text>Since f(x9,d)=1, then D2⩾ remains unchanged.</text></s>
<s sid="238"><CoreSc1 advantage="None" conceptID="Res61" novelty="None" type="Res"/><text>Because of RCΔ⩾̲D2⩾={x1,x2,x5},x9⪰Cx1, that is, x9∈[x1]C⊇′.</text></s>
Hence K={x|x∈RCΔ⩾̲D2⩾,x9∈[x]CΔ⩾′}={x1},RCΔ⩾̲D2⩾′=RCΔ⩾̲D2⩾-K={x2,x5}.
Proposition 8
<s sid="239"><CoreSc1 advantage="None" conceptID="Res62" novelty="None" type="Res"/><text>Let (U,C∪d,V,f) be a SOIS, A⊆C.</text></s>
<s sid="240"><CoreSc1 advantage="None" conceptID="Res63" novelty="None" type="Res"/><text>When x̃ is inserted into U, for RAΔ⩾¯Di⩾′, we have:(1)</text></s>
If ∃x∈Di⩾,x̃∈[x]AΔ⩾, then RAΔ⩾¯Di⩾′=RAΔ⩾¯Di⩾∪{x̃};
(2)
Otherwise, RAΔ⩾¯Di⩾′=RAΔ⩾¯Di⩾.
Proof
<s sid="241"><CoreSc1 advantage="None" conceptID="Res64" novelty="None" type="Res"/><text>When the object x̃ is inserted into U, since x̃⪰dx (x∈Di), we have U′=U∪{x̃},Di⩾′=Di⩾.</text></s>
<s sid="242"><CoreSc1 advantage="None" conceptID="Res65" novelty="None" type="Res"/><text>Then, ∀x∈Di⩾′, if x̃∈[x]AΔ⩾, then [x]AΔ⩾′=[x]AΔ⩾∪{x̃}.</text></s>
<s sid="243"><CoreSc1 advantage="None" conceptID="Res66" novelty="None" type="Res"/><text>According to Definition 4, we have x̃∈RAΔ⩾¯Di⩾′, that is, RAΔ⩾¯Di⩾′=RAΔ⩾¯Di⩾∪{x̃}; Otherwise, if ∀x∈Di⩾,x̃∉[x]AΔ⩾′, that is, [x]AΔ⩾′=[x]AΔ⩾.</text></s>
Then we have RAΔ⩾¯Di⩾′=RAΔ⩾¯Di⩾.□
Example 12
Continuation of Example 4
(1)
<s sid="244"><CoreSc1 advantage="None" conceptID="Obs43" novelty="None" type="Obs"/><text>For Table 1, according to Proposition 8, we compute the lower approximations of D2⩾ when the object x9 and x10 in Table 3 insert into Table 1, respectively.•</text></s>
<s sid="245"><CoreSc1 advantage="None" conceptID="Obs44" novelty="None" type="Obs"/><text>Assume the object x9 in Table 3 inserts into Table 1, and U′=U∪{x9}.</text></s>
<s sid="246"><CoreSc1 advantage="None" conceptID="Res67" novelty="None" type="Res"/><text>Since f(x9,d)=1, then D2⩾ remains unchanged.</text></s>
<s sid="247"><CoreSc1 advantage="None" conceptID="Res68" novelty="None" type="Res"/><text>Because of D2⩾={x1,x2,x4,x6},x9⪰Cx6, that is, x9∈[x6]CΔ⩾′.</text></s>
Hence RCΔ⩾¯D2⩾′=RCΔ⩾¯D2⩾∪{x9}={x1,x2,x3,x4,x6,x9}.
•
<s sid="248"><CoreSc1 advantage="None" conceptID="Obs45" novelty="None" type="Obs"/><text>Assume the object x10 in Table 3 inserts into Table 1, and U′=U∪{x10}.</text></s>
<s sid="249"><CoreSc1 advantage="None" conceptID="Res69" novelty="None" type="Res"/><text>Since f(x10,d)=1, then D2⩾ remains unchanged.</text></s>
<s sid="250"><CoreSc1 advantage="None" conceptID="Res70" novelty="None" type="Res"/><text>Because of ∀x∈D2⩾={x1,x2,x4,x6},x9⪰Cx, that is, x9∉[x]CΔ⩾′.</text></s>
Hence RCΔ⩾¯D2⩾′=RCΔ⩾¯D2⩾={x1,x2,x3,x4,x6}.
(2)
<s sid="251"><CoreSc1 advantage="None" conceptID="Obs46" novelty="None" type="Obs"/><text>For Table 2, according to Proposition 8, we compute the upper approximations of D2⩾ when the object x9 and x10 in Table 4 insert into Table 2, respectively.•</text></s>
<s sid="252"><CoreSc1 advantage="None" conceptID="Obs47" novelty="None" type="Obs"/><text>Assume the object x9 in Table 4 inserts into Table 2, and U′=U∪{x9}.</text></s>
<s sid="253"><CoreSc1 advantage="None" conceptID="Res71" novelty="None" type="Res"/><text>Since f(x9,d)=1, then D2⩾ remains unchanged.</text></s>
<s sid="254"><CoreSc1 advantage="None" conceptID="Res72" novelty="None" type="Res"/><text>Because of D2⩾={x1,x2,x3,x5,x6},x9⪰Cx1, that is, x9∈[x1]CΔ⩾′.</text></s>
Hence RCΔ⩾¯D2⩾′=RCΔ⩾¯D2⩾∪{x9}={x1,x2,x3,x5,x6,x9}.
•
<s sid="255"><CoreSc1 advantage="None" conceptID="Obs48" novelty="None" type="Obs"/><text>Assume the object x10 in Table 4 inserts into Table 2, and U′=U∪{x10}.</text></s>
<s sid="256"><CoreSc1 advantage="None" conceptID="Res73" novelty="None" type="Res"/><text>Since f(x10,d)=1, then D2⩾ remains unchanged.</text></s>
<s sid="257"><CoreSc1 advantage="None" conceptID="Res74" novelty="None" type="Res"/><text>Because of ∀x∈D2⩾={x1,x2,x3,x5,x6},x10⪰Cx, that is, x10∉[x]CΔ⩾′.</text></s>
Hence RCΔ⩾¯D2⩾′=RCΔ⩾¯D2⩾={x1,x2,x3,x5,x6}.
<s sid="258"><CoreSc1 advantage="None" conceptID="Con19" novelty="None" type="Con"/><text>Based on the above analysis, we can compute the approximations of the union of existing decision classes Di⩾ (1⩽i⩽r) when inserting a new object into SOIS.</text></s>
<s sid="259"><CoreSc1 advantage="None" conceptID="Con20" novelty="None" type="Con"/><text>However, when a new object x̃ is inserted into the universe, it might happen that x̃ will form a new decision class, i.e., ∀x∈U,f(x̃,d)≠f(x,d).</text></s>
<s sid="260"><CoreSc1 advantage="None" conceptID="Con21" novelty="None" type="Con"/><text>Then the universe U′=U∪{x̃} will be divided into r+1 partitions, such as: D={D1,…,Di, Dnew, Di+1,…,Dr}, where |D|=r+1,Dnew={x̃}.</text></s>
<s sid="261"><CoreSc1 advantage="None" conceptID="Con22" novelty="None" type="Con"/><text>At this point, in addition to updating the approximations of the existing unions of decision classes, we need to compute the unions of new decision class Dnew: Dnew⩾=Di+1⩾∪{x̃}.Proposition 9</text></s>
<s sid="262"><CoreSc1 advantage="None" conceptID="Res75" novelty="None" type="Res"/><text>Let S=(U,C∪d,V,f) be a SOIS, A⊆C.</text></s>
<s sid="263"><CoreSc1 advantage="None" conceptID="Res76" novelty="None" type="Res"/><text>When x̃ is inserted into U, if ∀x∈U,f(x̃,d)≠f(x,d), then the lower approximation of the union of the new decision class Dnew⩾ can be computed as follows:(1)</text></s>
<s sid="264"><CoreSc1 advantage="None" conceptID="Res77" novelty="None" type="Res"/><text>If [x̃]AΔ⩾⊆Dnew⩾, where Dnew⩾=Di+1⩾∪{x̃}, then RAΔ⩾̲Dnew⩾=RAΔ⩾̲Di+1⩾∪{x̃};</text></s>
(2)
Otherwise, RAΔ⩾̲Dnew⩾=RAΔ⩾̲Di+1⩾.
Proof
<s sid="265"><CoreSc1 advantage="None" conceptID="Res78" novelty="None" type="Res"/><text>When the object x̃ is inserted into U, then U′=U∪{x̃}.</text></s>
<s sid="266"><CoreSc1 advantage="None" conceptID="Con23" novelty="None" type="Con"/><text>Since ∀x∈U,f(x̃,d)≠f(x,d),x̃ will form a new decision class.</text></s>
<s sid="267"><CoreSc1 advantage="None" conceptID="Con24" novelty="None" type="Con"/><text>U′ will be divided into r+1 partitions, such as: D={D1,…,Di,Dnew,Di+1,…,Dr}, where |D|=r+1,Dnew={x̃}.</text></s>
<s sid="268"><CoreSc1 advantage="None" conceptID="Con25" novelty="None" type="Con"/><text>It is easy to obtain that the union of the new decision class Dnew is: Dnew⩾=Di+1⩾∪{x̃}.</text></s>
<s sid="269"><CoreSc1 advantage="None" conceptID="Con26" novelty="None" type="Con"/><text>Then from Definition 4, we know that ∀x∈U′, if [x]AΔ⩾′⊆Dnew⩾, then x∈RAΔ⩾̲Dnew⩾; Furthermore, since Dnew⩾=Di+1⩾∪{x̃} and ∀x∈U,[x]AΔ⩾′=[x]AΔ⩾∪{x̃} or [x]AΔ⩾′=[x]AΔ⩾, we have if x∈RAΔ⩾̲Di+1⩾, then x∈RAΔ⩾̲Dnew⩾, and if x∉RAΔ⩾̲Di+1⩾, then x∉RAΔ⩾̲Dnew⩾.</text></s>
<s sid="270"><CoreSc1 advantage="None" conceptID="Con27" novelty="None" type="Con"/><text>Hence, if [x̃]AΔ⩾⊆Dnew⩾, then RAΔ⩾̲Dnew⩾=RAΔ⩾̲Di+1⩾∪{x̃}; Otherwise, RAΔ⩾̲Dnew⩾=RAΔ⩾̲Di+1⩾.□</text></s>
Example 13
Continuation of Example 4
(1)
<s sid="271"><CoreSc1 advantage="None" conceptID="Obs49" novelty="None" type="Obs"/><text>For Table 1, according to Proposition 9, we compute the lower approximations of Dnew⩾ when the object x11 and x12 in Table 3 insert into Table 1, respectively.•</text></s>
<s sid="272"><CoreSc1 advantage="None" conceptID="Obs50" novelty="None" type="Obs"/><text>Assume the object x11 in Table 3 inserts into Table 1, and U′=U∪{x11}.</text></s>
<s sid="273"><CoreSc1 advantage="None" conceptID="Res79" novelty="None" type="Res"/><text>Since ∀x∈U, f(x,d)≠f(x11,d)=3 and f(D2,d)&lt;f(x11,d)&lt;f(D3,d), then D={D1,D2,Dnew,D3},Dnew⩾=D3⩾∪{x11}={x2,x6,x11}.</text></s>
<s sid="274"><CoreSc1 advantage="None" conceptID="Res80" novelty="None" type="Res"/><text>Because of [x11]CΔ⩾={x2,x11},[x11]CΔ⩾⊆Dnew⩾, we have RCΔ⩾̲Dnew⩾=RCΔ⩾̲D3⩾∪{x11}={x2,x6,x11}.</text></s>
•
<s sid="275"><CoreSc1 advantage="None" conceptID="Obs51" novelty="None" type="Obs"/><text>Assume the object x12 in Table 3 inserts into Table 1, and U′=U∪{x12}.</text></s>
<s sid="276"><CoreSc1 advantage="None" conceptID="Res81" novelty="None" type="Res"/><text>Since ∀x∈U, f(x,d)≠f(x12,d)=3 and f(D2,d)&lt;f(x12,d)&lt;f(D3,d), then D={D1,D2,Dnew,D3},Dnew⩾=D3⩾∪{x11}={x2,x6,x12}.</text></s>
<s sid="277"><CoreSc1 advantage="None" conceptID="Res82" novelty="None" type="Res"/><text>Because of [x12]CΔ⩾={x2,x4,x12},[x11]CΔ⩾⊈Dnew⩾, we have RCΔ⩾̲Dnew⩾=RCΔ⩾̲D3⩾={x2,x6}.</text></s>
(2)
<s sid="278"><CoreSc1 advantage="None" conceptID="Obs52" novelty="None" type="Obs"/><text>For Table 2, according to Proposition 9, we compute the lower approximations of Dnew⩾ when the object x11 and x12 in Table 4 are respectively inserted into Table 2.•</text></s>
<s sid="279"><CoreSc1 advantage="None" conceptID="Obs53" novelty="None" type="Obs"/><text>Assume the object x11 in Table 4 inserts into Table 2, and U′=U∪{x11}.</text></s>
<s sid="280"><CoreSc1 advantage="None" conceptID="Res83" novelty="None" type="Res"/><text>Since ∀x∈U, f(x,d)≠f(x11,d)=3 and f(D2,d)&lt;f(x11,d)&lt;f(D3,d), then D={D1,D2,Dnew,D3},Dnew⩾=D3⩾∪{x11}={x2,x5,x11}.</text></s>
<s sid="281"><CoreSc1 advantage="None" conceptID="Res84" novelty="None" type="Res"/><text>Because of [x11]CΔ⩾={x5,x11},[x11]CΔ⩾⊆Dnew⩾, we have RCΔ⩾̲Dnew⩾=RCΔ⩾̲D3⩾∪{x11}={x11}.</text></s>
•
<s sid="282"><CoreSc1 advantage="None" conceptID="Obs54" novelty="None" type="Obs"/><text>Assume the object x12 in Table 4 inserts into Table 2, and U′=U∪{x12}.</text></s>
<s sid="283"><CoreSc1 advantage="None" conceptID="Res85" novelty="None" type="Res"/><text>Since ∀x∈U, f(x,d)≠f(x12,d)=3 and f(D2,d)&lt;f(x12,d)&lt;f(D3,d), then D={D1,D2,Dnew,D3},Dnew⩾=D3⩾∪{x12}={x2,x5,x12}.</text></s>
<s sid="284"><CoreSc1 advantage="None" conceptID="Res86" novelty="None" type="Res"/><text>Because of [x12]CΔ⩾={x3,x5,x12},[x12]CΔ⩾⊈Dnew⩾, we have RCΔ⩾̲Dnew⩾=RCΔ⩾̲D3⩾=∅.</text></s>
Proposition 10
<s sid="285"><CoreSc1 advantage="None" conceptID="Res87" novelty="None" type="Res"/><text>Let S=(U,C∪d,V,f) be a SOIS, A⊆C.</text></s>
<s sid="286"><CoreSc1 advantage="None" conceptID="Res88" novelty="None" type="Res"/><text>When x̃ is inserted into U, if ∀x∈U,f(x̃,d)≠f(x,d), then the upper approximation of the union of the new decision class Dnew⩾ can be computed as follows:RAΔ⩾¯Dnew⩾=RAΔ⩾¯Di+1⩾∪[x̃]AΔ⩾where Dnew⩾=Di+1⩾∪{x̃}.</text></s>
Proof
<s sid="287"><CoreSc1 advantage="None" conceptID="Res89" novelty="None" type="Res"/><text>When the object x̃ inserts into U,U′=U∪{x̃}.</text></s>
<s sid="288"><CoreSc1 advantage="None" conceptID="Res90" novelty="None" type="Res"/><text>According to Definition 4, we have RAΔ⩾¯Dnew⩾=⋃x∈Dnew⩾[x]AΔ⩾′=⋃x∈Di+1⩾[x]AΔ⩾′∪[x̃]AΔ⩾.</text></s>
Since Dnew⩾=Di+1⩾∪{x̃}, then RAΔ⩾¯Dnew⩾=⋃x∈Di+1⩾[x]AΔ⩾′∪[x̃]AΔ⩾.
<s sid="289"><CoreSc1 advantage="None" conceptID="Res91" novelty="None" type="Res"/><text>Because ∀x∈U,[x]AΔ⩾′=[x]AΔ⩾∪{x̃} or [x]AΔ⩾′=[x]AΔ⩾, and x̃∈[x̃]AΔ⩾, we can obtain that RAΔ⩾¯Dnew⩾=⋃x∈Di+1⩾[x]AΔ⩾∪[x̃]AΔ⩾=RAΔ⩾¯Di+1⩾∪[x̃]AΔ⩾.□</text></s>
Example 14
Continuation of Example 4
(1)
<s sid="290"><CoreSc1 advantage="None" conceptID="Obs55" novelty="None" type="Obs"/><text>For Table 1, according to Proposition 9, we compute the lower approximations of Dnew⩾ when the object x11 in Table 3 inserts into Table 1.</text></s>
<s sid="291"><CoreSc1 advantage="None" conceptID="Obs56" novelty="None" type="Obs"/><text>Assume the object x11 in Table 3 inserts into Table 1, and U′=U∪{x11}.</text></s>
<s sid="292"><CoreSc1 advantage="None" conceptID="Res92" novelty="None" type="Res"/><text>Since ∀x∈U, f(x,d)≠f(x11,d)=3 and f(D2,d)&lt;f(x11,d)&lt;f(D3,d), then D={D1,D2,Dnew,D3},Dnew⩾=D3⩾∪{x11}={x2,x6,x11}.</text></s>
<s sid="293"><CoreSc1 advantage="None" conceptID="Res93" novelty="None" type="Res"/><text>Because of [x11]CΔ⩾={x2,x11}, we have RCΔ⩾¯Dnew⩾=RCΔ⩾¯D3⩾∪[x11]AΔ⩾={x2,x6,x11}.</text></s>
(2)
<s sid="294"><CoreSc1 advantage="None" conceptID="Obs57" novelty="None" type="Obs"/><text>For Table 2, according to Proposition 9, we compute the lower approximations of Dnew⩾ when the object x11 in Table 4 inserts into Table 2.</text></s>
<s sid="295"><CoreSc1 advantage="None" conceptID="Obs58" novelty="None" type="Obs"/><text>Assume the object x11 in Table 4 inserts into Table 2, and U′=U∪{x11}.</text></s>
<s sid="296"><CoreSc1 advantage="None" conceptID="Res94" novelty="None" type="Res"/><text>Since ∀x∈U, f(x,d)≠f(x11,d)=3 and f(D2,d)&lt;f(x11,d)&lt;f(D3,d), then D={D1,D2,Dnew,D3},Dnew⩾=D3⩾∪{x11}={x2,x5,x11}.</text></s>
<s sid="297"><CoreSc1 advantage="None" conceptID="Res95" novelty="None" type="Res"/><text>Because of [x11]CΔ⩾={x5,x11}, we have RCΔ⩾¯Dnew⩾=RCΔ⩾¯D3⩾∪[x11]CΔ⩾={x2,x3,x5,x11}.</text></s>
<s sid="298"><CoreSc1 advantage="None" conceptID="Res96" novelty="None" type="Res"/><text>Static (non-incremental) and incremental algorithms for computing approximations in SOIS with the variation of the object set</text></s>
<s sid="299"><CoreSc1 advantage="None" conceptID="Res97" novelty="None" type="Res"/><text>In this section, we design static and incremental algorithms on the variation of the object set in SOIS corresponding to Sections 2 and 3, respectively.</text></s>
<s sid="300"><CoreSc1 advantage="None" conceptID="Res98" novelty="None" type="Res"/><text>The static algorithm for computing approximations in SOIS</text></s>
<s sid="301"><CoreSc1 advantage="None" conceptID="Res99" novelty="None" type="Res"/><text>Algorithm 1 is a static (non-incremental) algorithm for computing the lower and upper approximations in SOIS while the object set in the information system is changed.</text></s>
<s sid="302"><CoreSc1 advantage="None" conceptID="Res100" novelty="None" type="Res"/><text>In Step 2, we compute all the decision classes, and the set of decision classes are preference-ordered according to the increasing order of class indices.</text></s>
<s sid="303"><CoreSc1 advantage="None" conceptID="Res101" novelty="None" type="Res"/><text>Step 3-7 compute all the upward unions of classes based on the set of decision classes.</text></s>
<s sid="304"><CoreSc1 advantage="None" conceptID="Res102" novelty="None" type="Res"/><text>Step 9-11 compute all the A-dominating sets.</text></s>
<s sid="305"><CoreSc1 advantage="None" conceptID="Res103" novelty="None" type="Res"/><text>Step 12-21 compute the lower and upper approximations in SOIS based on Definition 4.</text></s>
<s sid="306"><CoreSc1 advantage="None" conceptID="Res104" novelty="None" type="Res"/><text>The incremental algorithm for updating approximations in SOIS when deleting an object from the universe</text></s>
<s sid="307"><CoreSc1 advantage="None" conceptID="Res105" novelty="None" type="Res"/><text>Algorithm 2 is an incremental algorithm for updating approximations in SOIS while deleting an object from the universe.</text></s>
<s sid="308"><CoreSc1 advantage="None" conceptID="Res106" novelty="None" type="Res"/><text>Step 3-16 update the approximations of the union of classes Di⩾, when the deleted object x¯ belongs to the union of classes Di⩾.</text></s>
<s sid="309"><CoreSc1 advantage="None" conceptID="Res107" novelty="None" type="Res"/><text>Step 4-8 compute the lower approximations of Di⩾ by Proposition 1.</text></s>
<s sid="310"><CoreSc1 advantage="None" conceptID="Res108" novelty="None" type="Res"/><text>Step 9-16 compute the upper approximations of Di⩾ by Proposition 2.</text></s>
<s sid="311"><CoreSc1 advantage="None" conceptID="Res109" novelty="None" type="Res"/><text>Step 18-34 update the approximations of the union of classes Di⩾, when the deleted object x¯ does not belong to the union of classes Di⩾.</text></s>
<s sid="312"><CoreSc1 advantage="None" conceptID="Res110" novelty="None" type="Res"/><text>Step 19-27 compute the lower approximations of Di⩾ by Proposition 3.</text></s>
<s sid="313"><CoreSc1 advantage="None" conceptID="Res111" novelty="None" type="Res"/><text>Step 28-33 compute the upper approximations of Di⩾ by Proposition 4.</text></s>
<s sid="314"><CoreSc1 advantage="None" conceptID="Res112" novelty="None" type="Res"/><text>The incremental algorithm for updating approximations in SOIS when inserting an object into the universe</text></s>
<s sid="315"><CoreSc1 advantage="None" conceptID="Res113" novelty="None" type="Res"/><text>Algorithm 3 is an incremental algorithm for updating approximations in SOIS while inserting an object into the universe.</text></s>
<s sid="316"><CoreSc1 advantage="None" conceptID="Res114" novelty="None" type="Res"/><text>Step 2 compute the A-dominating set with respect to the inserted object x̃.</text></s>
<s sid="317"><CoreSc1 advantage="None" conceptID="Res115" novelty="None" type="Res"/><text>Step 3-25 update the approximations of the union of classes Di⩾, when the inserted object x̃ will belong to the union of classes Di⩾.</text></s>
<s sid="318"><CoreSc1 advantage="None" conceptID="Res116" novelty="None" type="Res"/><text>Step 5-10 compute the lower approximations of Di⩾ by Proposition 5.</text></s>
<s sid="319"><CoreSc1 advantage="None" conceptID="Res117" novelty="None" type="Res"/><text>Step 11 compute the upper approximation of Di⩾ by Proposition 6.</text></s>
<s sid="320"><CoreSc1 advantage="None" conceptID="Res118" novelty="None" type="Res"/><text>Step 13-24 update the approximations of the union of classes Di⩾, when the inserted object x̃ will not belong to the union of classes Di⩾.</text></s>
<s sid="321"><CoreSc1 advantage="None" conceptID="Res119" novelty="None" type="Res"/><text>Step 13-18 compute the lower approximations of Di⩾ by Proposition 7.</text></s>
<s sid="322"><CoreSc1 advantage="None" conceptID="Res120" novelty="None" type="Res"/><text>Step 19-24 update the approximations of Di⩾ by Proposition 8.</text></s>
<s sid="323"><CoreSc1 advantage="None" conceptID="Res121" novelty="None" type="Res"/><text>Step 26-35 compute the approximation of the union of new decision class Dnew⩾, if the inserted object does not belong to any existed decision classes.</text></s>
<s sid="324"><CoreSc1 advantage="None" conceptID="Res122" novelty="None" type="Res"/><text>Step 29-33 compute the lower approximation of Dnew⩾ by Proposition 9.</text></s>
<s sid="325"><CoreSc1 advantage="None" conceptID="Res123" novelty="None" type="Res"/><text>Step 34 compute the upper approximation of Dnew⩾ by Proposition 10.</text></s>
Experimental evaluations
<s sid="326"><CoreSc1 advantage="None" conceptID="Goa3" novelty="None" type="Goa"/><text>In this section, in order to evaluate the performance of the proposed incremental algorithms, we conduct a series of experiments to compare the computational time between the non-incremental algorithm and the incremental algorithms for computing approximations based on standard data sets.</text></s>
<s sid="327"><CoreSc1 advantage="None" conceptID="Res124" novelty="None" type="Res"/><text>The algorithms are implemental using the JAVA programming language in Eclipse 3.5 with Java Virtual Machine (JVM) 1.6 (available at http://www.eclipse.org/platform).</text></s>
<s sid="328"><CoreSc1 advantage="None" conceptID="Res125" novelty="None" type="Res"/><text>Experiments are performed on a computer with 2.66GHz CPU, 4.0GB of memory and 32-bit Windows 7 OS.</text></s>
<s sid="329"><CoreSc1 advantage="None" conceptID="Res126" novelty="None" type="Res"/><text>We download four data sets from the machine learning data repository, University of California at Irvine [51], where the basic information of data sets is outlined in Table 5.</text></s>
<s sid="330"><CoreSc1 advantage="None" conceptID="Res127" novelty="None" type="Res"/><text>The data sets 1-4 in Table 5 are all incomplete information systems with missing values.</text></s>
<s sid="331"><CoreSc1 advantage="None" conceptID="Res128" novelty="None" type="Res"/><text>In our experiment, we represent all the missing values by the set of all possible values of each attribute.</text></s>
<s sid="332"><CoreSc1 advantage="None" conceptID="Res129" novelty="None" type="Res"/><text>Then this type of data sets can be regarded as a special case of the set-valued information system.</text></s>
<s sid="333"><CoreSc1 advantage="None" conceptID="Goa4" novelty="None" type="Goa"/><text>Besides, we also use the set-valued data generator to generate two artificial data sets 5-6 in order to test the efficiency of the proposed algorithms, which are also outlined in Table 5.</text></s>
<s sid="334"><CoreSc1 advantage="None" conceptID="Goa5" novelty="None" type="Goa"/><text>Generally, we perform the experimental analysis with applying the non-incremental algorithm along with our proposed incremental algorithms when the objects inserting into or deleting from the information system, respectively.</text></s>
<s sid="335"><CoreSc1 advantage="None" conceptID="Goa6" novelty="None" type="Goa"/><text>In order to present more informative comparative data and acquire more dependable results in our experiments, we compare the computational efficiency of the algorithms according to the following two aspects:(1)</text></s>
<s sid="336"><CoreSc1 advantage="None" conceptID="Mod50" novelty="None" type="Mod"/><text>Size of the data set: To compare the computational efficiency and distinguish the computational times used by the non-incremental and incremental algorithms with different-sized data sets, we divide each of the six data sets into 10 parts of equal size, respectively.</text></s>
<s sid="337"><CoreSc1 advantage="None" conceptID="Mod51" novelty="None" type="Mod"/><text>The first part is regarded as the 1st data set, the combination of the first part and the second part is viewed as the 2nd data set, the combination of the 2nd data set and the third part is regarded as the 3rd data set, and so on.</text></s>
<s sid="338"><CoreSc1 advantage="None" conceptID="Res130" novelty="None" type="Res"/><text>The combination of all ten parts is viewed as the 10th data set.</text></s>
(2)
<s sid="339"><CoreSc1 advantage="None" conceptID="Res131" novelty="None" type="Res"/><text>Update ratio of the data set: The size of updated objects which inserting into or deleting from the universe may different, that is, the update ratio, i.e., the ratio of the number of updating (deleting or inserting) data and original data, may different.</text></s>
<s sid="340"><CoreSc1 advantage="None" conceptID="Obj13" novelty="None" type="Obj"/><text>Here, in order to analyze the influence of the update ratio on the efficiency of algorithms, we compare the computational time of the static and incremental algorithms with different update ratios.</text></s>
<s sid="341"><CoreSc1 advantage="None" conceptID="Res132" novelty="None" type="Res"/><text>That is to say, for each data sets, we conduct the comparison experiments with the same original data size, but different update ratios, i.e., deleting ratios and inserting ratios.</text></s>
<s sid="342"><CoreSc1 advantage="None" conceptID="Res133" novelty="None" type="Res"/><text>A comparison of computational efficiency between static and incremental algorithms with the deletion of the objects</text></s>
<s sid="343"><CoreSc1 advantage="None" conceptID="Res134" novelty="None" type="Res"/><text>To compare the efficiency of static (Algorithm 1) and incremental (Algorithm 2) algorithms for computing approximations when deleting the objects from the data sets.</text></s>
<s sid="344"><CoreSc1 advantage="None" conceptID="Res135" novelty="None" type="Res"/><text>Firstly, we compare the two algorithms on the six data sets in Table 5 with the same updating ratio (the ratio of the number of deleting data and original data), but different sizes of the original data.</text></s>
<s sid="345"><CoreSc1 advantage="None" conceptID="Res136" novelty="None" type="Res"/><text>Here, we assume that the updating ratio is equal to 5%.</text></s>
<s sid="346"><CoreSc1 advantage="None" conceptID="Res137" novelty="None" type="Res"/><text>The experimental results are shown in Table 6.</text></s>
<s sid="347"><CoreSc1 advantage="None" conceptID="Res138" novelty="None" type="Res"/><text>More detailed changing trendline of each of two algorithms with the increasing size of data sets are illustrated in Fig. 1.</text></s>
<s sid="348"><CoreSc1 advantage="None" conceptID="Res139" novelty="None" type="Res"/><text>Secondly, we compare the computational time of the two algorithms with the same size of original data, but different updating ratios for each data sets (from 5% to 100%).</text></s>
<s sid="349"><CoreSc1 advantage="None" conceptID="Res140" novelty="None" type="Res"/><text>we show the experimental results in Table 7.</text></s>
<s sid="350"><CoreSc1 advantage="None" conceptID="Obs59" novelty="None" type="Obs"/><text>More detailed changing trendline of each of two algorithms with the increasing updating ratio of data sets are presented in Fig. 2.</text></s>
<s sid="351"><CoreSc1 advantage="None" conceptID="Obs60" novelty="None" type="Obs"/><text>In each sub-figures (a)-(f) of Fig. 1, the x-coordinate pertains to the size of the data set (the 10 data sets starting from the smallest one), while the y-coordinate presents the computational time.</text></s>
<s sid="352"><CoreSc1 advantage="None" conceptID="Obs61" novelty="None" type="Obs"/><text>We use the star lines to denote the computational time of the static algorithm on different sizes of data sets, and the plus lines denote the computational time of the incremental algorithm on different sizes of data sets when deleting the objects into the universe.</text></s>
<s sid="353"><CoreSc1 advantage="None" conceptID="Res141" novelty="None" type="Res"/><text>It is easy to see the computational time of the both algorithms usually increases with the increase of the size of data sets according to Table 6 and Fig. 1.</text></s>
<s sid="354"><CoreSc1 advantage="None" conceptID="Res142" novelty="None" type="Res"/><text>As the important advantage of the incremental algorithm shown in Table 6 and Fig. 1, when deleting the objets from the universe, we find that the incremental algorithm is mush faster than the static algorithm for computing the approximations.</text></s>
<s sid="355"><CoreSc1 advantage="None" conceptID="Con28" novelty="None" type="Con"/><text>Furthermore, the differences become larger and larger when increasing the size of data sets.</text></s>
<s sid="356"><CoreSc1 advantage="None" conceptID="Res143" novelty="None" type="Res"/><text>In each sub-figures (a)-(f) of Fig. 2, the x-coordinate pertains to the ratio of the number of the deleting data and original data, while the y-coordinate concerns the computational time.</text></s>
<s sid="357"><CoreSc1 advantage="None" conceptID="Res144" novelty="None" type="Res"/><text>According to the experimental results in Table 7 and Fig. 2, we find that, for the static algorithm, the computational time for computing approximations with deletion of the objects from the universe is decreasing monotonically along with the increase of deleting ratios.</text></s>
<s sid="358"><CoreSc1 advantage="None" conceptID="Res145" novelty="None" type="Res"/><text>It is because with the increase of ratios, the size of the universe decreases gradually.</text></s>
<s sid="359"><CoreSc1 advantage="None" conceptID="Res146" novelty="None" type="Res"/><text>On the contrary, for incremental algorithm, we can see that the computational efficiency for computing approximations is changing smoothly along with the increase of deleting ratios.</text></s>
<s sid="360"><CoreSc1 advantage="None" conceptID="Res147" novelty="None" type="Res"/><text>It is easy to find out the incremental algorithm always performs faster than the non-incremental algorithm for computing approximations until a threshold of the deleting ratio.</text></s>
<s sid="361"><CoreSc1 advantage="None" conceptID="Res148" novelty="None" type="Res"/><text>The threshold differs depending on the data sets.</text></s>
<s sid="362"><CoreSc1 advantage="None" conceptID="Obs62" novelty="None" type="Obs"/><text>For example, in Fig. 2(a), (e), and (f), the thresholds of ratios are around 85%; In Fig. 2(b) and (c), the thresholds of ratios are around 65%; In Fig. 2(d), the incremental algorithm consistently outperforms the static algorithm even in the value of 90%.</text></s>
<s sid="363"><CoreSc1 advantage="None" conceptID="Con29" novelty="None" type="Con"/><text>A comparison of computational efficiency between static and incremental algorithms with the insertion of the objects</text></s>
<s sid="364"><CoreSc1 advantage="None" conceptID="Con30" novelty="None" type="Con"/><text>Similar to the experiment schemes for comparing the efficiencies between static and incremental algorithms when deleting the objects from the universe, we also adopt such schemes to compare the performance of algorithms on the case of inserting the objects into the universe.</text></s>
<s sid="365"><CoreSc1 advantage="None" conceptID="Res149" novelty="None" type="Res"/><text>Firstly, we compare the two algorithms, i.e., Algorithm 1 and Algorithm 3, on the six data sets in Table 5 with the same updating ratio (the ratio of the number of inserting data and original data), but different sizes of the original data.</text></s>
<s sid="366"><CoreSc1 advantage="None" conceptID="Res150" novelty="None" type="Res"/><text>Here, we assume the updating ratio is equal to 5%.</text></s>
<s sid="367"><CoreSc1 advantage="None" conceptID="Res151" novelty="None" type="Res"/><text>The experimental results are shown in Table 8.</text></s>
<s sid="368"><CoreSc1 advantage="None" conceptID="Res152" novelty="None" type="Res"/><text>More detailed change trendline of each of two algorithms with the increasing size of data sets are presented in Fig. 3.</text></s>
<s sid="369"><CoreSc1 advantage="None" conceptID="Res153" novelty="None" type="Res"/><text>Secondly, we compare the computational times of the two algorithms with the changing of updating ratios for each data sets.</text></s>
<s sid="370"><CoreSc1 advantage="None" conceptID="Res154" novelty="None" type="Res"/><text>We show the experimental results in Table 9, and more detailed change trendline of each of two algorithms with the increasing size of data sets are given in Fig. 4.</text></s>
<s sid="371"><CoreSc1 advantage="None" conceptID="Res155" novelty="None" type="Res"/><text>In each sub-figures (a)-(f) of Fig. 3, the x-coordinate pertains to the size of the data set (the 10 data sets starting from the smallest one), while the y-coordinate presents the computational time.</text></s>
<s sid="372"><CoreSc1 advantage="None" conceptID="Con31" novelty="None" type="Con"/><text>We use the star lines to denote the computational time of static algorithm (Algorithm 1) on different sizes of data sets, and the plus lines denote the computational time of incremental algorithm (Algorithm 3) on different sizes of data sets when inserting the objects into the universe.</text></s>
<s sid="373"><CoreSc1 advantage="None" conceptID="Con32" novelty="None" type="Con"/><text>Obviously, according to Table 8 and Fig. 3, we can find that the computational time of the both algorithms usually increases with the increasing size of data sets.</text></s>
<s sid="374"><CoreSc1 advantage="None" conceptID="Con33" novelty="None" type="Con"/><text>However, the incremental algorithm is much faster than the static algorithm for computing the approximations when inserting the objects into the universe.</text></s>
<s sid="375"><CoreSc1 advantage="None" conceptID="Con34" novelty="None" type="Con"/><text>Furthermore, the differences between static and incremental algorithms are getting larger when increasing the data size.</text></s>
<s sid="376"><CoreSc1 advantage="None" conceptID="Res156" novelty="None" type="Res"/><text>In each sub-figures (a)-(f) of Fig. 4, the x-coordinate pertains to the ratio of the number of the inserted objects and original data, while the y-coordinate concerns the computational time.</text></s>
<s sid="377"><CoreSc1 advantage="None" conceptID="Res157" novelty="None" type="Res"/><text>According to the experimental results as shown in Table 9 and Fig. 4, we find that the computational time of both static (Algorithm 1) and incremental (Algorithm 3) algorithms are increasing monotonically along with the increasing of insert ratios.</text></s>
<s sid="378"><CoreSc1 advantage="None" conceptID="Res158" novelty="None" type="Res"/><text>It is easy to get the incremental algorithm is always faster than the static algorithm when the inserting ratio increases from 10% to 100% according to Fig. 4(a)-(e).</text></s>
<s sid="379"><CoreSc1 advantage="None" conceptID="Res159" novelty="None" type="Res"/><text>In Fig. 4(f), we find the incremental algorithm is mush faster than the static algorithm when the inserting ratio is less than 85%, but slower than the static algorithm when the inserting ratio is more than 85%.</text></s>
Conclusions
<s sid="380"><CoreSc1 advantage="None" conceptID="Con35" novelty="None" type="Con"/><text>The incremental technique is an effective way to maintain knowledge in the dynamic environment.</text></s>
<s sid="381"><CoreSc1 advantage="None" conceptID="Con36" novelty="None" type="Con"/><text>In this paper, we proposed incremental methods for updating approximations in SOIS when the information system is updated by inserting or deleting objects.</text></s>
<s sid="382"><CoreSc1 advantage="None" conceptID="Res160" novelty="None" type="Res"/><text>Through discussing the principles of updating approximations by deleting objects from the information system and inserting objects into the information system, respectively, we proposed the incremental algorithms for updating approximations based on SOIS in terms of inserting or deleting an object.</text></s>
<s sid="383"><CoreSc1 advantage="None" conceptID="Res161" novelty="None" type="Res"/><text>Experimental studies pertaining to four UCI data sets and two artificial data sets showed that the incremental algorithms can improve the computational efficiency for updating approximations when the object set in the information system varies over time.</text></s>
<s sid="384"><CoreSc1 advantage="None" conceptID="Con37" novelty="None" type="Con"/><text>In real-world applications, an information system may be updated by inserting and deleting some objects at the same time.</text></s>
<s sid="385"><CoreSc1 advantage="None" conceptID="Con38" novelty="None" type="Con"/><text>In our further work, we will focus on improving the incremental algorithm for updating knowledge by deleting and deleting some objects simultaneously.</text></s>
<s sid="386"><CoreSc1 advantage="None" conceptID="Con39" novelty="None" type="Con"/><text>Furthermore, as an information system consists of the objects, the attributes, and the domain of attributes values, all of the elements in the information system will change as time goes by under the dynamic environment.</text></s>
<s sid="387"><CoreSc1 advantage="None" conceptID="Con40" novelty="None" type="Con"/><text>In the future, the variation of attributes and the domain of attributes values in SOIS will also be taken into consideration in terms of incremental updating knowledge.</text></s>
</BODY>
<OTHER>
Acknowledgements
This work is supported by the National Science Foundation of China (Nos.
61175047, 61100117 and 71201133) and NSAF (No.
U1230117), the Youth Social Science Foundation of the Chinese Education Commission (11YJC630127) and the Fundamental Research Funds for the Central Universities (SWJTU11ZT08, SWJTU12CX091, SWJTU12CX117).

</OTHER>
</PAPER>