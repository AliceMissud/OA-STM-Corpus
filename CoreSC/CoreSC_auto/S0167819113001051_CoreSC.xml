<?xml version="1.0" ?><PAPER><mode2 hasDoc="yes" name="S0167819113001051.tmf1" version="elsevier"/>
<TITLE>SpiNNaker: Fault tolerance in a power- and area- constrained large-scale neuromimetic architecture
</TITLE>
<ABSTRACT>

Highlights
•
<s sid="1"><CoreSc1 advantage="None" conceptID="Bac1" novelty="None" type="Bac"/><text>Discussion of chip-level fault tolerance of SpiNNaker's design.</text></s>
•
<s sid="2"><CoreSc1 advantage="None" conceptID="Bac2" novelty="None" type="Bac"/><text>The implemented software improves fault tolerance by providing diagnostics and reconfiguration.</text></s>
•
<s sid="3"><CoreSc1 advantage="None" conceptID="Bac3" novelty="None" type="Bac"/><text>Exploration of communication-level fault tolerance and its effects on system scalability.</text></s>
•
<s sid="4"><CoreSc1 advantage="None" conceptID="Bac4" novelty="None" type="Bac"/><text>Wide range of experiments showing that SpiNNaker is highly resilient to failures.</text></s>
Abstract
<s sid="5"><CoreSc1 advantage="None" conceptID="Bac5" novelty="None" type="Bac"/><text>SpiNNaker is a biologically-inspired massively-parallel computer designed to model up to a billion spiking neurons in real-time.</text></s>
<s sid="6"><CoreSc1 advantage="None" conceptID="Bac6" novelty="None" type="Bac"/><text>A full-fledged implementation of a SpiNNaker system will comprise more than 105 integrated circuits (half of which are SDRAMs and half multi-core systems-on-chip).</text></s>
<s sid="7"><CoreSc1 advantage="None" conceptID="Bac7" novelty="None" type="Bac"/><text>Given this scale, it is unavoidable that some components fail and, in consequence, fault-tolerance is a foundation of the system design.</text></s>
<s sid="8"><CoreSc1 advantage="None" conceptID="Bac8" novelty="None" type="Bac"/><text>Although the target application can tolerate a certain, low level of failures, important efforts have been devoted to incorporate different techniques for fault tolerance.</text></s>
<s sid="9"><CoreSc1 advantage="None" conceptID="Bac9" novelty="None" type="Bac"/><text>This paper is devoted to discussing how hardware and software mechanisms collaborate to make SpiNNaker operate properly even in the very likely scenario of component failures and how it can tolerate system-degradation levels well above those expected.</text></s>
</ABSTRACT>
<BODY>

Introduction
<s sid="10"><CoreSc1 advantage="None" conceptID="Met1" novelty="None" type="Met"/><text>SpiNNaker is an application specific design intended to model large biological neural networks - the name &quot;SpiNNaker&quot; being derived from 'Spiking Neural Network architecture'.</text></s>
<s sid="11"><CoreSc1 advantage="None" conceptID="Met2" novelty="None" type="Met"/><text>It consists of a toroidal arrangement of processing nodes, each incorporating a purpose-built, multi-core System-on-Chip (SoC) and an SDRAM memory (Fig. 1).</text></s>
<s sid="12"><CoreSc1 advantage="None" conceptID="Met3" novelty="None" type="Met"/><text>Neurons are modelled in software running on embedded ARM968 processors; each core is intended to model a nominal 1000 neurons.</text></s>
<s sid="13"><CoreSc1 advantage="None" conceptID="Met4" novelty="None" type="Met"/><text>Small-scale SpiNNaker systems have successfully been used as control systems in embedded applications [1], providing robots with real-time stimulus-response behaviour as described in [2].</text></s>
<s sid="14"><CoreSc1 advantage="None" conceptID="Mot1" novelty="None" type="Mot"/><text>However the ultimate aiming of the project is to construct a machine able to simulate up to 109 neurons in real time.</text></s>
<s sid="15"><CoreSc1 advantage="None" conceptID="Mot2" novelty="None" type="Mot"/><text>To put this number in context some small primates have brains with slightly lower neuron counts whereas the human brain has roughly 86 times this number [3].</text></s>
<s sid="16"><CoreSc1 advantage="None" conceptID="Bac10" novelty="None" type="Bac"/><text>To reach this number of neurons more than one hundred thousand integrated circuits will be needed (half of which are SpiNNaker chips and the other half SDRAMs).</text></s>
<s sid="17"><CoreSc1 advantage="None" conceptID="Bac11" novelty="None" type="Bac"/><text>A system of this scale may be expected to suffer component failures and many features of its design are included to provide a certain degree of fault tolerance.</text></s>
<s sid="18"><CoreSc1 advantage="None" conceptID="Bac12" novelty="None" type="Bac"/><text>These features can sometimes be justified on cost alone: the overall yield for the 100mm2 SpiNNaker SoC was estimated, using public domain yield statistics on a 20-core, at 50% fault-free chips, 25% single-fault chips, 10% two-fault chips and the remaining 15% will be unusable due to critical failures.</text></s>
<s sid="19"><CoreSc1 advantage="None" conceptID="Res1" novelty="None" type="Res"/><text>Early test on the production chip (in Fig. 2) show similar, if rather better, yield characteristics (see Section 4).</text></s>
<s sid="20"><CoreSc1 advantage="None" conceptID="Bac13" novelty="None" type="Bac"/><text>The 35% of chips having one or two faults would not be usable without fault tolerance features.</text></s>
<s sid="21"><CoreSc1 advantage="None" conceptID="Bac14" novelty="None" type="Bac"/><text>Fault tolerance is addressed at a number of levels, not least the application itself, which is intrinsically fault-tolerant.</text></s>
<s sid="22"><CoreSc1 advantage="None" conceptID="Bac15" novelty="None" type="Bac"/><text>SpiNNaker incorporates measures to enable continued function in the presence of faults; in fact it has been designed as a power- and cost-effective fault-tolerant platform.</text></s>
<s sid="23"><CoreSc1 advantage="None" conceptID="Bac16" novelty="None" type="Bac"/><text>The major defence against faults in such a system is the massive processing resource.</text></s>
<s sid="24"><CoreSc1 advantage="None" conceptID="Met5" novelty="None" type="Met"/><text>Processors are almost free and dedicating a small proportion of the processing power for system management and reconfiguration yields significant distributed 'intelligence' without much impact on the application.</text></s>
<s sid="25"><CoreSc1 advantage="None" conceptID="Met6" novelty="None" type="Met"/><text>From the outset the intention has been to allocate one core on each SoC entirely to system management; if this eventually proves insufficient it is simple to delegate a second core to this task.</text></s>
<s sid="26"><CoreSc1 advantage="None" conceptID="Met7" novelty="None" type="Met"/><text>Cores devoted to system management can identify and map around failed devices at run time.</text></s>
<s sid="27"><CoreSc1 advantage="None" conceptID="Met8" novelty="None" type="Met"/><text>Particular attention has been paid to inter-chip communications where link failures or transient congestion may be routed around rapidly without software intervention.</text></s>
<s sid="28"><CoreSc1 advantage="None" conceptID="Met9" novelty="None" type="Met"/><text>Finally some more conventional techniques - such as automatic CRC generation and checking and watchdog timers - are employed in each processing node.</text></s>
<s sid="29"><CoreSc1 advantage="None" conceptID="Mot3" novelty="None" type="Mot"/><text>As a large-scale system has not yet been built the full possibilities of software reconfiguration have yet to be explored.</text></s>
<s sid="30"><CoreSc1 advantage="None" conceptID="Obj1" novelty="None" type="Obj"/><text>However statistical models of the architecture have been developed and used to verify the principles, and the hardware mechanisms themselves have been tested in silicon in small-scale (4 chip) systems.</text></s>
<s sid="31"><CoreSc1 advantage="None" conceptID="Obj2" novelty="None" type="Obj"/><text>The construction of a larger machine is in progress.</text></s>
Background
<s sid="32"><CoreSc1 advantage="None" conceptID="Obj3" novelty="None" type="Obj"/><text>This section reviews common terminology on fault-tolerance and microelectronics, introducing several important concepts related to SpiNNaker and putting in context how fault tolerance is addressed.</text></s>
<s sid="33"><CoreSc1 advantage="None" conceptID="Obj4" novelty="None" type="Obj"/><text>Throughout this paper, we differentiate between soft and hard errors.</text></s>
<s sid="34"><CoreSc1 advantage="None" conceptID="Met10" novelty="None" type="Met"/><text>Soft errors are transient errors - usually produced by electromagnetic noise - that affect the state of a bit to an extent that it swaps its value (from 0 to 1, or vice versa).</text></s>
<s sid="35"><CoreSc1 advantage="None" conceptID="Met11" novelty="None" type="Met"/><text>Cosmic rays are nowadays the main cause of soft errors [4].</text></s>
<s sid="36"><CoreSc1 advantage="None" conceptID="Met12" novelty="None" type="Met"/><text>In contrast, hard errors are permanent errors due to physical defects, usually introduced during fabrication.</text></s>
<s sid="37"><CoreSc1 advantage="None" conceptID="Bac17" novelty="None" type="Bac"/><text>Some authors consider a third type of error, intermittent failures in which a component is barely stable and behaves irregularly as correct or as erroneous, the main triggers for one behaviour or the other being environmental factors (such as temperature, or voltage) [5].</text></s>
<s sid="38"><CoreSc1 advantage="None" conceptID="Obj5" novelty="None" type="Obj"/><text>We consider intermittent failures as hard failures and deactivate components that exhibit this behaviour.</text></s>
<s sid="39"><CoreSc1 advantage="None" conceptID="Obs1" novelty="None" type="Obs"/><text>All units within a SpiNNaker chip are provided with two levels of reset.</text></s>
<s sid="40"><CoreSc1 advantage="None" conceptID="Res2" novelty="None" type="Res"/><text>A 'soft' reset is a signal to the state machines to abandon their operation at the next convenient opportunity, thus allowing any handshakes to complete first.</text></s>
<s sid="41"><CoreSc1 advantage="None" conceptID="Bac18" novelty="None" type="Bac"/><text>The 'hard' reset involves switching off a component and restarting it in order to reach its initial state.</text></s>
<s sid="42"><CoreSc1 advantage="None" conceptID="Bac19" novelty="None" type="Bac"/><text>Note that the latter is really intended only for power-up.</text></s>
<s sid="43"><CoreSc1 advantage="None" conceptID="Met13" novelty="None" type="Met"/><text>Globally Asynchronous Locally Synchronous (GALS) technology offers the possibility of synchronous and asynchronous logic to coexist, obtaining the best of each world [6].</text></s>
<s sid="44"><CoreSc1 advantage="None" conceptID="Met14" novelty="None" type="Met"/><text>Most devices use synchronous logic whereas communication between them is implemented using asynchronous fabrics.</text></s>
<s sid="45"><CoreSc1 advantage="None" conceptID="Res3" novelty="None" type="Res"/><text>GALS simplifies development and reduces power consumption but, in contrast, makes fault tolerance difficult due to the lack of time awareness.</text></s>
<s sid="46"><CoreSc1 advantage="None" conceptID="Res4" novelty="None" type="Res"/><text>The three main elements for fault-tolerance are the Host, the System Controller and the Monitor Processor and Process.</text></s>
<s sid="47"><CoreSc1 advantage="None" conceptID="Res5" novelty="None" type="Res"/><text>The Host is a regular computer which runs an application that interfaces with SpiNNaker giving the Host a range of control operations over the hardware.</text></s>
<s sid="48"><CoreSc1 advantage="None" conceptID="Obj6" novelty="None" type="Obj"/><text>The Host is in charge of starting the system, uploading neural applications and data and looking after the status of the system once it starts its execution.</text></s>
<s sid="49"><CoreSc1 advantage="None" conceptID="Obj7" novelty="None" type="Obj"/><text>It includes a User Interface that allows exploration of the status of SpiNNaker components (see Fig. 3).</text></s>
<s sid="50"><CoreSc1 advantage="None" conceptID="Obj8" novelty="None" type="Obj"/><text>The Monitor Process is the application in charge of controlling the status of each chip components.</text></s>
<s sid="51"><CoreSc1 advantage="None" conceptID="Obj9" novelty="None" type="Obj"/><text>It requires a dedicated core, namely the Monitor Processor, which is selected during the boot-up process from all the functional cores.</text></s>
<s sid="52"><CoreSc1 advantage="None" conceptID="Obj10" novelty="None" type="Obj"/><text>The Monitor Process uses the System Controller, a specialized piece of hardware, to detect and try to heal failing components.</text></s>
<s sid="53"><CoreSc1 advantage="None" conceptID="Met15" novelty="None" type="Met"/><text>The System Controller supports soft and hard resets of the different components within a chip and also communicates with the System Controller in neighbouring chips.</text></s>
<s sid="54"><CoreSc1 advantage="None" conceptID="Met16" novelty="None" type="Met"/><text>Watchdog devices are added to the design in order to supervise the correct operation of critical components such as the Monitor Process, or the communication ports.</text></s>
<s sid="55"><CoreSc1 advantage="None" conceptID="Res6" novelty="None" type="Res"/><text>If a component does not respond for a predetermined amount of time, the watchdog will apply 'soft' reset first, only resorting to 'hard' reset if this fails.</text></s>
<s sid="56"><CoreSc1 advantage="None" conceptID="Res7" novelty="None" type="Res"/><text>If both resets fail the watchdog will mark the component as faulty in the System Controller so that the Monitor Process can switch it off or, alternatively, try more elaborated nursing.</text></s>
<s sid="57"><CoreSc1 advantage="None" conceptID="Res8" novelty="None" type="Res"/><text>SpiNNaker's fault tolerance relies mainly on redundancy: 18 cores, 6 output links, 2 PLLs (phase locked loops) and the memory subsystem.</text></s>
<s sid="58"><CoreSc1 advantage="None" conceptID="Res9" novelty="None" type="Res"/><text>The main strength of this redundancy is that components do not have their identifiers hard-coded, and therefore the functionality of one component can be covered seamlessly by any redundant one.</text></s>
<s sid="59"><CoreSc1 advantage="None" conceptID="Res10" novelty="None" type="Res"/><text>Practically, this means that critical components such as the Monitor Processor are extremely reliable.</text></s>
<s sid="60"><CoreSc1 advantage="None" conceptID="Obs2" novelty="None" type="Obs"/><text>Table 1 shows the relative areas of the different components of the chip to put in context their likelihood of fail.</text></s>
<s sid="61"><CoreSc1 advantage="None" conceptID="Obj11" novelty="None" type="Obj"/><text>The largest part of the chip is devoted to cores and TCMs, the most redundant and therefore less critical components of SpiNNaker.</text></s>
Overview of SpiNNaker
Application-induced architecture
<s sid="62"><CoreSc1 advantage="None" conceptID="Met17" novelty="None" type="Met"/><text>SpiNNaker simulates spiking neural networks using Izhikevich [7] and Leaky Integrate and Fire [8] models which emulate the dynamics of biological neural systems.</text></s>
<s sid="63"><CoreSc1 advantage="None" conceptID="Met18" novelty="None" type="Met"/><text>However SpiNNaker has an architecture general enough to run other flavours of application [9].</text></s>
<s sid="64"><CoreSc1 advantage="None" conceptID="Met19" novelty="None" type="Met"/><text>For example it also supports Multilayer Perceptron models [10] and other non-neural applications such as ray-tracing, many body interaction, finite element analysis and analogue circuit simulation.</text></s>
<s sid="65"><CoreSc1 advantage="None" conceptID="Met20" novelty="None" type="Met"/><text>Spiking neural systems have abundant parallelism and no explicit requirement of coherence as only local information is used by the neurons.</text></s>
<s sid="66"><CoreSc1 advantage="None" conceptID="Exp1" novelty="None" type="Exp"/><text>The process is as follows: each neuron has a membrane potential which is affected by incoming stimuli (signals).</text></s>
<s sid="67"><CoreSc1 advantage="None" conceptID="Exp2" novelty="None" type="Exp"/><text>If the membrane potential exceeds a given threshold, the neuron discharges and fires a signal (a so-called spike) which is transmitted to all neurons connected through a synaptic connection, typically in the order of 103 [11].</text></s>
<s sid="68"><CoreSc1 advantage="None" conceptID="Res11" novelty="None" type="Res"/><text>Biological neurons work in a noisy environment [12] and, indeed, die during normal operation (adult humans lose about one neuron per second [13]).</text></s>
<s sid="69"><CoreSc1 advantage="None" conceptID="Res12" novelty="None" type="Res"/><text>Thus their operation is neither perfect nor deterministic.</text></s>
<s sid="70"><CoreSc1 advantage="None" conceptID="Res13" novelty="None" type="Res"/><text>The SpiNNaker architecture reflects this behaviour.</text></s>
<s sid="71"><CoreSc1 advantage="None" conceptID="Res14" novelty="None" type="Res"/><text>Neurons are modelled as event-driven applications executed by the processing cores.</text></s>
<s sid="72"><CoreSc1 advantage="None" conceptID="Exp3" novelty="None" type="Exp"/><text>Spikes are represented by short network packets (40 bits) using Address-Event Representation (AER), a format widely used in neural network models [14-16].</text></s>
<s sid="73"><CoreSc1 advantage="None" conceptID="Exp4" novelty="None" type="Exp"/><text>Packets are multicast routed in hardware with the on-chip routers replicating them as necessary to reach all their destinations.</text></s>
<s sid="74"><CoreSc1 advantage="None" conceptID="Bac20" novelty="None" type="Bac"/><text>Given that digital electronics are orders of magnitude faster than the biological process - for example, biological spikes are propagated through an axon for up to 20ms while transmitting a packet through the SpiNNaker interconnection network should take a few microseconds at most - it is possible to multiplex many neurons onto a processor and many spikes onto a network although the consequence of a single-point failure can easily be more serious than the loss of one neuron.</text></s>
SpiNNaker chip
<s sid="75"><CoreSc1 advantage="None" conceptID="Obj12" novelty="None" type="Obj"/><text>The basic unit of the system is the SpiNNaker chip (Fig. 4), custom GALS SoC with a network router and 18 cores sharing some resources such as a SRAM, a boot ROM, a System Controller, an Ethernet interface and an 128Mbyte off-chip (but in-package, see Fig. 2) SDRAM.</text></s>
<s sid="76"><CoreSc1 advantage="None" conceptID="Met21" novelty="None" type="Met"/><text>Each processing core is an ARM968, with two private tightly coupled memories for instructions (ITCM) and data (DTCM), some peripherals - including direct access to the Comms NoC - and a bridge to the shared resources.</text></s>
Fault tolerant architecture
<s sid="77"><CoreSc1 advantage="None" conceptID="Met22" novelty="None" type="Met"/><text>From Section 3 some fault-tolerant features will already be apparent.</text></s>
<s sid="78"><CoreSc1 advantage="None" conceptID="Met23" novelty="None" type="Met"/><text>Firstly the application itself is robust against minor perturbations in timing and should tolerate a percentage of missing spikes and neurons.</text></s>
<s sid="79"><CoreSc1 advantage="None" conceptID="Res15" novelty="None" type="Res"/><text>Secondly, there is a huge hardware resource available which provides a high degree of redundancy.</text></s>
<s sid="80"><CoreSc1 advantage="None" conceptID="Res16" novelty="None" type="Res"/><text>Although each node has 18 cores, the intended use does not require any specific number of cores, merely (any) one to provide node control and some others to run the application.</text></s>
<s sid="81"><CoreSc1 advantage="None" conceptID="Res17" novelty="None" type="Res"/><text>Indeed for cost purposes it is intended to use some flawed devices; yield estimates suggest that this may improve the usability of manufactured dice from 50% to around 80%.</text></s>
<s sid="82"><CoreSc1 advantage="None" conceptID="Hyp1" novelty="None" type="Hyp"/><text>Based on the area use of the die the majority of flaws may be expected to be in local memories; these may leave a core degraded but still usable although the simplest action is still to shut it down.</text></s>
<s sid="83"><CoreSc1 advantage="None" conceptID="Res18" novelty="None" type="Res"/><text>Preliminary evidence from the first batch of fabricated chips suggests these estimates to be appropriate if slightly pessimistic.</text></s>
<s sid="84"><CoreSc1 advantage="None" conceptID="Obs3" novelty="None" type="Obs"/><text>Of 46 chips, 30 (65%) were flawless chips, 12 (26%) have 17 working cores and 4 (9%) have more serious problems.</text></s>
<s sid="85"><CoreSc1 advantage="None" conceptID="Obs4" novelty="None" type="Obs"/><text>Of the 12, 11 have private memory faults and one a peripheral logic fault.</text></s>
<s sid="86"><CoreSc1 advantage="None" conceptID="Res19" novelty="None" type="Res"/><text>From this small sample it seems likely that 42 of 46 (93%) dice will be serviceable because manufacturing faults can be tolerated.</text></s>
<s sid="87"><CoreSc1 advantage="None" conceptID="Res20" novelty="None" type="Res"/><text>This represents an increase of roughly 40% in terms of achievable computing power (from 540 to 744 cores).</text></s>
<s sid="88"><CoreSc1 advantage="None" conceptID="Met24" novelty="None" type="Met"/><text>This redundancy can also be used to protect against (less likely) run-time faults by offloading work.</text></s>
<s sid="89"><CoreSc1 advantage="None" conceptID="Met25" novelty="None" type="Met"/><text>By keeping a stand-by core on each node a run-time fault can be accommodated without too much effort, particularly as the majority of the data is held in the separate, shared SDRAM.</text></s>
<s sid="90"><CoreSc1 advantage="None" conceptID="Obs5" novelty="None" type="Obs"/><text>The SDRAM devices are 'known good' before packaging.</text></s>
<s sid="91"><CoreSc1 advantage="None" conceptID="Res21" novelty="None" type="Res"/><text>Each provides a node with more than its anticipated store requirement, thus there is capacity to test and map around any dubious region.</text></s>
<s sid="92"><CoreSc1 advantage="None" conceptID="Res22" novelty="None" type="Res"/><text>This is one of the tasks for the local Monitor Processor.</text></s>
<s sid="93"><CoreSc1 advantage="None" conceptID="Res23" novelty="None" type="Res"/><text>In addition to redundancy, a number of features have been included either as design considerations or specifically for fault-tolerance.</text></s>
<s sid="94"><CoreSc1 advantage="None" conceptID="Res24" novelty="None" type="Res"/><text>Fig. 5 shows a map of the expected failure types and the mechanisms provided to reduce their impact in the usability of SpiNNaker.</text></s>
Diagnostics and dynamic configuration
<s sid="95"><CoreSc1 advantage="None" conceptID="Res25" novelty="None" type="Res"/><text>System routines can clearly be split into two: (i) power-on testing and initial configuration, and (ii) isolation and reconfiguration during normal operation.</text></s>
<s sid="96"><CoreSc1 advantage="None" conceptID="Res26" novelty="None" type="Res"/><text>In either case, the interaction between hardware and system software in each chip is coordinated by the Monitor Processor which maintains a continuously updated state (good, fault, disabled, etc.) of the chip components.</text></s>
<s sid="97"><CoreSc1 advantage="None" conceptID="Met26" novelty="None" type="Met"/><text>The System Controller can disable or reconfigure chip components.</text></s>
<s sid="98"><CoreSc1 advantage="None" conceptID="Met27" novelty="None" type="Met"/><text>In extreme failure cases the System Controller can be accessed from a neighbouring SpiNNaker chip using a local debug facility.</text></s>
Power-on diagnostics and configuration
<s sid="99"><CoreSc1 advantage="None" conceptID="Met28" novelty="None" type="Met"/><text>Each SpiNNaker chip performs diagnostics and initialization using minimal system software stored in the Boot ROM.</text></s>
<s sid="100"><CoreSc1 advantage="None" conceptID="Met29" novelty="None" type="Met"/><text>In this stage each processing core performs a power-on self-test and initialisation of its private peripherals.</text></s>
<s sid="101"><CoreSc1 advantage="None" conceptID="Met30" novelty="None" type="Met"/><text>Healthy cores then compete to access the System Controller monitor election register, the winner becoming the Monitor Processor.</text></s>
<s sid="102"><CoreSc1 advantage="None" conceptID="Res27" novelty="None" type="Res"/><text>The remaining cores simply register their state in the System Controller and stall until the Monitor completes the node configuration (including detailed chip-level tests, initialising shared resources and detecting any connected Ethernet port).</text></s>
<s sid="103"><CoreSc1 advantage="None" conceptID="Res28" novelty="None" type="Res"/><text>All chip-level results are stored in the System Controller.</text></s>
<s sid="104"><CoreSc1 advantage="None" conceptID="Res29" novelty="None" type="Res"/><text>After this step, nodes enter a listening mode awaiting external instructions.</text></s>
<s sid="105"><CoreSc1 advantage="None" conceptID="Res30" novelty="None" type="Res"/><text>The host machine designates one or more Ethernet attached nodes to receive the system image to be executed by the Monitor Processors.</text></s>
<s sid="106"><CoreSc1 advantage="None" conceptID="Res31" novelty="None" type="Res"/><text>The image is transmitted in blocks to the Ethernet attached Monitors which compile the image, perform a CRC check and copy it to their local memory where it can be executed.</text></s>
<s sid="107"><CoreSc1 advantage="None" conceptID="Res32" novelty="None" type="Res"/><text>The system image informs the host machine and propagates itself to its neighbours; these neighbours send it forward their neighbours, and so on.</text></s>
<s sid="108"><CoreSc1 advantage="None" conceptID="Res33" novelty="None" type="Res"/><text>This way the system image is flood-filled in a redundant manner as each chip will receive several copies of the system image (see below).</text></s>
<s sid="109"><CoreSc1 advantage="None" conceptID="Res34" novelty="None" type="Res"/><text>Once system boot is complete, the Monitor Processors test connections to neighbouring chips to record any faulty link or neighbour.</text></s>
<s sid="110"><CoreSc1 advantage="None" conceptID="Res35" novelty="None" type="Res"/><text>The host nominates one Ethernet-attached chip as the Reference Chip, making it the origin address, (0,0), of the network, notifying it of the topological characteristics, such as the number of chips.</text></s>
<s sid="111"><CoreSc1 advantage="None" conceptID="Res36" novelty="None" type="Res"/><text>The Reference Chip then broadcasts its address to its six neighbours, and so on.</text></s>
<s sid="112"><CoreSc1 advantage="None" conceptID="Met31" novelty="None" type="Met"/><text>This generates a second wave through the network that enables each chip to compute its relative address in the network topology and configure point-to-point routing tables.</text></s>
<s sid="113"><CoreSc1 advantage="None" conceptID="Met32" novelty="None" type="Met"/><text>Evaluation of flood filling policies</text></s>
<s sid="114"><CoreSc1 advantage="None" conceptID="Met33" novelty="None" type="Met"/><text>Data loading can be done via several flood-fill strategies, each offering different performance and fault resilience compromises.</text></s>
<s sid="115"><CoreSc1 advantage="None" conceptID="Met34" novelty="None" type="Met"/><text>Several of these strategies were evaluated previously [17], but when that evaluation was performed, broadcast packets were addressed to all neighbours and consequently most strategies had to use point-to-point (unicast) packets, with the consequent overloading of the injection ports.</text></s>
<s sid="116"><CoreSc1 advantage="None" conceptID="Obj13" novelty="None" type="Obj"/><text>To overcome this overhead a selective multicast able to forward packets to a subset of the neighbours was included in the final design.</text></s>
<s sid="117"><CoreSc1 advantage="None" conceptID="Obj14" novelty="None" type="Obj"/><text>The following evaluation considers several strategies using this selective multicast.</text></s>
<s sid="118"><CoreSc1 advantage="None" conceptID="Obs6" novelty="None" type="Obs"/><text>Fig. 6 summarizes the results of an event-driven simulation of the application loading process in the largest system configuration (256 ×256 nodes).</text></s>
<s sid="119"><CoreSc1 advantage="None" conceptID="Obs7" novelty="None" type="Obs"/><text>The top two graphs consider SpiNNaker systems without failures and are intended to show the performance (time consumed in the floodfill).</text></s>
<s sid="120"><CoreSc1 advantage="None" conceptID="Res37" novelty="None" type="Res"/><text>The bottom two consider systems with different link failure configurations and show the resilience level provided by each strategy.</text></s>
<s sid="121"><CoreSc1 advantage="None" conceptID="Obj15" novelty="None" type="Obj"/><text>Next we explain how these graphs can be interpreted.</text></s>
<s sid="122"><CoreSc1 advantage="None" conceptID="Obj16" novelty="None" type="Obj"/><text>Seven different flood-fill policies were considered in the simulations:•</text></s>
<s sid="123"><CoreSc1 advantage="None" conceptID="Obs8" novelty="None" type="Obs"/><text>bcast sends the packet to all neighbouring chips.</text></s>
•
<s sid="124"><CoreSc1 advantage="None" conceptID="Res38" novelty="None" type="Res"/><text>2msg sends the packet only to the neighbours in the positive X and Y directions.</text></s>
<s sid="125"><CoreSc1 advantage="None" conceptID="Res39" novelty="None" type="Res"/><text>This is the minimum number of neighbours required to perform an efficient flooding.</text></s>
•
<s sid="126"><CoreSc1 advantage="None" conceptID="Res40" novelty="None" type="Res"/><text>3msg sends the packet to the neighbours in positive X, Y and XY diagonal.</text></s>
•
<s sid="127"><CoreSc1 advantage="None" conceptID="Res41" novelty="None" type="Res"/><text>5msg sends the packet to all the neighbours but the one the original packet was received from.</text></s>
•
<s sid="128"><CoreSc1 advantage="None" conceptID="Res42" novelty="None" type="Res"/><text>randP sends the packet in the positive X and Y directions and in addition randomly to each of the other directions with a P% probability.</text></s>
<s sid="129"><CoreSc1 advantage="None" conceptID="Res43" novelty="None" type="Res"/><text>We considered 25% (rand25), 50% (rand50) and 75% (rand75) in our evaluation.</text></s>
<s sid="130"><CoreSc1 advantage="None" conceptID="Res44" novelty="None" type="Res"/><text>In the simulations considering several Ethernet ports, nodes located at (0, 0), (128, 128), (128, 0) and (0, 128) are connected to the host.</text></s>
<s sid="131"><CoreSc1 advantage="None" conceptID="Res45" novelty="None" type="Res"/><text>The results without failures in Fig. 6(a) and (b) show that (i) different flooding strategies provide diverse performance levels, (ii) given the 2D-pipelined nature of the application loading procedure, the loading times are not affected substantially by the network size; and (iii) similarly, the number of Ethernet-connected nodes does not affect significantly the time required to load the application.</text></s>
<s sid="132"><CoreSc1 advantage="None" conceptID="Obs9" novelty="None" type="Obs"/><text>The configurations with failures - see Fig. 6(c) and (d) - present the normalized number of undelivered packets.</text></s>
<s sid="133"><CoreSc1 advantage="None" conceptID="Obs10" novelty="None" type="Obs"/><text>Points that are not shown in the plot mean that the loading process was successful.</text></s>
<s sid="134"><CoreSc1 advantage="None" conceptID="Obj17" novelty="None" type="Obj"/><text>The failure distributions considered in this study are the following.•</text></s>
<s sid="135"><CoreSc1 advantage="None" conceptID="Obs11" novelty="None" type="Obs"/><text>vert represents a configuration where all the links along the Y-axis in the bisection are treated as faulty, leading to a network split in vertical columns.</text></s>
•
<s sid="136"><CoreSc1 advantage="None" conceptID="Obs12" novelty="None" type="Obs"/><text>horiz represents a similar configuration, but affecting the horizontal axis.</text></s>
•
<s sid="137"><CoreSc1 advantage="None" conceptID="Obs13" novelty="None" type="Obs"/><text>cross represents the union of horiz and vert.</text></s>
<s sid="138"><CoreSc1 advantage="None" conceptID="Obs14" novelty="None" type="Obs"/><text>Small-scale examples of these three configurations are shown in Fig. 7.</text></s>
•
<s sid="139"><CoreSc1 advantage="None" conceptID="Res46" novelty="None" type="Res"/><text>The remaining configurations represent uniform random sets of link failures: 1536 (rnd1), 3072 (rnd2), 6144 (rnd3), 12,288 (rnd4) and 24,576 (rnd5).</text></s>
<s sid="140"><CoreSc1 advantage="None" conceptID="Con1" novelty="None" type="Con"/><text>In general, those strategies sending more packets are less likely to lose packets but at the price of increasing the time required to finalize the whole process.</text></s>
<s sid="141"><CoreSc1 advantage="None" conceptID="Res47" novelty="None" type="Res"/><text>In all cases, it will take only from 5 to 15 ms to load an application completely.</text></s>
<s sid="142"><CoreSc1 advantage="None" conceptID="Con2" novelty="None" type="Con"/><text>Results also show that increasing the number of Ethernet connections improves robustness, especially in scenarios with multiple failures.</text></s>
<s sid="143"><CoreSc1 advantage="None" conceptID="Con3" novelty="None" type="Con"/><text>We conclude that the SpiNNaker configuration process is efficient, scalable and robust.</text></s>
<s sid="144"><CoreSc1 advantage="None" conceptID="Res48" novelty="None" type="Res"/><text>Moreover, there is a reasonable range of distribution strategies that allow trade-offs between speed and fault-resilience.</text></s>
Run-time reconfiguration
<s sid="145"><CoreSc1 advantage="None" conceptID="Res49" novelty="None" type="Res"/><text>During regular operation, the Monitor Processor periodically checks and updates the state of chip resources, including the state of the links to its neighbours, in the System Controller.</text></s>
<s sid="146"><CoreSc1 advantage="None" conceptID="Res50" novelty="None" type="Res"/><text>Any Monitor Processor can activate the neighbour diagnostic and recovery routine if it suspects a neighbour chip is not working properly.</text></s>
<s sid="147"><CoreSc1 advantage="None" conceptID="Res51" novelty="None" type="Res"/><text>This nurse Chip will 'peek and poke' the remote System Controller to identify any healthy cores.</text></s>
<s sid="148"><CoreSc1 advantage="None" conceptID="Obj18" novelty="None" type="Obj"/><text>It will first try to change the remote Monitor Processor, then try to overcome a Boot ROM failure by copying the boot-up code to the remote System RAM and remapping the remote Boot ROM and System RAM.</text></s>
<s sid="149"><CoreSc1 advantage="None" conceptID="Obj19" novelty="None" type="Obj"/><text>Finally, the Nurse Chip will reset the remote chip to attempt to recover from a transient fault.</text></s>
<s sid="150"><CoreSc1 advantage="None" conceptID="Met35" novelty="None" type="Met"/><text>If nothing works, the failed chip is isolated by disabling its clocks.</text></s>
<s sid="151"><CoreSc1 advantage="None" conceptID="Met36" novelty="None" type="Met"/><text>When cores or chips are detected to be faulty, the system tries to migrate their functionality (typically neurons) to other cores.</text></s>
<s sid="152"><CoreSc1 advantage="None" conceptID="Hyp2" novelty="None" type="Hyp"/><text>This process is in principle straightforward, however depending on the failure some of the neural information may be impossible to recover.</text></s>
<s sid="153"><CoreSc1 advantage="None" conceptID="Met37" novelty="None" type="Met"/><text>For example, to migrate from a chip because it cannot access its SDRAM, only the neural information stored in local memory can be recovered.</text></s>
<s sid="154"><CoreSc1 advantage="None" conceptID="Met38" novelty="None" type="Met"/><text>The way to regenerate unrecoverable information will depend on the executed application but, as discussed before, losing neurons is acceptable in a biological brain and therefore it may be so in the simulated application.</text></s>
<s sid="155"><CoreSc1 advantage="None" conceptID="Res52" novelty="None" type="Res"/><text>When routers or links stop working properly, part of the routing tables may need to be reconstructed dynamically to avoid unreliable areas of the network.</text></s>
<s sid="156"><CoreSc1 advantage="None" conceptID="Con4" novelty="None" type="Con"/><text>When a route is destroyed, the system can generate new routes by the back propagation of a routing key from the destination node to the source node.</text></s>
<s sid="157"><CoreSc1 advantage="None" conceptID="Con5" novelty="None" type="Con"/><text>The host system will collect the required information from this procedure and will generate and propagate the updated routing tables.</text></s>
<s sid="158"><CoreSc1 advantage="None" conceptID="Con6" novelty="None" type="Con"/><text>Alternatively, a distributed reconfiguration may rely on the Monitor Processes around the failing components for the generation and propagation of the updated routing tables.</text></s>
<s sid="159"><CoreSc1 advantage="None" conceptID="Res53" novelty="None" type="Res"/><text>Finally, each SpiNNaker chip is provided with a watchdog timer which detects when the Monitor Processor has not responded for a long time.</text></s>
<s sid="160"><CoreSc1 advantage="None" conceptID="Res54" novelty="None" type="Res"/><text>When this is detected, the recovery process first tries to recover the Monitor Processor by soft resetting it.</text></s>
<s sid="161"><CoreSc1 advantage="None" conceptID="Con7" novelty="None" type="Con"/><text>If this measure does not solve the problem, then it hard resets the chip, forcing the System Controller to select another core as a Monitor Processor.</text></s>
Communications fault tolerance
<s sid="162"><CoreSc1 advantage="None" conceptID="Con8" novelty="None" type="Con"/><text>Given that the supported application is communication-intensive the interconnection fabric of SpiNNaker is another critical component and therefore great effort has been devoted to design a robust and stable infrastructure.</text></s>
On-chip and off-chip communication
<s sid="163"><CoreSc1 advantage="None" conceptID="Con9" novelty="None" type="Con"/><text>The Comms NoC connects the processing cores via a custom on-chip router offering a bandwidth of up to 1GByte/s.</text></s>
<s sid="164"><CoreSc1 advantage="None" conceptID="Res55" novelty="None" type="Res"/><text>The Communications Controller within each processing core handles packets on behalf of its simulated neurons and interfaces with the Comms NoC.</text></s>
<s sid="165"><CoreSc1 advantage="None" conceptID="Res56" novelty="None" type="Res"/><text>Together the on-chip router and the self-timed fabric seamlessly extend on-chip communications onto inter-chip connections.</text></s>
<s sid="166"><CoreSc1 advantage="None" conceptID="Res57" novelty="None" type="Res"/><text>The Comms NoC has 18 ports for internal use of the processing cores and six ports to communicate with six adjacent chips (Fig. 4).</text></s>
<s sid="167"><CoreSc1 advantage="None" conceptID="Res58" novelty="None" type="Res"/><text>External ports contain two independent, unidirectional self-timed chip-to-chip interfaces, one for transmitting and the other one for receiving data; i.e. a failure in a link or interface only affects one of the directions.</text></s>
<s sid="168"><CoreSc1 advantage="None" conceptID="Res59" novelty="None" type="Res"/><text>Asynchronously arriving packets to the router are arbitrated and serialised.</text></s>
<s sid="169"><CoreSc1 advantage="None" conceptID="Res60" novelty="None" type="Res"/><text>The router can process one packet per clock cycle.</text></s>
<s sid="170"><CoreSc1 advantage="None" conceptID="Con10" novelty="None" type="Con"/><text>It is expected that the average traffic demand will be much lower than this.</text></s>
<s sid="171"><CoreSc1 advantage="None" conceptID="Con11" novelty="None" type="Con"/><text>In the event of a 'collision' packets can be delayed arbitrarily and buffering between routers helps to accommodate this.</text></s>
<s sid="172"><CoreSc1 advantage="None" conceptID="Met39" novelty="None" type="Met"/><text>Packets are checked for integrity on arrival at the router; faulty packets are dropped into a register where they can be examined by the local Monitor Processor.</text></s>
<s sid="173"><CoreSc1 advantage="None" conceptID="Res61" novelty="None" type="Res"/><text>Faults may be caused by corruption in transit - indicated by parity and framing errors - or by being outdated.</text></s>
<s sid="174"><CoreSc1 advantage="None" conceptID="Res62" novelty="None" type="Res"/><text>AER packet routing is done with a 1024 entry associative look-up table.</text></s>
<s sid="175"><CoreSc1 advantage="None" conceptID="Obj20" novelty="None" type="Obj"/><text>Each table entry has its own bitmap mask that will be applied to the source address before it is compared with the table entries in order.</text></s>
<s sid="176"><CoreSc1 advantage="None" conceptID="Obs15" novelty="None" type="Obs"/><text>If an address is not found then the packet is default routed to the port opposite the one it came from.</text></s>
<s sid="177"><CoreSc1 advantage="None" conceptID="Obs16" novelty="None" type="Obs"/><text>Table entries are therefore only used when packets turn or bifurcate.</text></s>
<s sid="178"><CoreSc1 advantage="None" conceptID="Obs17" novelty="None" type="Obs"/><text>Each table entry can be deactivated independently if not functioning properly; there is therefore some flexibility (potential redundancy) in the way table entries are used.</text></s>
<s sid="179"><CoreSc1 advantage="None" conceptID="Res63" novelty="None" type="Res"/><text>As the table uses standard cell latches the soft error rate is expected to be very low.</text></s>
<s sid="180"><CoreSc1 advantage="None" conceptID="Con12" novelty="None" type="Con"/><text>Packets may be replicated to any subset of the router's outputs.</text></s>
<s sid="181"><CoreSc1 advantage="None" conceptID="Con13" novelty="None" type="Con"/><text>They are sent when all the desired outputs are ready to accept them, stalling until this time.</text></s>
<s sid="182"><CoreSc1 advantage="None" conceptID="Con14" novelty="None" type="Con"/><text>In the event of an output being blocked this could cause problems and backlog the router.</text></s>
<s sid="183"><CoreSc1 advantage="None" conceptID="Con15" novelty="None" type="Con"/><text>Thus, after a programmable interval, the router attempts to route around any blocked (or broken) external links through a so-called emergency route.</text></s>
<s sid="184"><CoreSc1 advantage="None" conceptID="Con16" novelty="None" type="Con"/><text>If this still fails after another programmable interval the offending packet is dropped into a local register and the subsequent packet is tried instead.</text></s>
<s sid="185"><CoreSc1 advantage="None" conceptID="Con17" novelty="None" type="Con"/><text>The Monitor Processor may be interrupted to examine the dropped packet and resend it - perhaps suitably modified - later.</text></s>
<s sid="186"><CoreSc1 advantage="None" conceptID="Res64" novelty="None" type="Res"/><text>Emergency routed packets take advantage of the triangular topology to try to reach their destinations, as shown in Fig. 8.</text></s>
<s sid="187"><CoreSc1 advantage="None" conceptID="Res65" novelty="None" type="Res"/><text>Emergency routes are always adjacent to the intended path and the subsequent turns are therefore predefined.</text></s>
<s sid="188"><CoreSc1 advantage="None" conceptID="Res66" novelty="None" type="Res"/><text>This is coded into the short packet header.</text></s>
<s sid="189"><CoreSc1 advantage="None" conceptID="Res67" novelty="None" type="Res"/><text>A particular concern is the possible occurrence of (network-level) deadlock.</text></s>
<s sid="190"><CoreSc1 advantage="None" conceptID="Con18" novelty="None" type="Con"/><text>Conventional HPC networks avoid the formation of such chains by means of complex combinations of topology, routing algorithms and flow-control techniques [18].</text></s>
<s sid="191"><CoreSc1 advantage="None" conceptID="Con19" novelty="None" type="Con"/><text>Given that routing is application specific a different approach to deadlock avoidance was required.</text></s>
<s sid="192"><CoreSc1 advantage="None" conceptID="Con20" novelty="None" type="Con"/><text>As neural applications do not require delivery guarantees, a time-out based, packet-dropping mechanism suffices, provided that the proportion of lost packets is low.</text></s>
Topological robustness
<s sid="193"><CoreSc1 advantage="None" conceptID="Con21" novelty="None" type="Con"/><text>To assess the robustness of the two-dimensional triangular torus topology we tested how it loses connectivity in the presence of link failures.</text></s>
<s sid="194"><CoreSc1 advantage="None" conceptID="Con22" novelty="None" type="Con"/><text>A typical manufacturing process can be expected to produce components with a functional life of well over 10 years.</text></s>
<s sid="195"><CoreSc1 advantage="None" conceptID="Res68" novelty="None" type="Res"/><text>With a very pessimistic scenario model of a 5-year mean time to failure (MTTF) with sigma of 2 years, the expected number of link failures in a complete SpiNNaker system (65,536 nodes) for any given day (Fday) would lie between 160 and 360.</text></s>
<s sid="196"><CoreSc1 advantage="None" conceptID="Res69" novelty="None" type="Res"/><text>We contrasted SpiNNaker topology with regular two- and three-dimensional tori for 65,536 nodes.</text></s>
<s sid="197"><CoreSc1 advantage="None" conceptID="Res70" novelty="None" type="Res"/><text>The 2-D topologies are arranged as square networks of 256×256 nodes whereas the 3-D torus is arranged as a 64×32×32 network.</text></s>
<s sid="198"><CoreSc1 advantage="None" conceptID="Res71" novelty="None" type="Res"/><text>We assessed how the three topologies lose node-connectivity as the number of link failures increases from 1 to 65,536.</text></s>
<s sid="199"><CoreSc1 advantage="None" conceptID="Res72" novelty="None" type="Res"/><text>A depth-first search algorithm was used to calculate this figure for 105 random uniform failure configurations.</text></s>
<s sid="200"><CoreSc1 advantage="None" conceptID="Res73" novelty="None" type="Res"/><text>The average of these 105 runs is plotted in Fig. 9.</text></s>
<s sid="201"><CoreSc1 advantage="None" conceptID="Res74" novelty="None" type="Res"/><text>In the figure we can see that the triangular two-dimensional torus implemented in SpiNNaker provides a robustness level similar to a three-dimensional torus.</text></s>
<s sid="202"><CoreSc1 advantage="None" conceptID="Con23" novelty="None" type="Con"/><text>Both topologies can support up to 8,192 random link failures without any of the nodes losing connectivity with the rest of the system, more than one order of magnitude above (Fday).</text></s>
<s sid="203"><CoreSc1 advantage="None" conceptID="Con24" novelty="None" type="Con"/><text>On average tens of thousands of link failures are required to lose one or more nodes.</text></s>
<s sid="204"><CoreSc1 advantage="None" conceptID="Con25" novelty="None" type="Con"/><text>This robustness motivates the use of the triangular torus topology in SpiNNaker.</text></s>
<s sid="205"><CoreSc1 advantage="None" conceptID="Con26" novelty="None" type="Con"/><text>Interconnect stability under severe degradation</text></s>
<s sid="206"><CoreSc1 advantage="None" conceptID="Con27" novelty="None" type="Con"/><text>The packet dropping mechanism provides a deadlock-free interconnection network.</text></s>
<s sid="207"><CoreSc1 advantage="None" conceptID="Con28" novelty="None" type="Con"/><text>However, there is a loss of information that has to be assessed.</text></s>
<s sid="208"><CoreSc1 advantage="None" conceptID="Res75" novelty="None" type="Res"/><text>Spiking neuron systems can work when a few messages are lost but, even in very pessimistic scenarios, the number of dropped packets should be low (below 1 packet per million.</text></s>
<s sid="209"><CoreSc1 advantage="None" conceptID="Res76" novelty="None" type="Res"/><text>Approximatelly 1 packet each 1,500 cycles in the following experiments).</text></s>
<s sid="210"><CoreSc1 advantage="None" conceptID="Con29" novelty="None" type="Con"/><text>Simulation has verified that the network can deal with loads well-above the expected without significantly impacting applications (packet delay is acceptable) [21].</text></s>
<s sid="211"><CoreSc1 advantage="None" conceptID="Con30" novelty="None" type="Con"/><text>The simulations model a 256×256 network considering scenarios in which the network suffers different levels of hard failures.</text></s>
<s sid="212"><CoreSc1 advantage="None" conceptID="Goa1" novelty="None" type="Goa"/><text>To account for the real-time constraint, this section investigates the temporal evolution of the system and focuses on stability, understood as the variability (which should be low) of the figures of merit and assesses the effectiveness of the emergency routing mechanism.</text></s>
<s sid="213"><CoreSc1 advantage="None" conceptID="Mod1" novelty="None" type="Mod"/><text>Simulation model of the SpiNNaker network</text></s>
<s sid="214"><CoreSc1 advantage="None" conceptID="Mod2" novelty="None" type="Mod"/><text>A simplified model of the SpiNNaker interconnection infrastructure has been implemented in INSEE [19].</text></s>
<s sid="215"><CoreSc1 advantage="None" conceptID="Mod3" novelty="None" type="Mod"/><text>It includes the topological description of the system and a model of the router.</text></s>
<s sid="216"><CoreSc1 advantage="None" conceptID="Res77" novelty="None" type="Res"/><text>Time is modelled in terms of abstract network cycles the time to route and forward a packet (1 network cycle≈10 processor cycles).</text></s>
<s sid="217"><CoreSc1 advantage="None" conceptID="Res78" novelty="None" type="Res"/><text>A network node represents a complete SpiNNaker chip, with all its cores and its router.</text></s>
<s sid="218"><CoreSc1 advantage="None" conceptID="Res79" novelty="None" type="Res"/><text>Nodes are modelled as independent traffic sources that inject packets following a Bernoulli temporal distribution that can be parameterized to generate any chosen injection rate.</text></s>
<s sid="219"><CoreSc1 advantage="None" conceptID="Res80" novelty="None" type="Res"/><text>The spatial distribution of the traffic is uniform.</text></s>
<s sid="220"><CoreSc1 advantage="None" conceptID="Res81" novelty="None" type="Res"/><text>All ports are modelled as a single four-packet queue.</text></s>
<s sid="221"><CoreSc1 advantage="None" conceptID="Res82" novelty="None" type="Res"/><text>If this is full and the node tries to inject a packet, it is dropped.</text></s>
Communications are point-to-point.
<s sid="222"><CoreSc1 advantage="None" conceptID="Res83" novelty="None" type="Res"/><text>Routing tables are not implemented, using Dimension Order Routing instead.</text></s>
<s sid="223"><CoreSc1 advantage="None" conceptID="Res84" novelty="None" type="Res"/><text>This emulates the expected shape of communications - two straight lines with one inflection point [20].</text></s>
<s sid="224"><CoreSc1 advantage="None" conceptID="Res85" novelty="None" type="Res"/><text>As discussed in Section 5, the SpiNNaker system is aware of network failures and can modify its routing tables to avoid conflictive areas.</text></s>
<s sid="225"><CoreSc1 advantage="None" conceptID="Res86" novelty="None" type="Res"/><text>In contrast, DOR is oblivious and therefore unaware of network failures so our results should be taken as pessimistic</text></s>
<s sid="226"><CoreSc1 advantage="None" conceptID="Res87" novelty="None" type="Res"/><text>The experiments consider systems with 0 to 1024 link failures which covers scenarios well above Fday (as discussed before).</text></s>
<s sid="227"><CoreSc1 advantage="None" conceptID="Res88" novelty="None" type="Res"/><text>Consequently this evaluation should be understood as a worst-case study.</text></s>
<s sid="228"><CoreSc1 advantage="None" conceptID="Res89" novelty="None" type="Res"/><text>Experiments and discussion of results</text></s>
<s sid="229"><CoreSc1 advantage="None" conceptID="Obj21" novelty="None" type="Obj"/><text>In the following experimental work, we will use the maximum network load expected during regular operational levels of SpiNNaker which was derived in previous research [21].</text></s>
<s sid="230"><CoreSc1 advantage="None" conceptID="Obj22" novelty="None" type="Obj"/><text>We show the evolution of a SpiNNaker network degrading progressively from 0 to 1024 random link failures which are introduced at the beginning of every sampling period (5,000 cycles).</text></s>
<s sid="231"><CoreSc1 advantage="None" conceptID="Res90" novelty="None" type="Res"/><text>The figures of interest are accepted load, number of dropped packets and packet latency figures (average and maximum).</text></s>
<s sid="232"><CoreSc1 advantage="None" conceptID="Res91" novelty="None" type="Res"/><text>Router parameters are fixed to the values suggested by previous experiments [21].</text></s>
<s sid="233"><CoreSc1 advantage="None" conceptID="Obj23" novelty="None" type="Obj"/><text>To assess the impact of emergency routing on system stability, we plot results without (Fig. 10a) and with this mechanism (Fig. 10b).</text></s>
<s sid="234"><CoreSc1 advantage="None" conceptID="Res92" novelty="None" type="Res"/><text>To better understand the graphs, notice that the X-axis measures time (cycles).</text></s>
<s sid="235"><CoreSc1 advantage="None" conceptID="Res93" novelty="None" type="Res"/><text>The labels at the top (1, 2, 4,…,1024) indicate the total number of failures at the corresponding time: during the first 5 kcycles the network is fully operative, from 5k to 10k there is a single link failure, from 10k to 15k there are two failures, and so on.</text></s>
<s sid="236"><CoreSc1 advantage="None" conceptID="Res94" novelty="None" type="Res"/><text>Each performance metric has its own unit, indicated in the Y-axes: packets (for the dropped packets line), cycles (for the average and maximum delay lines) and packets/cycle/node (for the accepted load line).</text></s>
<s sid="237"><CoreSc1 advantage="None" conceptID="Res95" novelty="None" type="Res"/><text>Note that plotted data, including the number of dropped packets, are not cumulative, but correspond to 10-cycle measurement periods.</text></s>
<s sid="238"><CoreSc1 advantage="None" conceptID="Res96" novelty="None" type="Res"/><text>Fig. 10(a) shows how the progressive introduction of failures results in a high variability of performance metrics when emergency routing is not activated.</text></s>
<s sid="239"><CoreSc1 advantage="None" conceptID="Res97" novelty="None" type="Res"/><text>Accepted load drops by up to 25%, maximum delay noticeably fluctuates and the number of dropped packets grows linearly with the number of link failures.</text></s>
<s sid="240"><CoreSc1 advantage="None" conceptID="Res98" novelty="None" type="Res"/><text>For clarity, in the graphs the Y-axis is bounded by 0 and 500, which leaves out the number of dropped packets for 512 failures (around 800) and 1024 failures (around 1600).</text></s>
<s sid="241"><CoreSc1 advantage="None" conceptID="Res99" novelty="None" type="Res"/><text>We can see that even with a single failure the system with emergency routing deactivated (approx.</text></s>
<s sid="242"><CoreSc1 advantage="None" conceptID="Res100" novelty="None" type="Res"/><text>1 packet dropped every 50 cycles) noticeably exceeds the acceptable limit.</text></s>
<s sid="243"><CoreSc1 advantage="None" conceptID="Res101" novelty="None" type="Res"/><text>In contrast, evolution with the emergency routing activated, Fig. 10(b), shows very stable performance metrics.</text></s>
<s sid="244"><CoreSc1 advantage="None" conceptID="Res102" novelty="None" type="Res"/><text>Only some minor peaks in the maximum delay can be observed.</text></s>
<s sid="245"><CoreSc1 advantage="None" conceptID="Res103" novelty="None" type="Res"/><text>The most remarkable difference is in the number of dropped packets: no packets are dropped for experiments with fewer than 512 failures.</text></s>
<s sid="246"><CoreSc1 advantage="None" conceptID="Con31" novelty="None" type="Con"/><text>Considering that these scenarios are well beyond the described pessimistic range of failures (160-360), we can confirm that the emergency routing plays a major role in improving fault tolerance at the network level.</text></s>
<s sid="247"><CoreSc1 advantage="None" conceptID="Obs18" novelty="None" type="Obs"/><text>It is also worth noticing that, in all cases, when failures are introduced in the system we do not observe significant transient periods.</text></s>
<s sid="248"><CoreSc1 advantage="None" conceptID="Res104" novelty="None" type="Res"/><text>This means that, after a failure, the system reaches a stable situation very rapidly.</text></s>
<s sid="249"><CoreSc1 advantage="None" conceptID="Res105" novelty="None" type="Res"/><text>The conclusion is that the SpiNNaker interconnection network provides a highly stable communications fabric for the real-time simulation of spiking neurons.</text></s>
<s sid="250"><CoreSc1 advantage="None" conceptID="Res106" novelty="None" type="Res"/><text>Even under very pessimistic scenarios the interconnection network does not show significant performance fluctuations and degrades gracefully.</text></s>
Chip-to-chip interfaces
<s sid="251"><CoreSc1 advantage="None" conceptID="Res107" novelty="None" type="Res"/><text>The self-timed communication fabric is implemented using handshake protocols because of their advantages for large networks:•</text></s>
<s sid="252"><CoreSc1 advantage="None" conceptID="Res108" novelty="None" type="Res"/><text>Chips can be interconnected without regard to wiring delays which simplifies machine construction as some chips will be adjacent on a PCB whilst others may require considerable cabling or buffering with potential for delays and skew.</text></s>
•
<s sid="253"><CoreSc1 advantage="None" conceptID="Res109" novelty="None" type="Res"/><text>Power economy by limiting logic transitions (no clock information is transmitted).</text></s>
•
<s sid="254"><CoreSc1 advantage="None" conceptID="Res110" novelty="None" type="Res"/><text>Adequately high speed is retained.</text></s>
•
<s sid="255"><CoreSc1 advantage="None" conceptID="Res111" novelty="None" type="Res"/><text>Well suited to short, intermittent transmissions - appropriate for neural communications.</text></s>
<s sid="256"><CoreSc1 advantage="None" conceptID="Res112" novelty="None" type="Res"/><text>There is, however, a significant drawback to handshaking links: in the presence of noise they are prone to deadlock.</text></s>
<s sid="257"><CoreSc1 advantage="None" conceptID="Con32" novelty="None" type="Con"/><text>In this subsection these are deadlocks at the interface level, not to be confused with the previously discussed network-level deadlocks.</text></s>
<s sid="258"><CoreSc1 advantage="None" conceptID="Con33" novelty="None" type="Con"/><text>A handshake link can be thought of as passing a data token from the sender to the receiver which the handshake returns so that the next data can be sent.</text></s>
<s sid="259"><CoreSc1 advantage="None" conceptID="Con34" novelty="None" type="Con"/><text>Noise on the link may not only corrupt the data but also this control information, removing or introducing other tokens so that the sender and receiver lose coherence.</text></s>
<s sid="260"><CoreSc1 advantage="None" conceptID="Res113" novelty="None" type="Res"/><text>In the most serious case, a lost token can result in each waiting for the other and the data link cannot recover.</text></s>
<s sid="261"><CoreSc1 advantage="None" conceptID="Res114" novelty="None" type="Res"/><text>Timeout is not possible as there is no concept of time, only sequencing.</text></s>
<s sid="262"><CoreSc1 advantage="None" conceptID="Res115" novelty="None" type="Res"/><text>The on-chip network uses Silistix CHAIN [23] interconnection with 3-of-6 return-to-zero (RTZ) coding [22].</text></s>
<s sid="263"><CoreSc1 advantage="None" conceptID="Res116" novelty="None" type="Res"/><text>This provides a convenient symbol set with 20 codes of which 16 are used.</text></s>
<s sid="264"><CoreSc1 advantage="None" conceptID="Res117" novelty="None" type="Res"/><text>A separate channel provides an End-of-Packet (EoP) marker.</text></s>
<s sid="265"><CoreSc1 advantage="None" conceptID="Res118" novelty="None" type="Res"/><text>The inter-chip links use a different protocol to balance speed, pin usage and (particularly) power consumption.</text></s>
<s sid="266"><CoreSc1 advantage="None" conceptID="Res119" novelty="None" type="Res"/><text>Each four bit token is encoded as a 2-of-7 code (21 possible codes of which 17 are used: 4 bits plus EoP [24]).</text></s>
<s sid="267"><CoreSc1 advantage="None" conceptID="Res120" novelty="None" type="Res"/><text>To reduce the number of transitions a non-return-to-zero (NRZ) coding is used.</text></s>
<s sid="268"><CoreSc1 advantage="None" conceptID="Res121" novelty="None" type="Res"/><text>Noise glitches on the inter-chip wires introduce extra transitions, potentially in both the forward and return paths; these must be detected and recovered from at each end of the link.</text></s>
<s sid="269"><CoreSc1 advantage="None" conceptID="Res122" novelty="None" type="Res"/><text>The off-chip wiring is the most likely place for noise to be induced and it is assumed that such noise will cause a short glitch (i.e. two extra transitions) on a wire.</text></s>
<s sid="270"><CoreSc1 advantage="None" conceptID="Res123" novelty="None" type="Res"/><text>Glitches will be reasonably uncommon, therefore data integrity is not addressed in hardware; detection of damaged packets can be delegated to system software if any recovery is to be attempted.</text></s>
<s sid="271"><CoreSc1 advantage="None" conceptID="Res124" novelty="None" type="Res"/><text>The hardware simply has to keep running.</text></s>
<s sid="272"><CoreSc1 advantage="None" conceptID="Res125" novelty="None" type="Res"/><text>The majority of the fault tolerance resides in the receiver (Fig. 11) where various stages filter out potential problems.•</text></s>
<s sid="273"><CoreSc1 advantage="None" conceptID="Res126" novelty="None" type="Res"/><text>NRZ to RTZ Conversion: The problem for the first stage of the receiver is that it may not know the level of an input wire at its reset time.</text></s>
<s sid="274"><CoreSc1 advantage="None" conceptID="Res127" novelty="None" type="Res"/><text>This is overcome using a phase converter comprising two parallel RS flip-flops (Fig. 12) which acts as a transition detector which is set by one or more input transitions.</text></s>
<s sid="275"><CoreSc1 advantage="None" conceptID="Res128" novelty="None" type="Res"/><text>It is cleared locally between the detection of a symbol and its external acknowledgement.</text></s>
<s sid="276"><CoreSc1 advantage="None" conceptID="Res129" novelty="None" type="Res"/><text>Two transitions are made per symbol.</text></s>
<s sid="277"><CoreSc1 advantage="None" conceptID="Res130" novelty="None" type="Res"/><text>When at least two such phase converters are set, it is assumed that an input flit has been captured and passed to the next stage.</text></s>
•
<s sid="278"><CoreSc1 advantage="None" conceptID="Res131" novelty="None" type="Res"/><text>2-of-7 to 3-of-6 Conversion: The flit is then searched by the symbol converter (Fig. 13) using an asynchronous state machine with Muller C-elements [25,26].</text></s>
<s sid="279"><CoreSc1 advantage="None" conceptID="Con35" novelty="None" type="Con"/><text>In the absence of errors exactly one of these will be set but a glitch may have set more.</text></s>
<s sid="280"><CoreSc1 advantage="None" conceptID="Con36" novelty="None" type="Con"/><text>The output is therefore filtered with a priority encoder based on mutual exclusion elements which chooses a single, legal, 'one-hot' code.</text></s>
<s sid="281"><CoreSc1 advantage="None" conceptID="Con37" novelty="None" type="Con"/><text>There is no attempt to choose the 'correct' code - that information is not available - but any legal code will prevent a deadlock.</text></s>
<s sid="282"><CoreSc1 advantage="None" conceptID="Con38" novelty="None" type="Con"/><text>It is then a simple matter to generate a 3-of-6 code with an auxiliary EoP line appropriate for the NoC.</text></s>
•
<s sid="283"><CoreSc1 advantage="None" conceptID="Res132" novelty="None" type="Res"/><text>Flit Counter: Glitches can easily insert extra flits into a packet but it is important that no packet exceeds a maximum length.</text></s>
<s sid="284"><CoreSc1 advantage="None" conceptID="Res133" novelty="None" type="Res"/><text>A flit counter is added to keep track of the number of flits and, if it exceeds a given threshold an extra EoP is inserted, notifying explicitly a framing error.</text></s>
<s sid="285"><CoreSc1 advantage="None" conceptID="Res134" novelty="None" type="Res"/><text>The counter is reset on reception of an EoP.</text></s>
•
<s sid="286"><CoreSc1 advantage="None" conceptID="Res135" novelty="None" type="Res"/><text>Transmitter: The only external input is the handshake acknowledge line.</text></s>
<s sid="287"><CoreSc1 advantage="None" conceptID="Res136" novelty="None" type="Res"/><text>A phase converter detects at least one transition and treats that as the acknowledgement, further transitions being ignored until sending the next flit.</text></s>
<s sid="288"><CoreSc1 advantage="None" conceptID="Res137" novelty="None" type="Res"/><text>When a transmitter is reset its state is 'ready to send'.</text></s>
<s sid="289"><CoreSc1 advantage="None" conceptID="Res138" novelty="None" type="Res"/><text>Similarly, when a receiver is reset it sends an acknowledgement.</text></s>
<s sid="290"><CoreSc1 advantage="None" conceptID="Res139" novelty="None" type="Res"/><text>If the reset occurred during reception this enables the transmitter to send again but if no acknowledgement was outstanding then there is a spurious transition which is filtered by the transmitter.</text></s>
<s sid="291"><CoreSc1 advantage="None" conceptID="Res140" novelty="None" type="Res"/><text>The glitch tolerance automatically provides a simple, robust, single-ended reset capability which means that a node may be reset independently and still recover communication with its neighbours.</text></s>
Performance assessment
<s sid="292"><CoreSc1 advantage="None" conceptID="Res141" novelty="None" type="Res"/><text>Our novel fault tolerant interface was compared with a conventional unit.</text></s>
<s sid="293"><CoreSc1 advantage="None" conceptID="Res142" novelty="None" type="Res"/><text>Both circuits were simulated in Verilog handling roughly a million packets each in an extremely noisy environment in which packets have a 50% probability of being affected by a glitch.</text></s>
<s sid="294"><CoreSc1 advantage="None" conceptID="Res143" novelty="None" type="Res"/><text>This noise level is exceedingly high and thus the number of packets corrupted should not be a concern.</text></s>
<s sid="295"><CoreSc1 advantage="None" conceptID="Res144" novelty="None" type="Res"/><text>Results of these simulations are shown in Table 2.</text></s>
<s sid="296"><CoreSc1 advantage="None" conceptID="Res145" novelty="None" type="Res"/><text>Glitches represents the actual packet ratio affected by a glitch.</text></s>
<s sid="297"><CoreSc1 advantage="None" conceptID="Res146" novelty="None" type="Res"/><text>Error-free Packets represents the percentage of the packets affected by a glitch that were interpreted correctly i.e., those that have resisted the glitch; Deadlocks represents the percentage of packets affected by a glitch that deadlocked the interface.</text></s>
<s sid="298"><CoreSc1 advantage="None" conceptID="Res147" novelty="None" type="Res"/><text>As expected our design did not deadlock whereas a conventional unit deadlocked roughly 2% of the times that a glitch appears.</text></s>
<s sid="299"><CoreSc1 advantage="None" conceptID="Res148" novelty="None" type="Res"/><text>This is very significant as a single deadlock has the potential to cripple a link permanently (until the whole system is rebooted).</text></s>
<s sid="300"><CoreSc1 advantage="None" conceptID="Con39" novelty="None" type="Con"/><text>Given the communication-intensive application model supported by SpiNNaker this would mean a network becoming highly degraded very quickly if glitches appeared.</text></s>
<s sid="301"><CoreSc1 advantage="None" conceptID="Con40" novelty="None" type="Con"/><text>The price of the deadlock-free interface is that glitches alter the received data roughly 10% more often.</text></s>
<s sid="302"><CoreSc1 advantage="None" conceptID="Con41" novelty="None" type="Con"/><text>This is acceptable as glitches should be rare and erroneous packets can be detected and dropped.</text></s>
Intra-chip connections
<s sid="303"><CoreSc1 advantage="None" conceptID="Res149" novelty="None" type="Res"/><text>The asynchronous on-chip links are much less sensitive to noise-induced glitches, so they employ simpler logic.</text></s>
<s sid="304"><CoreSc1 advantage="None" conceptID="Res150" novelty="None" type="Res"/><text>However the potential for deadlock with handshake communications still applies.</text></s>
<s sid="305"><CoreSc1 advantage="None" conceptID="Con42" novelty="None" type="Con"/><text>To alleviate this intra-chip interfaces are provided with two levels of reset (soft and hard).</text></s>
<s sid="306"><CoreSc1 advantage="None" conceptID="Con43" novelty="None" type="Con"/><text>Watchdog will apply soft reset first and if this does not solve the problem, it will perform a hard reset of the entire node, thus disrupting chip operation - but not deadlocking the on-chip network.</text></s>
Other fault-tolerant features
Clock redundancy
<s sid="307"><CoreSc1 advantage="None" conceptID="Con44" novelty="None" type="Con"/><text>SpiNNaker chips have two independent PLLs with the intention of running the processors and the router at one frequency (200MHz) and the SDRAM at another (166MHz) to improve overall performance.</text></s>
<s sid="308"><CoreSc1 advantage="None" conceptID="Con45" novelty="None" type="Con"/><text>However clock sources can be switched so, in the event of a PLL failure, all subsystems' clocks can be derived from the same source.</text></s>
<s sid="309"><CoreSc1 advantage="None" conceptID="Con46" novelty="None" type="Con"/><text>This may reduce performance on that node but has no other consequence as the GALS interconnection is inherently adaptive.</text></s>
<s sid="310"><CoreSc1 advantage="None" conceptID="Con47" novelty="None" type="Con"/><text>GALS implications on fault tolerance</text></s>
<s sid="311"><CoreSc1 advantage="None" conceptID="Con48" novelty="None" type="Con"/><text>Using a GALS approach not only facilitates the SoC design process but also simplifies isolation of faulty components in run time by supporting resetting or disabling on-chip components independently from the rest of the SoC.</text></s>
Memory subsystem fault tolerance
<s sid="312"><CoreSc1 advantage="None" conceptID="Con49" novelty="None" type="Con"/><text>Various RAM is spread across a SpiNNaker chip (private TCMs, on-chip SRAM and off-chip RAM) which, as explained before, are the main expected points of failure.</text></s>
<s sid="313"><CoreSc1 advantage="None" conceptID="Con50" novelty="None" type="Con"/><text>In principle it is possible to work-around hard failures in private memories but the degree of redundancy in the system means our plan is simply to inactivate cores with permanent TCM failure(s).</text></s>
<s sid="314"><CoreSc1 advantage="None" conceptID="Con51" novelty="None" type="Con"/><text>The SDRAMs have some spare capacity and are mapped by the Monitor Processor so hard failures can be worked around.</text></s>
<s sid="315"><CoreSc1 advantage="None" conceptID="Con52" novelty="None" type="Con"/><text>Soft errors present a different challenge.</text></s>
<s sid="316"><CoreSc1 advantage="None" conceptID="Con53" novelty="None" type="Con"/><text>The SDRAM is usually accessed in blocks via DMA.</text></s>
<s sid="317"><CoreSc1 advantage="None" conceptID="Con54" novelty="None" type="Con"/><text>The DMA controller includes a fully programmable CRC generator and checker so faulty blocks can be detected and subject to software recovery.</text></s>
<s sid="318"><CoreSc1 advantage="None" conceptID="Con55" novelty="None" type="Con"/><text>Private memories are not protected by error detection; this was a pragmatic decision to maximise the speed and capacity of the chip.</text></s>
<s sid="319"><CoreSc1 advantage="None" conceptID="Con56" novelty="None" type="Con"/><text>Soft errors in code space can cause a software crash resulting in some lost neural information.</text></s>
<s sid="320"><CoreSc1 advantage="None" conceptID="Con57" novelty="None" type="Con"/><text>Recovery from this should be achieved by the watchdog mechanism resetting the affected core.</text></s>
<s sid="321"><CoreSc1 advantage="None" conceptID="Con58" novelty="None" type="Con"/><text>Corruption of data space may be detected by software limit checks or crashing or other erratic behaviour.</text></s>
<s sid="322"><CoreSc1 advantage="None" conceptID="Con59" novelty="None" type="Con"/><text>There may be some loss of data or some erroneous neural firing but the application should be robust enough to withstand this; it almost certainly happens in biological systems too!</text></s>
<s sid="323"><CoreSc1 advantage="None" conceptID="Con60" novelty="None" type="Con"/><text>Connecting with the outside world</text></s>
<s sid="324"><CoreSc1 advantage="None" conceptID="Con61" novelty="None" type="Con"/><text>A SpiNNaker system communicates with a host computer via Ethernet (Fig. 1) using TCP/IP.</text></s>
<s sid="325"><CoreSc1 advantage="None" conceptID="Con62" novelty="None" type="Con"/><text>This communication is used for different management actions, such as loading to the chip memories the application code or the neural connectivity information.</text></s>
<s sid="326"><CoreSc1 advantage="None" conceptID="Res151" novelty="None" type="Res"/><text>Although all chips have an Ethernet interface in practice only a few will make use of it to reduce power consumption and maximize the computing resources available to neurons.</text></s>
<s sid="327"><CoreSc1 advantage="None" conceptID="Res152" novelty="None" type="Res"/><text>Each Ethernet-connected chip translates frame-based communication to inter-chip packet-based communication.</text></s>
<s sid="328"><CoreSc1 advantage="None" conceptID="Res153" novelty="None" type="Res"/><text>The presence of several possible interfaces does, however, eliminate another possible single-point failure.</text></s>
Related work
<s sid="329"><CoreSc1 advantage="None" conceptID="Con63" novelty="None" type="Con"/><text>Research in simulating biologically-plausible neural networks (brain-like systems) is not new.</text></s>
<s sid="330"><CoreSc1 advantage="None" conceptID="Con64" novelty="None" type="Con"/><text>In the early 1990s a team at U.C.Berkeley worked on the Connectionist Network Supercomputer [27] which aimed to build a supercomputer specifically tailored for neural computation as a tool for connectionist research.</text></s>
<s sid="331"><CoreSc1 advantage="None" conceptID="Res154" novelty="None" type="Res"/><text>The system was a 2D mesh, with a target size of 128 nodes (scalable to 512).</text></s>
<s sid="332"><CoreSc1 advantage="None" conceptID="Res155" novelty="None" type="Res"/><text>Each node would incorporate a general-purpose RISC processor plus a vector coprocessor, 16 MBytes of RAM and a router.</text></s>
<s sid="333"><CoreSc1 advantage="None" conceptID="Res156" novelty="None" type="Res"/><text>As far as we know, the node was built (under the codename T0), but the system never operated as a network.</text></s>
<s sid="334"><CoreSc1 advantage="None" conceptID="Res157" novelty="None" type="Res"/><text>Experiments using up to five nodes in a bus configuration were discussed in [28].</text></s>
<s sid="335"><CoreSc1 advantage="None" conceptID="Res158" novelty="None" type="Res"/><text>More recently, the Microelectronics Division at the Technical University of Berlin worked on a project entitled Design and implementation of spiking neural networks [http://mikro.ee.tu-berlin.de/spinn] whose objectives are similar to those of SpiNNaker.</text></s>
<s sid="336"><CoreSc1 advantage="None" conceptID="Res159" novelty="None" type="Res"/><text>A product of this is the Spiking Neural Network Emulation Engine (SEE), an acceleration board implemented with FPGAs interconnected via an on-board bus.</text></s>
<s sid="337"><CoreSc1 advantage="None" conceptID="Obs19" novelty="None" type="Obs"/><text>SEE accelerators were able to perform neural computations 30 times faster than a desktop PC [29].</text></s>
<s sid="338"><CoreSc1 advantage="None" conceptID="Con65" novelty="None" type="Con"/><text>However, as these boards cannot be connected to form a network, they are not able to scale to the magnitudes of SpiNNaker.</text></s>
<s sid="339"><CoreSc1 advantage="None" conceptID="Con66" novelty="None" type="Con"/><text>Research on spiking neural networks has also used different off-the-shelf technologies such as FPGAs [30], graphic processors [31] and general purpose processors and accelerators [32], obtaining speed-ups of over two orders of magnitude compared to software-only implementations.</text></s>
<s sid="340"><CoreSc1 advantage="None" conceptID="Con67" novelty="None" type="Con"/><text>The relatively small scale of these systems allowed the assumption of a complete absence of component failures and, therefore, did not address reliability issues and did not incorporate fault-tolerant techniques.</text></s>
<s sid="341"><CoreSc1 advantage="None" conceptID="Con68" novelty="None" type="Con"/><text>As far as we know, there are only three active projects comparable to SpiNNaker in terms of simulation scale.</text></s>
<s sid="342"><CoreSc1 advantage="None" conceptID="Con69" novelty="None" type="Con"/><text>First, the Blue Brain project [http://bluebrain.epfl.ch/] aims to create biologically accurate functional models of the brain; however, model complexity (far more intricate than SpiNNaker's) only allows real-time execution of roughly a neuron per node [33].</text></s>
<s sid="343"><CoreSc1 advantage="None" conceptID="Res160" novelty="None" type="Res"/><text>This is a low figure in comparison with the several thousand (simpler) neurons per node supported by SpiNNaker.</text></s>
<s sid="344"><CoreSc1 advantage="None" conceptID="Res161" novelty="None" type="Res"/><text>Secondly, DARPA's System of Neuromorphic Adaptive Plastic Scalable Electronics (SyNAPSE) project claims that it has achieved the simulation of spiking neural networks the size of a cat's brain [34] - 109 neurons - using Izhikevich models like those supported by SpiNNaker.</text></s>
<s sid="345"><CoreSc1 advantage="None" conceptID="Res162" novelty="None" type="Res"/><text>However their simulations run 2-3 orders of magnitude slower than real-time.</text></s>
<s sid="346"><CoreSc1 advantage="None" conceptID="Res163" novelty="None" type="Res"/><text>In contrast with the biologically-inspired SpiNNaker architecture, neither Blue Brain nor SyNAPSE contemplate the construction of a custom architecture but use general-purpose supercomputers from the IBM BlueGene family, depending on the underlying platform for their reliability and fault tolerance.</text></s>
<s sid="347"><CoreSc1 advantage="None" conceptID="Res164" novelty="None" type="Res"/><text>The IBM BlueGene/L consists of 64K compute nodes, each based on PowerPC 400 processors.</text></s>
<s sid="348"><CoreSc1 advantage="None" conceptID="Res165" novelty="None" type="Res"/><text>Additionally, it contains several service nodes that reside outside the core [35] and communicate with it using Ethernet.</text></s>
<s sid="349"><CoreSc1 advantage="None" conceptID="Res166" novelty="None" type="Res"/><text>This infrastructure is used for booting, controlling and monitoring the system.</text></s>
<s sid="350"><CoreSc1 advantage="None" conceptID="Res167" novelty="None" type="Res"/><text>System monitoring and job execution is done by the combined action of service and I/O nodes which maintain log files.</text></s>
<s sid="351"><CoreSc1 advantage="None" conceptID="Res168" novelty="None" type="Res"/><text>During boot-up service nodes can control the computing core to the lowest level of granularity [36].</text></s>
<s sid="352"><CoreSc1 advantage="None" conceptID="Res169" novelty="None" type="Res"/><text>Service nodes can also directly write to and read from the device control registers of each processor.</text></s>
<s sid="353"><CoreSc1 advantage="None" conceptID="Res170" novelty="None" type="Res"/><text>This feature is useful for handling runtime problems and investigating any booting up issues.</text></s>
<s sid="354"><CoreSc1 advantage="None" conceptID="Con70" novelty="None" type="Con"/><text>For fault tolerance at boot-up or at run-time a self-test mechanism is kept in each chip to perform system diagnostics.</text></s>
<s sid="355"><CoreSc1 advantage="None" conceptID="Con71" novelty="None" type="Con"/><text>The BlueGene supercomputer or others, e.g., the Cray XT family of supercomputers [37,38], being general-purpose will provide solutions that do not match the power-efficiency of SpiNNaker.</text></s>
<s sid="356"><CoreSc1 advantage="None" conceptID="Con72" novelty="None" type="Con"/><text>Last but not least, the FACETS project [39] is attempting to create a faster than real-time hardware system for the simulation of networks of large but unspecified size.</text></s>
<s sid="357"><CoreSc1 advantage="None" conceptID="Con73" novelty="None" type="Con"/><text>This architecture, while biologically inspired, uses a fixed synapse and neuron model and, therefore, is not a system as general as SpiNNaker.</text></s>
<s sid="358"><CoreSc1 advantage="None" conceptID="Res171" novelty="None" type="Res"/><text>It employs analogue circuits to implement most of the central dynamic functions.</text></s>
<s sid="359"><CoreSc1 advantage="None" conceptID="Res172" novelty="None" type="Res"/><text>For these blocks what would constitute a 'fault' is not precisely defined since analogue circuits exhibit a continuum of states.</text></s>
<s sid="360"><CoreSc1 advantage="None" conceptID="Con74" novelty="None" type="Con"/><text>It is therefore relevant to discuss fault tolerance only with respect to the digital components: the communications infrastructure of the design.</text></s>
<s sid="361"><CoreSc1 advantage="None" conceptID="Con75" novelty="None" type="Con"/><text>The FACETS architecture uses wafer-scale devices [40] to achieve the necessary connectivity.</text></s>
<s sid="362"><CoreSc1 advantage="None" conceptID="Con76" novelty="None" type="Con"/><text>It uses AER signalling (similar to SpiNNaker), but with a circuit-switched, synchronous communications subsystem.</text></s>
<s sid="363"><CoreSc1 advantage="None" conceptID="Con77" novelty="None" type="Con"/><text>Systems of this kind are fault tolerant in the sense of being reconfigurable in the event of a failed link; however they are not live-reroutable, thus the system provides no protection against transient faults nor does it permit packet recovery or retransmission while the system is active.</text></s>
<s sid="364"><CoreSc1 advantage="None" conceptID="Con78" novelty="None" type="Con"/><text>A failed link requires at least a local reconfiguration with possible further routing impact.</text></s>
<s sid="365"><CoreSc1 advantage="None" conceptID="Con79" novelty="None" type="Con"/><text>FACETS authors discuss fault tolerance but only as a general property of neural systems; the system does not include specifically designed fault-tolerant mechanisms.</text></s>
<s sid="366"><CoreSc1 advantage="None" conceptID="Con80" novelty="None" type="Con"/><text>Thus the FACETS system, and its associated HICANN devices, once again represent a very different system designed to solve a different problem: faster than real-time neural simulation, for which power consumption is not a factor and fault tolerance merely a side effect rather than a design feature.</text></s>
<s sid="367"><CoreSc1 advantage="None" conceptID="Con81" novelty="None" type="Con"/><text>Outside of the field of brain-like systems we can cite a heterogeneous SoC with certain architectural similarities to SpiNNaker [41].</text></s>
<s sid="368"><CoreSc1 advantage="None" conceptID="Con82" novelty="None" type="Con"/><text>This consists of an array of processors connected over an on-chip NoC and containing various heterogeneous system components.</text></s>
<s sid="369"><CoreSc1 advantage="None" conceptID="Con83" novelty="None" type="Con"/><text>However, that project considers general-purpose applications within mission critical scenarios requiring the robustness of triple modular redundancy.</text></s>
<s sid="370"><CoreSc1 advantage="None" conceptID="Con84" novelty="None" type="Con"/><text>This approach is an expensive solution unsuitable for SpiNNaker.</text></s>
<s sid="371"><CoreSc1 advantage="None" conceptID="Con85" novelty="None" type="Con"/><text>In addition, their NoC appears to be a conventional synchronous design rather than the SpiNNaker self-timed communication fabric which may difficult scaling up the system.</text></s>
<s sid="372"><CoreSc1 advantage="None" conceptID="Con86" novelty="None" type="Con"/><text>Reviewing the literature on general purpose multiprocessor systems we can see how memory fault tolerance efforts have been devoted mainly to the interconnect structure [42], and to the use of ECC (originally following [43]), although this may not be in itself sufficient [44].</text></s>
<s sid="373"><CoreSc1 advantage="None" conceptID="Con87" novelty="None" type="Con"/><text>Given that symmetric redundancy of memory is expensive, recent work has introduced the concept of heterogeneous fault tolerance: graceful fall-back onto other components able to perform the same function, possibly with reduced performance [45,46].</text></s>
<s sid="374"><CoreSc1 advantage="None" conceptID="Con88" novelty="None" type="Con"/><text>Such an approach lowers overall hardware costs and represents a reasonable compromise in a power- or area-constrained design.</text></s>
<s sid="375"><CoreSc1 advantage="None" conceptID="Con89" novelty="None" type="Con"/><text>Our asymmetric memory architecture follows this approach.</text></s>
<s sid="376"><CoreSc1 advantage="None" conceptID="Con90" novelty="None" type="Con"/><text>Implementing fault tolerance in direct networks (such as 3D tori) is complex and costly and, therefore, a hot research topic.</text></s>
<s sid="377"><CoreSc1 advantage="None" conceptID="Con91" novelty="None" type="Con"/><text>Current solutions are neither easy nor cheap to implement in silicon (see, for example, [47,48]).</text></s>
<s sid="378"><CoreSc1 advantage="None" conceptID="Con92" novelty="None" type="Con"/><text>The simple emergency routing mechanism implemented in SpiNNker has been shown to be very effective for this purpose.</text></s>
Summary and conclusions
<s sid="379"><CoreSc1 advantage="None" conceptID="Con93" novelty="None" type="Con"/><text>This paper has focused on introducing the broad collection of fault tolerance mechanisms implemented in SpiNNaker.</text></s>
<s sid="380"><CoreSc1 advantage="None" conceptID="Con94" novelty="None" type="Con"/><text>Such features are quite extensive, and we have presented descriptions of the principal mechanisms and, where available, the pre-silicon assessment of their effectiveness.</text></s>
<s sid="381"><CoreSc1 advantage="None" conceptID="Con95" novelty="None" type="Con"/><text>Some of the most important features discussed in this paper are the following:•</text></s>
<s sid="382"><CoreSc1 advantage="None" conceptID="Con96" novelty="None" type="Con"/><text>A collection of system routines able to detect faults and to quickly recover from them when possible or to isolate components and to reconfigure the system otherwise.</text></s>
•
<s sid="383"><CoreSc1 advantage="None" conceptID="Con97" novelty="None" type="Con"/><text>A range of application loading policies offering different levels of resilience and performance which can be used depending on the level of system degradation.</text></s>
•
<s sid="384"><CoreSc1 advantage="None" conceptID="Con98" novelty="None" type="Con"/><text>The use of GALS logic that facilitates the SoC design process, simplifies timing closure and simplifies the isolation of faulty components but introduces weaknesses that have been overcome with custom-hardware.</text></s>
•
<s sid="385"><CoreSc1 advantage="None" conceptID="Con99" novelty="None" type="Con"/><text>Asymmetric redundancy of the memory subsystem, granting graceful fall-back onto other components able to perform the same function although with reduced performance.</text></s>
<s sid="386"><CoreSc1 advantage="None" conceptID="Con100" novelty="None" type="Con"/><text>Such an approach lowers overall hardware costs and represents a reasonable compromise in a power- or area-constrained design.</text></s>
•
<s sid="387"><CoreSc1 advantage="None" conceptID="Con101" novelty="None" type="Con"/><text>A novel robust self-timed chip-to-chip interface circuit, resilient to noise-induced glitches preventing deadlocks.</text></s>
•
<s sid="388"><CoreSc1 advantage="None" conceptID="Con102" novelty="None" type="Con"/><text>A stable communication fabric able to support communication demands exceeding those expected during regular operation.</text></s>
•
<s sid="389"><CoreSc1 advantage="None" conceptID="Con103" novelty="None" type="Con"/><text>The novel emergency routing mechanism helps to deal with congestion and network failures.</text></s>
<s sid="390"><CoreSc1 advantage="None" conceptID="Con104" novelty="None" type="Con"/><text>The main conclusion of this paper is that SpiNNaker is a well-balanced fault-resilient architecture in which fault-tolerance has been considered a fundamental foundation of its design.</text></s>
<s sid="391"><CoreSc1 advantage="None" conceptID="Con105" novelty="None" type="Con"/><text>This should facilitate its scaling from the prototype, 4-chip systems into practical, large-scale networks with over 1 million cores.</text></s>
</BODY>
<OTHER>
Acknowledgements
The SpiNNaker project is supported by the Engineering and Physical Sciences Research Council (EPSRC), through grants EP/G015740/1, EP/G013500/1, EP/D07908X/1 and GR/S61270/01, and also by industrial partners ARM and Silistix.
Prof.
Miguel-Alonso is supported by the Spanish Ministry of Science and Innovation (grant TIN2010-14931) and by the Basque Government (grant IT-242-07).
Dr.
Luján holds a Royal Society University Research Fellowship.
Dr.
Navaridas was a Royal Society Newton International Fellow when this research was performed.

</OTHER>
</PAPER>